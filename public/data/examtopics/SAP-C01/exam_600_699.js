var ExamTopic_600_699 = {
  "msg": "Quiz Questions",
  "data": [
    {
      "question_id": "#600",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company with multiple accounts is currently using a configuration that does not meet the following security governance policies:<br>✑ Prevent ingress from port 22 to any Amazon EC2 instance.<br>✑ Require billing and application tags for resources.<br>✑ Encrypt all Amazon EBS volumes.<br>A solutions architect wants to provide preventive and detective controls, including notifications about a specific resource, if there are policy deviations.<br>Which solution should the solutions architect implement?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#600",
          "answers": [
            {
              "choice": "<p>A. Create an AWS CodeCommit repository containing policy-compliant AWS CloudFormation templates. Create an AWS Service Catalog portfolio. Import the CloudFormation templates by attaching the CodeCommit repository to the portfolio. Restrict users across all accounts to items from the AWS Service Catalog portfolio. Use AWS Config managed rules to detect deviations from the policies. Configure an Amazon CloudWatch Events rule for deviations, and associate a CloudWatch alarm to send notifications when the TriggeredRules metric is greater than zero.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use AWS Service Catalog to build a portfolio with products that are in compliance with the governance policies in a central account. Restrict users across all accounts to AWS Service Catalog products. Share a compliant portfolio to other accounts. Use AWS Config managed rules to detect deviations from the policies. Configure an Amazon CloudWatch Events rule to send a notification when a deviation occurs.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Implement policy-compliant AWS CloudFormation templates for each account, and ensure that all provisioning is completed by CloudFormation. Configure Amazon Inspector to perform regular checks against resources. Perform policy validation and write the assessment output to Amazon CloudWatch Logs. Create a CloudWatch Logs metric filter to increment a metric when a deviation occurs. Configure a CloudWatch alarm to send notifications when the configured metric is greater than zero.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Restrict users and enforce least privilege access using AWS IAM. Consolidate all AWS CloudTrail logs into a single account. Send the CloudTrail logs to Amazon Elasticsearch Service (Amazon ES). Implement monitoring, alerting, and reporting using the Kibana dashboard in Amazon ES and with Amazon SNS.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 211018,
          "date": "Sun 19 Sep 2021 22:23",
          "username": "bbnbnuyh",
          "content": "B: https://aws.amazon.com/blogs/mt/use-aws-service-catalog-to-build-a-custom-catalog-of-products-from-aws-marketplace/<br>https://docs.aws.amazon.com/config/latest/developerguide/monitor-config-with-cloudwatchevents.html",
          "upvote_count": "16",
          "selected_answers": ""
        },
        {
          "id": 255320,
          "date": "Mon 27 Sep 2021 14:25",
          "username": "Bulti",
          "content": "B is the right answer. It is a standard hub and spoke service catalog approach to enabling users in multiple account launch products from their portfolio in their local service catalog. A is incorrect because, it doesn't make sense to have users in other accounts access a single service catalog in a central account. This is not hub and spoke service catalog model that is promoted as a best practice in a multi-account setup.",
          "upvote_count": "9",
          "selected_answers": ""
        },
        {
          "id": 677198,
          "date": "Fri 23 Sep 2022 15:39",
          "username": "AwsBRFan",
          "content": "Just codecommit will not work: https://docs.aws.amazon.com/codepipeline/latest/userguide/tutorials-S3-servicecatalog.html",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 615430,
          "date": "Sun 12 Jun 2022 18:52",
          "username": "CloudHell",
          "content": "B makes sense to me.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 497312,
          "date": "Thu 09 Dec 2021 05:20",
          "username": "cldy",
          "content": "B.  Use AWS Service Catalog to build a portfolio with products that are in compliance with the governance policies in a central account. Restrict users across all accounts to AWS Service Catalog products. Share a compliant portfolio to other accounts. Use AWS Config managed rules to detect deviations from the policies. Configure an Amazon CloudWatch Events rule to send a notification when a deviation occurs.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 491068,
          "date": "Wed 01 Dec 2021 00:49",
          "username": "AzureDP900",
          "content": "B is correct answer",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 436130,
          "date": "Sat 06 Nov 2021 01:52",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 412603,
          "date": "Sat 06 Nov 2021 00:56",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 405412,
          "date": "Thu 04 Nov 2021 16:39",
          "username": "Kopa",
          "content": "B, Use AWS Config managed rules to detect deviations from the policies. This is what AWS Config is made of.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 355108,
          "date": "Fri 22 Oct 2021 17:30",
          "username": "blackgamer",
          "content": "Answer is B. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 350960,
          "date": "Wed 13 Oct 2021 11:45",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 331579,
          "date": "Sun 10 Oct 2021 06:15",
          "username": "Sunflyhome",
          "content": "For ppl voting C, which step does control port 22 access?<br>ASC's portfolio doesn't define EC2's security group, does it?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 293096,
          "date": "Fri 08 Oct 2021 19:17",
          "username": "Kian1",
          "content": "going with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 269499,
          "date": "Mon 04 Oct 2021 00:34",
          "username": "01037student22RedKane",
          "content": "Why is A wrong?Bulli has explained this above.Probably because CoodeCommit repository can't be attached to the Porfolio. Service Catalog seams to only be able to create products based on CloudFormation templates or existing stacks.",
          "upvote_count": "111",
          "selected_answers": ""
        },
        {
          "id": 449480,
          "date": "Sun 07 Nov 2021 11:20",
          "username": "student22",
          "content": "Bulli has explained this above.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 330095,
          "date": "Sat 09 Oct 2021 07:52",
          "username": "RedKane",
          "content": "Probably because CoodeCommit repository can't be attached to the Porfolio. Service Catalog seams to only be able to create products based on CloudFormation templates or existing stacks.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 265326,
          "date": "Sun 03 Oct 2021 13:41",
          "username": "Ebi",
          "content": "B is the answer",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 244850,
          "date": "Sat 25 Sep 2021 21:11",
          "username": "T14102020",
          "content": "Correct is B.  ServiceCatalog + AWS Config managed rules to detect deviations + without Cloudwatchrules to detect deviations",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 232558,
          "date": "Tue 21 Sep 2021 04:43",
          "username": "jackdryan",
          "content": "I'll go with B",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#601",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is manually deploying its application to production and wants to move to a more mature deployment pattern. The company has asked a solutions architect to design a solution that leverages its current Chef tools and knowledge. The application must be deployed to a staging environment for testing and verification before being deployed to production. Any new deployment must be rolled back in 5 minutes if errors are discovered after a deployment.<br>Which AWS service and deployment pattern should the solutions architect use to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: D</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#601",
          "answers": [
            {
              "choice": "<p>A. Use AWS Elastic Beanstalk and deploy the application using a rolling update deployment strategy.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use AWS CodePipeline and deploy the application using a rolling update deployment strategy.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use AWS CodeBuild and deploy the application using a canary deployment strategy.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use AWS OpsWorks and deploy the application using a blue/green deployment strategy.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 156458,
          "date": "Mon 20 Sep 2021 12:46",
          "username": "Nemer",
          "content": "D.  blue/greenstaging/production with OpsWorks, which leverages Chef.",
          "upvote_count": "16",
          "selected_answers": ""
        },
        {
          "id": 269334,
          "date": "Sun 10 Oct 2021 15:30",
          "username": "Ebi",
          "content": "I will also go with D",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 496653,
          "date": "Wed 08 Dec 2021 09:35",
          "username": "cldy",
          "content": "D.  Use AWS OpsWorks and deploy the application using a blue/green deployment strategy.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491074,
          "date": "Wed 01 Dec 2021 01:13",
          "username": "AzureDP900",
          "content": "I will go with D, Blue/Green deployment we can revert back so quickly.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 483866,
          "date": "Mon 22 Nov 2021 06:02",
          "username": "acloudguru",
          "content": "should be D.  keywords \\\" current Chef tools and knowledge.\\\"",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 436131,
          "date": "Sat 06 Nov 2021 04:26",
          "username": "tgv",
          "content": "DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413231,
          "date": "Thu 04 Nov 2021 20:28",
          "username": "WhyIronMan",
          "content": "I'll go with D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 355150,
          "date": "Thu 04 Nov 2021 13:36",
          "username": "blackgamer",
          "content": "D, OpsWorks is like managed service for chef and puppets.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 351689,
          "date": "Mon 01 Nov 2021 06:11",
          "username": "Waiweng",
          "content": "it's D",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 334063,
          "date": "Sat 23 Oct 2021 17:47",
          "username": "KnightVictor",
          "content": "should be D.  keywords \\\" current Chef tools and knowledge.\\\"",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 292595,
          "date": "Sat 16 Oct 2021 16:20",
          "username": "Kian1",
          "content": "going with D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 266056,
          "date": "Sat 09 Oct 2021 03:57",
          "username": "kopper2019",
          "content": "Chef = OpsWorks = D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 244676,
          "date": "Fri 08 Oct 2021 18:28",
          "username": "T14102020",
          "content": "Correct is D.  blue/green",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 232370,
          "date": "Thu 30 Sep 2021 08:00",
          "username": "jackdryan",
          "content": "I'll go with D",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 229551,
          "date": "Mon 27 Sep 2021 20:54",
          "username": "oopsy",
          "content": "must be D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 208624,
          "date": "Sat 25 Sep 2021 16:23",
          "username": "CYL",
          "content": "D.  Opswork to utilize Chef. Blue / Green to allow for testing before switching to live production.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 205933,
          "date": "Wed 22 Sep 2021 23:15",
          "username": "Bulti",
          "content": "D is the right answer",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#602",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has been using a third-party provider for its content delivery network and recently decided to switch to Amazon CloudFront. The development team wants to maximize performance for the global user base. The company uses a content management system (CMS) that serves both static and dynamic content.<br>The CMS is behind an Application Load Balancer (ALB) which is set as the default origin for the distribution. Static assets are served from an Amazon S3 bucket.<br>The Origin Access Identity (OAI) was created properly and the S3 bucket policy has been updated to allow the GetObject action from the OAI, but static assets are receiving a 404 error.<br>Which combination of steps should the solutions architect take to fix the error? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: AD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#602",
          "answers": [
            {
              "choice": "<p>A. Add another origin to the CloudFront distribution for the static assets.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Add a path-based rule to the ALB to forward requests for the static assets.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Add an RTMP distribution to allow caching of both static and dynamic content.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Add a behavior to the CloudFront distribution for the path pattern and the origin of the static assets.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Add a host header condition to the ALB listener and forward the header from CloudFront to add traffic to the allow list.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 156498,
          "date": "Thu 30 Sep 2021 06:43",
          "username": "Nemeroscargee",
          "content": "AD. Addan origin and a behavior.<br>https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-distribution-serve-content/Add another origin for S3, not for CloudFront in the page you pointed out.",
          "upvote_count": "272",
          "selected_answers": ""
        },
        {
          "id": 363191,
          "date": "Mon 01 Nov 2021 14:46",
          "username": "oscargee",
          "content": "Add another origin for S3, not for CloudFront in the page you pointed out.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 622524,
          "date": "Sun 26 Jun 2022 13:48",
          "username": "kangtamo",
          "content": "Agree with AD. ",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: AD"
        },
        {
          "id": 496339,
          "date": "Tue 07 Dec 2021 22:21",
          "username": "AzureDP900",
          "content": "I'll go with A,D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436140,
          "date": "Tue 02 Nov 2021 06:27",
          "username": "tgv",
          "content": "AAA DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413232,
          "date": "Mon 01 Nov 2021 23:50",
          "username": "WhyIronMan",
          "content": "I'll go with A,D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 355170,
          "date": "Sun 31 Oct 2021 18:55",
          "username": "blackgamer",
          "content": "A and D .",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 353666,
          "date": "Sat 30 Oct 2021 19:22",
          "username": "Waiweng",
          "content": "it's A&D",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 292598,
          "date": "Wed 27 Oct 2021 10:52",
          "username": "Kian1",
          "content": "going with AD origin",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 269337,
          "date": "Sun 24 Oct 2021 17:46",
          "username": "Ebi",
          "content": "Answer is AD",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 265546,
          "date": "Sat 23 Oct 2021 22:58",
          "username": "01037",
          "content": "CMS serves both static and dynamic content, so why 404 happens?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 244693,
          "date": "Fri 22 Oct 2021 00:25",
          "username": "T14102020",
          "content": "Correct is AD.  Add an origin and a behavior.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 232382,
          "date": "Tue 19 Oct 2021 08:17",
          "username": "jackdryan",
          "content": "I'll go with A,D",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 208628,
          "date": "Tue 19 Oct 2021 00:23",
          "username": "CYL",
          "content": "AD allows us to store static content on S3 and have cloudfront assess it directly.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 207040,
          "date": "Sat 16 Oct 2021 16:05",
          "username": "ishuiyutian",
          "content": "A & D is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 205932,
          "date": "Sat 16 Oct 2021 14:43",
          "username": "Bulti",
          "content": "aD is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 173920,
          "date": "Tue 05 Oct 2021 23:16",
          "username": "wsw",
          "content": "AD is correct yes",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 157879,
          "date": "Tue 05 Oct 2021 08:33",
          "username": "Anila_Dhharisi",
          "content": "AD as per the link given by Nemer",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#603",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A financial services company logs personally identifiable information to its application logs stored in Amazon S3. Due to regulatory compliance requirements, the log files must be encrypted at rest. The security team has mandated that the company's on-premises hardware security modules (HSMs) be used to generate the<br>CMK material.<br>Which steps should the solutions architect take to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#603",
          "answers": [
            {
              "choice": "<p>A. Create an AWS CloudHSM cluster. Create a new CMK in AWS KMS using AWS_CloudHSM as the source for the key material and an origin of AWS_CLOUDHSM. Enable automatic key rotation on the CMK with a duration of 1 year. Configure a bucket policy on the logging bucket that disallows uploads of unencrypted data and requires that the encryption source be AWS KMS.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Provision an AWS Direct Connect connection, ensuring there is no overlap of the RFC 1918 address space between on-premises hardware and the VPCs. Configure an AWS bucket policy on the logging bucket that requires all objects to be encrypted. Configure the logging application to query the on-premises HSMs from the AWS environment for the encryption key material, and create a unique CMK for each logging event.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create a CMK in AWS KMS with no key material and an origin of EXTERNAL. Import the key material generated from the on-premises HSMs into the CMK using the public key and import token provided by AWS. Configure a bucket policy on the logging bucket that disallows uploads of non-encrypted data and requires that the encryption source be AWS KMS.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a new CMK in AWS KMS with AWS-provided key material and an origin of AWS_KMS. Disable this CMK, and overwrite the key material with the key material from the on-premises HSM using the public key and import token provided by AWS. Re-enable the CMK. Enable automatic key rotation on the CMK with a duration of 1 year. Configure a bucket policy on the logging bucket that disallows uploads of non-encrypted data and requires that the encryption source be AWS KMS.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 156522,
          "date": "Thu 23 Sep 2021 05:47",
          "username": "Nemer",
          "content": "C. Create CMK with origin EXTERNAL.<br>https://aws.amazon.com/blogs/security/how-to-byok-bring-your-own-key-to-aws-kms-for-less-than-15-00-a-year-using-aws-cloudhsm/",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 285327,
          "date": "Mon 18 Oct 2021 10:57",
          "username": "Ebi",
          "content": "C is my choice",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 717190,
          "date": "Sun 13 Nov 2022 09:48",
          "username": "et22s",
          "content": "C: KMS keys designed for imported key material have an origin value of EXTERNAL that cannot be changed. You cannot convert a KMS key for imported key material to use key material from any other source, including AWS KMS.<br><br>https://docs.aws.amazon.com/kms/latest/developerguide/importing-keys.html#importing-keys-considerations",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 595430,
          "date": "Sun 01 May 2022 06:24",
          "username": "pankajrawat",
          "content": "C is the correct answer",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 496340,
          "date": "Tue 07 Dec 2021 22:24",
          "username": "AzureDP900",
          "content": "I will go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 495095,
          "date": "Mon 06 Dec 2021 12:55",
          "username": "cldy",
          "content": "C.  Create a CMK in AWS KMS with no key material and an origin of EXTERNAL. Import the key material generated from the on-premises HSMs into the CMK using the public key and import token provided by AWS. Configure a bucket policy on the logging bucket that disallows uploads of non-encrypted data and requires that the encryption source be AWS KMS.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491089,
          "date": "Wed 01 Dec 2021 01:34",
          "username": "AzureDP900",
          "content": "C is correct answer !",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 484919,
          "date": "Tue 23 Nov 2021 10:46",
          "username": "backfringe",
          "content": "I go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 482939,
          "date": "Sun 21 Nov 2021 01:18",
          "username": "acloudguru",
          "content": "C,https://aws.amazon.com/blogs/security/how-to-byok-bring-your-own-key-to-aws-kms-for-less-than-15-00-a-year-using-aws-cloudhsm/",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 436133,
          "date": "Sat 06 Nov 2021 17:47",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433182,
          "date": "Sat 06 Nov 2021 12:10",
          "username": "blackgamer",
          "content": "C is the answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413237,
          "date": "Thu 21 Oct 2021 06:24",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 353669,
          "date": "Thu 21 Oct 2021 06:19",
          "username": "Waiweng",
          "content": "it;s C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 269787,
          "date": "Fri 15 Oct 2021 05:54",
          "username": "kopper2019",
          "content": "it's C<br><br>Step 1: Create the CMK with no key material associated<br>Begin by creating a customer master key (CMK) in AWS KMS that has no key material associated. The CLI command to create the CMK is as follows:<br><br>$ aws kms create-key --origin EXTERNAL --region us-east-1<br><br>If successful, you’ll see an output on the CLI similar to below. The KeyState will be PendingImport and the Origin will be EXTERNAL.",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 244747,
          "date": "Mon 04 Oct 2021 16:57",
          "username": "T14102020",
          "content": "Correct is C.  Create CMK with origin EXTERNAL.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 232420,
          "date": "Tue 28 Sep 2021 13:37",
          "username": "jackdryan",
          "content": "I'll go with C",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 208550,
          "date": "Mon 27 Sep 2021 00:02",
          "username": "CYL",
          "content": "C.  https://docs.aws.amazon.com/kms/latest/developerguide/importing-keys-create-cmk.html",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#604",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A solutions architect is implementing infrastructure as code for a two-tier web application in an AWS CloudFormation template. The web frontend application will be deployed on Amazon EC2 instances in an Auto Scaling group. The backend database will be an Amazon RDS for MySQL DB instance. The database password will be rotated every 60 days.<br>How can the solutions architect MOST securely manage the configuration of the application's database credentials?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#604",
          "answers": [
            {
              "choice": "<p>A. Provide the database password as a parameter in the CloudFormation template. Create an initialization script in the Auto Scaling group's launch configuration UserData property to reference the password parameter using the Ref intrinsic function. Store the password on the EC2 instances. Reference the parameter for the value of the MasterUserPassword property in the AWS::RDS::DBInstance resource using the Ref intrinsic function.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create a new AWS Secrets Manager secret resource in the CloudFormation template to be used as the database password. Configure the application to retrieve the password from Secrets Manager when needed. Reference the secret resource for the value of the MasterUserPassword property in the AWS::RDS::DBInstance resource using a dynamic reference.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create a new AWS Secrets Manager secret resource in the CloudFormation template to be used as the database password. Create an initialization script in the Auto Scaling group's launch configuration UserData property to reference the secret resource using the Ref intrinsic function. Reference the secret resource for the value of the MasterUserPassword property in the AWS::RDS::DBInstance resource using the Ref intrinsic function.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a new AWS Systems Manager Parameter Store parameter in the CloudFormation template to be used as the database password. Create an initialization script in the Auto Scaling group's launch configuration UserData property to reference the parameter. Reference the parameter for the value of the MasterUserPassword property in the AWS::RDS::DBInstance resource using the Fn::GetAtt intrinsic function.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 156596,
          "date": "Sun 19 Sep 2021 20:14",
          "username": "Nemer",
          "content": "B. <br>https://docs.aws.amazon.com/secretsmanager/latest/userguide/integrating_cloudformation.html",
          "upvote_count": "23",
          "selected_answers": ""
        },
        {
          "id": 603292,
          "date": "Wed 18 May 2022 14:59",
          "username": "bobsmith2000",
          "content": "B no-brainer.<br>RDS creds, rotation - Secret Manager",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 497575,
          "date": "Thu 09 Dec 2021 11:06",
          "username": "cldy",
          "content": "B.  Create a new AWS Secrets Manager secret resource in the CloudFormation template to be used as the database password. Configure the application to retrieve the password from Secrets Manager when needed. Reference the secret resource for the value of the MasterUserPassword property in the AWS::RDS::DBInstance resource using a dynamic reference.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496341,
          "date": "Tue 07 Dec 2021 22:28",
          "username": "AzureDP900",
          "content": "B is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436136,
          "date": "Sat 06 Nov 2021 13:57",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413241,
          "date": "Fri 05 Nov 2021 23:55",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 384147,
          "date": "Wed 03 Nov 2021 09:29",
          "username": "Balki",
          "content": "B. <br>C hardcodes the passwords in the script and the new password will be lost after 60 days",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 357556,
          "date": "Sat 30 Oct 2021 18:55",
          "username": "blackgamer",
          "content": "The solution is B as it is required for password rotation too.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 353673,
          "date": "Mon 25 Oct 2021 13:57",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 342066,
          "date": "Sun 24 Oct 2021 05:11",
          "username": "Amitv2706",
          "content": "B.  For Secret Rotation which is provided only by Secret Manager",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 303233,
          "date": "Sat 23 Oct 2021 07:30",
          "username": "AJBA",
          "content": "Bhttps://aws.amazon.com/blogs/security/how-to-create-and-retrieve-secrets-managed-in-aws-secrets-manager-using-aws-cloudformation-template/#aws-comment-trigger-8922:~:text=The%20secret%20(username%20and%20password%20for,BackupRetentionPeriod%3A%200",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 296564,
          "date": "Fri 22 Oct 2021 13:12",
          "username": "natpilotkirrim",
          "content": "C is correct. good option with Ref function ( https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-secretsmanager-secrettargetattachment.html ) ; for B, Dynamic references for secure values, such as ssm-secure and secretsmanager, are not currently supported;You definitely CAN use a dynamic reference for secretsmanager for an RDS DB password, even with rotation:<br><br>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html<br><br>But I'm not saying you're wrong, it appears from that document you referenced, you definitely CAN do this with the Ref function as well.<br><br>So it appears B and C are both feasible answers.It would come down to which one you think is the better answer.And that might be a matter of personal preference?",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 462125,
          "date": "Sun 07 Nov 2021 16:06",
          "username": "kirrim",
          "content": "You definitely CAN use a dynamic reference for secretsmanager for an RDS DB password, even with rotation:<br><br>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html<br><br>But I'm not saying you're wrong, it appears from that document you referenced, you definitely CAN do this with the Ref function as well.<br><br>So it appears B and C are both feasible answers.It would come down to which one you think is the better answer.And that might be a matter of personal preference?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 292602,
          "date": "Tue 19 Oct 2021 00:20",
          "username": "Kian1",
          "content": "going with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 267650,
          "date": "Mon 18 Oct 2021 19:56",
          "username": "Ebi",
          "content": "Answer is B",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 253871,
          "date": "Sun 17 Oct 2021 06:52",
          "username": "Bulti",
          "content": "Answer is B.  You need to reference secret from secret manager dynamically in the CloudFormation template where the RDS resource is configured. Loading it as part of the userdata script is not secure.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 244749,
          "date": "Sat 16 Oct 2021 21:22",
          "username": "T14102020",
          "content": "Correct is B.  Secrets Manager + dynamic function",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 237663,
          "date": "Mon 11 Oct 2021 13:46",
          "username": "karoth_parulrajjayaraj",
          "content": "B.  Configure CloudTrail in each member account to deliver log events to a central S3 bucket. Ensure the central S3 bucket policy allows PutObject access from the member accounts. Migrate existing logs to the central S3 bucket. Set up an Amazon CloudWatch alarm to alert if CloudTrail is not configured properly.<br><br>C.  Configure an organization-level CloudTrail in the parent account to deliver log events to a central S3 bucket. Migrate the existing CloudTrail logs from each member account to the central S3 bucket. Delete the existing CloudTrail and logs in the member accounts.<br><br>D.  Configure an organization-level CloudTrail in the parent account to deliver log events to a central S3 bucket. Configure CloudTrail in each member account to deliver log events to the central S3 bucket.C - organization-level solution and Existing logs are kept",
          "upvote_count": "13",
          "selected_answers": ""
        },
        {
          "id": 241046,
          "date": "Tue 12 Oct 2021 14:38",
          "username": "arulrajjayaraj",
          "content": "C - organization-level solution and Existing logs are kept",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#605",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company built an application based on AWS Lambda deployed in an AWS CloudFormation stack. The last production release of the web application introduced an issue that resulted in an outage lasting several minutes. A solutions architect must adjust the deployment process to support a canary release.<br>Which solution will meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: A</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#605",
          "answers": [
            {
              "choice": "<p>A. Create an alias for every new deployed version of the Lambda function. Use the AWS CLI update-alias command with the routing-config parameter to distribute the load.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Deploy the application into a new CloudFormation stack. Use an Amazon Route 53 weighted routing policy to distribute the load.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create a version for every new deployed Lambda function. Use the AWS CLI update-function-configuration command with the routing-config parameter to distribute the load.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Configure AWS CodeDeploy and use CodeDeployDefault.OneAtATime in the Deployment configuration to distribute the load.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 156608,
          "date": "Mon 20 Sep 2021 00:41",
          "username": "Nemer",
          "content": "A.  Alias traffic shifting.<br>https://aws.amazon.com/blogs/compute/implementing-canary-deployments-of-aws-lambda-functions-with-alias-traffic-shifting/",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 651711,
          "date": "Thu 25 Aug 2022 10:37",
          "username": "Sumit_Kumar",
          "content": "# Update $LATEST version of function<br>aws lambda update-function-code --function-name myfunction ….<br><br># Publish new version of function<br>aws lambda publish-version --function-name myfunction<br><br># Point alias to new version, weighted at 5% (original version at 95% of traffic)<br>aws lambda update-alias --function-name myfunction --name myalias --routing-config '{\\\"AdditionalVersionWeights\\\" : {\\\"2\\\" : 0.05} }'<br><br># Verify that the new version is healthy<br>…<br># Set the primary version on the alias to the new version and reset the additional versions (100% weighted)<br>aws lambda update-alias --function-name myfunction --name myalias --function-version 2 --routing-config '{}'<br>This is begging to be automate",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 645745,
          "date": "Fri 12 Aug 2022 07:17",
          "username": "Jughead",
          "content": "A is the answer",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 602177,
          "date": "Sun 15 May 2022 18:03",
          "username": "bobsmith2000",
          "content": "NONE of them is correct.<br>B and D are nonsense.<br>B - there's no point to deploy a new Lambda every time and edit rte<br>D - Look it up here. https://docs.amazonaws.cn/en_us/codedeploy/latest/userguide/deployment-configurations.html<br><br>Between A and C. <br>A is wrong because \\\"Create an alias for every new deployed version\\\". The alias it's the same, the weight between the versions for the alias it's different. You point out to the alias and then operate with version.<br>C it's wrong because you have to use update-alias instead of update-function-configuration.<br><br>So it's either A and C phrasing is messed up or none of them is correct.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 496649,
          "date": "Wed 08 Dec 2021 09:34",
          "username": "cldy",
          "content": "A.  Create an alias for every new deployed version of the Lambda function. Use the AWS CLI update-alias command with the routing-config parameter to distribute the load.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491095,
          "date": "Wed 01 Dec 2021 01:41",
          "username": "AzureDP900",
          "content": "Correct Answer A.  there is no second thoughts also!",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436137,
          "date": "Sun 07 Nov 2021 08:34",
          "username": "tgv",
          "content": "AAA<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413242,
          "date": "Fri 29 Oct 2021 15:23",
          "username": "WhyIronMan",
          "content": "I'll go with A",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357664,
          "date": "Wed 27 Oct 2021 17:10",
          "username": "blackgamer",
          "content": "A is the answer. Refer below link for details explanation on how Lambda Alias works.<br><br>https://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 353675,
          "date": "Tue 26 Oct 2021 09:58",
          "username": "Waiweng",
          "content": "it's A",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 292605,
          "date": "Sat 23 Oct 2021 08:45",
          "username": "Kian1",
          "content": "going with A",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 290072,
          "date": "Wed 20 Oct 2021 06:05",
          "username": "lechuk",
          "content": "Maybe a Typo but it's not need to create an ALIAS for every every function deployment...",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 267657,
          "date": "Tue 19 Oct 2021 21:18",
          "username": "Ebi",
          "content": "A is my answer",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 253875,
          "date": "Sun 17 Oct 2021 18:15",
          "username": "Bulti",
          "content": "A is the correct option for Serverless.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 244754,
          "date": "Fri 15 Oct 2021 23:41",
          "username": "T14102020",
          "content": "Correct is A . Update alias traffic",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 232428,
          "date": "Thu 14 Oct 2021 08:57",
          "username": "jackdryan",
          "content": "I'll go with A",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 208556,
          "date": "Tue 12 Oct 2021 09:12",
          "username": "CYL",
          "content": "A.  Use alias to switch traffic.",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#606",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A manufacturing company is growing exponentially and has secured funding to improve its IT infrastructure and ecommerce presence. The company's ecommerce platform consists of:<br>✑ Static assets primarily comprised of product images stored in Amazon S3.<br>✑ Amazon DynamoDB tables that store product information, user information, and order information.<br>✑ Web servers containing the application's front-end behind Elastic Load Balancers.<br>The company wants to set up a disaster recovery site in a separate Region.<br>Which combination of actions should the solutions architect take to implement the new design while meeting all the requirements? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: ABD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#606",
          "answers": [
            {
              "choice": "<p>A. Enable Amazon Route 53 health checks to determine if the primary site is down, and route traffic to the disaster recovery site if there is an issue.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Enable Amazon S3 cross-Region replication on the buckets that contain static assets.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Enable multi-Region targets on the Elastic Load Balancer and target Amazon EC2 instances in both Regions.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Enable DynamoDB global tables to achieve a multi-Region table replication.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Enable Amazon CloudWatch and create CloudWatch alarms that route traffic to the disaster recovery site when application latency exceeds the desired threshold.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>F. Enable Amazon S3 versioning on the source and destination buckets containing static assets to ensure there is a rollback version available in the event of data corruption.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 156800,
          "date": "Fri 24 Sep 2021 20:33",
          "username": "Konnon",
          "content": "The answer is ABD. ",
          "upvote_count": "27",
          "selected_answers": ""
        },
        {
          "id": 156921,
          "date": "Sat 25 Sep 2021 19:22",
          "username": "Nemer",
          "content": "ABD is right. <br> Route 53 + S3 CRR + DynDB global tables.",
          "upvote_count": "15",
          "selected_answers": ""
        },
        {
          "id": 673796,
          "date": "Tue 20 Sep 2022 06:49",
          "username": "sodasusodasuCal88",
          "content": "why not E ?BD is right.<br> <br>i wanna know how about E? <br>Thanks!The first issue with E is that its based on latency.<br>Second , cloud watch alarms don't just switch traffic and they need to trigger a lambda function to do that which is not mentioned <br>Third , even if lambda was mentionedwhy would you use this option if its supported natively in route 53 without the need to implement this long process <br>Remember that in the professional exam some option could be done technically but you are asked for the *Best option <br>so in this case A is better to do this and more reliable",
          "upvote_count": "111",
          "selected_answers": ""
        },
        {
          "id": 673798,
          "date": "Tue 20 Sep 2022 06:52",
          "username": "sodasuCal88",
          "content": "BD is right.<br> <br>i wanna know how about E? <br>Thanks!The first issue with E is that its based on latency.<br>Second , cloud watch alarms don't just switch traffic and they need to trigger a lambda function to do that which is not mentioned <br>Third , even if lambda was mentionedwhy would you use this option if its supported natively in route 53 without the need to implement this long process <br>Remember that in the professional exam some option could be done technically but you are asked for the *Best option <br>so in this case A is better to do this and more reliable",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 708622,
          "date": "Mon 31 Oct 2022 19:00",
          "username": "Cal88",
          "content": "The first issue with E is that its based on latency.<br>Second , cloud watch alarms don't just switch traffic and they need to trigger a lambda function to do that which is not mentioned <br>Third , even if lambda was mentionedwhy would you use this option if its supported natively in route 53 without the need to implement this long process <br>Remember that in the professional exam some option could be done technically but you are asked for the *Best option <br>so in this case A is better to do this and more reliable",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 619602,
          "date": "Tue 21 Jun 2022 07:23",
          "username": "KiraguJohn",
          "content": "ABD it is",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 580853,
          "date": "Mon 04 Apr 2022 19:06",
          "username": "roka_ua",
          "content": "Vote ABD",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ABD"
        },
        {
          "id": 564884,
          "date": "Thu 10 Mar 2022 17:27",
          "username": "Ni_yot",
          "content": "AB &D for me. Slightly tricky question. But R53 will cover the DR requirement.S3 CRR means there is another copy of the data in another region and Global tables ensure multiple copies of the data in case of site down.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 532772,
          "date": "Wed 26 Jan 2022 11:07",
          "username": "shotty1",
          "content": "it is ABD",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ABD"
        },
        {
          "id": 491100,
          "date": "Wed 01 Dec 2021 01:43",
          "username": "AzureDP900",
          "content": "ABD is correct answer!",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: ABD"
        },
        {
          "id": 448840,
          "date": "Sun 07 Nov 2021 02:16",
          "username": "moon2351",
          "content": "Answer is ADB",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436143,
          "date": "Thu 28 Oct 2021 15:18",
          "username": "tgv",
          "content": "AAA BBB DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413244,
          "date": "Wed 27 Oct 2021 11:09",
          "username": "WhyIronMan",
          "content": "I'll go with A,B,D",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 357669,
          "date": "Sat 23 Oct 2021 22:25",
          "username": "blackgamer",
          "content": "The answer is ABD for sure.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 351859,
          "date": "Tue 19 Oct 2021 16:49",
          "username": "Waiweng",
          "content": "it's ABD",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 268808,
          "date": "Tue 19 Oct 2021 05:15",
          "username": "Justu",
          "content": "ABD, seems right but it doesn't fully answer the question: \\\"Which combination of actions, while meeting all the requirements?\\\" as it's not stating anything about the application layer.<br><br>However, another picks are not correct either. So I would answer ABD :D<br><br>C: There's no multi-region targets in ELB.  However you can load balance traffic with the IP addresses, so you could do it.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 267661,
          "date": "Sun 17 Oct 2021 06:53",
          "username": "Ebi",
          "content": "ABD is my answer",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 253882,
          "date": "Mon 11 Oct 2021 17:15",
          "username": "Bultistudent22Bulti",
          "content": "It's not clear if versioning is enabled on S3 buckets in source and destination region. Without that CRR will not work. So I will go with A,D, F.  Static content will not change. So no need to sync up but in case someone deletes it or gets corrupted you can go to the previous version.A,B,D<br>Not F because the requirement is for a DR site.On second thought I will go with ABD.  B is correct and F is wrong because if cross region replication is enabled then versioning is enabled as well without which cross region replication is not possible.",
          "upvote_count": "212",
          "selected_answers": ""
        },
        {
          "id": 437496,
          "date": "Sat 06 Nov 2021 18:15",
          "username": "student22",
          "content": "A,B,D<br>Not F because the requirement is for a DR site.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 258751,
          "date": "Fri 15 Oct 2021 00:51",
          "username": "Bulti",
          "content": "On second thought I will go with ABD.  B is correct and F is wrong because if cross region replication is enabled then versioning is enabled as well without which cross region replication is not possible.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 244759,
          "date": "Mon 11 Oct 2021 15:20",
          "username": "T14102020",
          "content": "Correct is ABD.  Route 53 + S3 CRR + DynDB global tables.",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#607",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is developing a gene reporting device that will collect genomic information to assist researchers will collecting large samples of data from a diverse population. The device will push 8 KB of genomic data every second to a data platform that will need to process and analyze the data and provide information back to researchers. The data platform must meet the following requirements:<br>✑ Provide near-real-time analytics of the inbound genomic data<br>✑ Ensure the data is flexible, parallel, and durable<br>✑ Deliver results of processing to a data warehouse<br>Which strategy should a solutions architect use to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#607",
          "answers": [
            {
              "choice": "<p>A. Use Amazon Kinesis Data Firehouse to collect the inbound sensor data, analyze the data with Kinesis clients, and save the results to an Amazon RDS instance.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use Amazon Kinesis Data Streams to collect the inbound sensor data, analyze the data with Kinesis clients, and save the results to an Amazon Redshift cluster using Amazon EMR.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use Amazon S3 to collect the inbound device data, analyze the data from Amazon SQS with Kinesis, and save the results to an Amazon Redshift cluster.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use an Amazon API Gateway to put requests into an Amazon SQS queue, analyze the data with an AWS Lambda function, and save the results to an Amazon Redshift cluster using Amazon EMR.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 156926,
          "date": "Tue 21 Sep 2021 05:56",
          "username": "Nemer",
          "content": "B is right.Kinesis streams / EMR / Redshift.",
          "upvote_count": "23",
          "selected_answers": ""
        },
        {
          "id": 268574,
          "date": "Thu 21 Oct 2021 16:33",
          "username": "Ebi",
          "content": "I will go with B",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 713618,
          "date": "Tue 08 Nov 2022 10:01",
          "username": "Heer",
          "content": "Near real time =Kinesis Streams<br>Dataware house:Redshift",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 689114,
          "date": "Sat 08 Oct 2022 09:40",
          "username": "WayneYi",
          "content": "I chose A, but then I noticed that it is sending results to RDS, oops!",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 650945,
          "date": "Tue 23 Aug 2022 20:16",
          "username": "Ni_yot",
          "content": "B is correct ans. like this one",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 537618,
          "date": "Tue 01 Feb 2022 04:24",
          "username": "HellGate",
          "content": "B<br>real-time requirement = Kinesis",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491103,
          "date": "Wed 01 Dec 2021 01:48",
          "username": "AzureDP900",
          "content": "B for sure !",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 479582,
          "date": "Tue 16 Nov 2021 19:56",
          "username": "Kopa",
          "content": "Ascertain that the data is adaptable, parallel, and durable is very tempting to S3, but most probably its B with Kinesis",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436147,
          "date": "Sat 06 Nov 2021 10:42",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413245,
          "date": "Tue 02 Nov 2021 05:18",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 404195,
          "date": "Wed 27 Oct 2021 13:45",
          "username": "KittuCheeku",
          "content": "B is the correct answer as it is best suited amongst 4 given options. KDS (Analytics) + Redshift (Data Warehouse) + Using Elastic MapReduce",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 351861,
          "date": "Mon 25 Oct 2021 16:02",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 349064,
          "date": "Mon 25 Oct 2021 05:57",
          "username": "digimaniacTonyGe",
          "content": "I think C is correct too. B is an overkill. 8KB per second is really low data rate.near-real-time, always think of Kinesis",
          "upvote_count": "12",
          "selected_answers": ""
        },
        {
          "id": 371420,
          "date": "Wed 27 Oct 2021 01:44",
          "username": "TonyGe",
          "content": "near-real-time, always think of Kinesis",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 253892,
          "date": "Thu 14 Oct 2021 10:06",
          "username": "Bulti",
          "content": "answer is B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 244764,
          "date": "Fri 08 Oct 2021 20:23",
          "username": "T14102020",
          "content": "Correct is D.  Kinesis data streams + EMR + Redshift.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 232456,
          "date": "Fri 08 Oct 2021 08:31",
          "username": "jackdryan",
          "content": "I'll go with B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 208564,
          "date": "Wed 29 Sep 2021 14:53",
          "username": "CYL",
          "content": "B.  Redshift is the data-warehouse. EMR to do the data transformation. Kinesis for real-time data transfer.",
          "upvote_count": "4",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#608",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company needs to move its on-premises resources to AWS. The current environment consists of 100 virtual machines (VMs) with a total of 40 TB of storage.<br>Most of the VMs can be taken offline because they support functions during business hours only, however, some are mission critical, so downtime must be minimized.<br>The administrator of the on-premises network provisioned 10 Mbps of internet bandwidth for the migration. The on-premises network throughput has reached capacity and would be costly to increase. A solutions architect must design a migration solution that can be performed within the next 3 months.<br>Which method would fulfill these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: D</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#608",
          "answers": [
            {
              "choice": "<p>A. Set up a 1 Gbps AWS Direct Connect connection. Then, provision a private virtual interface, and use AWS Server Migration Service (SMS) to migrate the VMs into Amazon EC2.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use AWS Application Discovery Service to assess each application, and determine how to refactor and optimize each using AWS services or AWS Marketplace solutions.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Export the VMs locally, beginning with the most mission-critical servers first. Use AWS Transfer for SFTP to securely upload each VM to Amazon S3 after they are exported. Use VM Import/Export to import the VMs into Amazon EC2.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Migrate mission-critical VMs with AWS SMS. Export the other VMs locally and transfer them to Amazon S3 using AWS Snowball. Use VM Import/Export to import the VMs into Amazon EC2.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 156950,
          "date": "Mon 20 Sep 2021 10:44",
          "username": "Nemer",
          "content": "D. 40 TB transfer -> snowball. SMS only needed for the mission-critical VMs that would need live incremental replication with no downtime.",
          "upvote_count": "25",
          "selected_answers": ""
        },
        {
          "id": 268821,
          "date": "Sun 17 Oct 2021 23:08",
          "username": "Justu",
          "content": "To transfer 40TB of data in 10Mbps link, it will take 400 days. So transferring anything over that link in 3 months is not feasible. Rules C out. <br><br>Direct Connect link is needed only while migration period. So ordering that for just 3 months doesn't seem correct. Also it's a costly option. Rules out A. <br><br>And refactoring 100 applications in 3 months, doesn't sound right to me as well. Rules out B. <br><br>So left will be D.  Problem with D is that Snowball transfer also takes some time, but I guess it's OK for non critical systems to be down for week. If we can use the on-prem servers while setupping AWS instances and then transfer only the delta of data, the downtime then will be minimized.",
          "upvote_count": "10",
          "selected_answers": ""
        },
        {
          "id": 638363,
          "date": "Thu 28 Jul 2022 02:07",
          "username": "hilft",
          "content": "snowball. other options will take forever.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 540370,
          "date": "Fri 04 Feb 2022 12:05",
          "username": "kyo",
          "content": "AWS Server Migration Service is better than VM I/E. ",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 514373,
          "date": "Sat 01 Jan 2022 06:09",
          "username": "cldy",
          "content": "D correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496346,
          "date": "Tue 07 Dec 2021 22:51",
          "username": "AzureDP900",
          "content": "D is right answer. A is not correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435743,
          "date": "Wed 03 Nov 2021 21:12",
          "username": "tgv",
          "content": "DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 428964,
          "date": "Mon 01 Nov 2021 11:49",
          "username": "levy_kViper57",
          "content": "I will go with A, firstly, there is no concern about the cost in the topic. customer's purpose is to migrate all service and data to aws in 3 months without any affect for end user.<br>For D, with snowball, the service and old data can be migrate to aws in weeks, but how to process the datas generated during the weeks? only 10Mb network obviously is not the correct solution. Customer sholud find a solution to keep the data consistent.You did not read the question. \\\" The on-premises network throughput has reached capacity and would be costly to increase. Cost is a concern, so a 1 Gbps Direct Connect connection would definitely be too expensive.",
          "upvote_count": "34",
          "selected_answers": ""
        },
        {
          "id": 447144,
          "date": "Fri 05 Nov 2021 16:11",
          "username": "Viper57",
          "content": "You did not read the question. \\\" The on-premises network throughput has reached capacity and would be costly to increase. Cost is a concern, so a 1 Gbps Direct Connect connection would definitely be too expensive.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 415329,
          "date": "Mon 01 Nov 2021 10:30",
          "username": "zolthar_z",
          "content": "I think the solution is D, the key is the cost limitation. There is a reason to put that in the question. The direct connect is the best solution if you don't have a budget problem. With D you can create a copy of the non-essentials VMs, work with the on-premise while the VMs arrive and are deployed in EC2.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 413246,
          "date": "Thu 28 Oct 2021 00:45",
          "username": "WhyIronMan",
          "content": "I'll go with D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 406133,
          "date": "Tue 26 Oct 2021 07:55",
          "username": "Kopa",
          "content": "D, since customer is not willing to make additional cost with direct connect. Also not full 40 TB are to be migrated as some of data will offloaded to Snowball device.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 383022,
          "date": "Mon 25 Oct 2021 18:49",
          "username": "tvs",
          "content": "Should be D . SMS transfer vmdk to s3 which Need public virtual interface over DX. https://aws.amazon.com/blogs/apn/aws-server-migration-service-server-migration-to-the-cloud-made-easy/",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 357676,
          "date": "Mon 25 Oct 2021 10:28",
          "username": "blackgamer",
          "content": "D is the solution.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 351867,
          "date": "Mon 25 Oct 2021 03:10",
          "username": "Waiweng",
          "content": "it's D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 296572,
          "date": "Sun 24 Oct 2021 02:11",
          "username": "natpilot",
          "content": "A for sure, direct connect can be establiched in 1 month and is more indicated for critical vm migration; for D, after VM import, how is feasible to do the data resync of about 3 days of data with 10Mbps full used?",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 272440,
          "date": "Wed 20 Oct 2021 07:40",
          "username": "elf78",
          "content": "D - Assuming mission critical VMs are migrated using SMS via existing link and others via Snowball. All other options don't sound reasonable.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 268579,
          "date": "Thu 14 Oct 2021 23:08",
          "username": "EbiEbi",
          "content": "A for sure,<br>D is not the option, snowball migration takes weeks while non-critical VMs must be available during business hours.After further review I guess this questions does not have any correct answer:<br>A: Is not correct, as mentioned in other comments, private VIF will work for connecting to VPC not public services like S3<br>B: No sense, it is talking discover not actual migration <br>C: No sense, no needed to have SFTP<br>D: Transferring VMs using Snowball will take weeks while as per question non-critical application are used during business hours <br><br>Very bad question",
          "upvote_count": "64",
          "selected_answers": ""
        },
        {
          "id": 285391,
          "date": "Wed 20 Oct 2021 09:52",
          "username": "Ebi",
          "content": "After further review I guess this questions does not have any correct answer:<br>A: Is not correct, as mentioned in other comments, private VIF will work for connecting to VPC not public services like S3<br>B: No sense, it is talking discover not actual migration <br>C: No sense, no needed to have SFTP<br>D: Transferring VMs using Snowball will take weeks while as per question non-critical application are used during business hours <br><br>Very bad question",
          "upvote_count": "4",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#609",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company runs a popular public-facing ecommerce website. Its user base is growing quickly from a local market to a national market. The website is hosted in an on-premises data center with web servers and a MySQL database. The company wants to migrate its workload to AWS. A solutions architect needs to create a solution to:<br>✑ Improve security<br>✑ Improve reliability<br>✑ Improve availability<br>✑ Reduce latency<br>✑ Reduce maintenance<br>Which combination of steps should the solutions architect take to meet these requirements? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: ABE</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#609",
          "answers": [
            {
              "choice": "<p>A. Use Amazon EC2 instances in two Availability Zones for the web servers in an Auto Scaling group behind an Application Load Balancer.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Migrate the database to a Multi-AZ Amazon Aurora MySQL DB cluster.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use Amazon EC2 instances in two Availability Zones to host a highly available MySQL database cluster.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Host static website content in Amazon S3. Use S3 Transfer Acceleration to reduce latency while serving webpages. Use AWS WAF to improve website security.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>E. Host static website content in Amazon S3. Use Amazon CloudFront to reduce latency while serving webpages. Use AWS WAF to improve website security.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>F. Migrate the database to a single-AZ Amazon RDS for MySQL DB instance.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 156966,
          "date": "Wed 22 Sep 2021 14:05",
          "username": "Nemersam422",
          "content": "ABE.  <br>Excluding: C does not reduce maintenance (MySQL IaaS),we need CloudFront for WAF (D is out), and F is not HA. C doesn't qualify for reduce maintenance",
          "upvote_count": "391",
          "selected_answers": ""
        },
        {
          "id": 185698,
          "date": "Sun 26 Sep 2021 19:02",
          "username": "sam422",
          "content": "C doesn't qualify for reduce maintenance",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 157902,
          "date": "Sun 26 Sep 2021 08:13",
          "username": "Anila_Dhharisi",
          "content": "yes its ABE. ",
          "upvote_count": "8",
          "selected_answers": ""
        },
        {
          "id": 636793,
          "date": "Mon 25 Jul 2022 17:39",
          "username": "hilft",
          "content": "ABE straight forward",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 627291,
          "date": "Tue 05 Jul 2022 08:22",
          "username": "TechX",
          "content": "It's ABE",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: ABE"
        },
        {
          "id": 626425,
          "date": "Sun 03 Jul 2022 07:29",
          "username": "aandc",
          "content": "easy one",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: ABE"
        },
        {
          "id": 586289,
          "date": "Fri 15 Apr 2022 12:52",
          "username": "tartarus23",
          "content": "A.  high availability and performance for the web servers since they are multi-AZ, auto-scaled and load balanced.<br>B.  database are multi az and shifted to auroa db cluster so it is reliable and scalable<br>E.  static website content in S3 and cached in Cloudfront reduces latency . WAF increases security.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: ABE"
        },
        {
          "id": 558335,
          "date": "Mon 28 Feb 2022 21:40",
          "username": "Ni_yot",
          "content": "ABE for me.With this option, the web app and DB are highly available. And the latency and security is covered with the E answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 533736,
          "date": "Thu 27 Jan 2022 13:35",
          "username": "zoliv",
          "content": "ABE for sure!",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ABE"
        },
        {
          "id": 522064,
          "date": "Wed 12 Jan 2022 12:03",
          "username": "pititcu667",
          "content": "This is my choice.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ABE"
        },
        {
          "id": 497371,
          "date": "Thu 09 Dec 2021 07:06",
          "username": "weequanchallenger1",
          "content": "A need maintenence<br>C need maintenence<br>F not reliabilityNo..... ABE",
          "upvote_count": "11",
          "selected_answers": "Selected Answer: BDE"
        },
        {
          "id": 504487,
          "date": "Sat 18 Dec 2021 23:12",
          "username": "challenger1",
          "content": "No..... ABE",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 497368,
          "date": "Thu 09 Dec 2021 07:04",
          "username": "weequan",
          "content": "A need maintenence<br>C is not meet with reliability<br>F not reliability",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BDE"
        },
        {
          "id": 491106,
          "date": "Wed 01 Dec 2021 02:00",
          "username": "AzureDP900",
          "content": "ABE is right answer!",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: ABE"
        },
        {
          "id": 491105,
          "date": "Wed 01 Dec 2021 01:59",
          "username": "AzureDP900",
          "content": "I will go with ABE !",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436151,
          "date": "Tue 02 Nov 2021 23:01",
          "username": "tgv",
          "content": "AAA BBB EEE<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413248,
          "date": "Mon 01 Nov 2021 19:00",
          "username": "WhyIronMan",
          "content": "I'll go with A,B,E",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 357859,
          "date": "Sun 31 Oct 2021 05:57",
          "username": "blackgamer",
          "content": "ABE for sure.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 351870,
          "date": "Fri 29 Oct 2021 00:24",
          "username": "Waiweng",
          "content": "it's ABE",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#610",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has an internal application running on AWS that is used to track and process shipments in the company's warehouse. Currently, after the system receives an order, it emails the staff the information needed to ship a package. Once the package is shipped, the staff replies to the email and the order is marked as shipped.<br>The company wants to stop using email in the application and move to a serverless application model.<br>Which architecture solution meets these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#610",
          "answers": [
            {
              "choice": "<p>A. Use AWS Batch to configure the different tasks required to ship a package. Have AWS Batch trigger an AWS Lambda function that creates and prints a shipping label. Once that label is scanned, as it leaves the warehouse, have another Lambda function move the process to the next step in the AWS Batch job.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. When a new order is created, store the order information in Amazon SQS. Have AWS Lambda check the queue every 5 minutes and process any needed work. When an order needs to be shipped, have Lambda print the label in the warehouse. Once the label has been scanned, as it leaves the warehouse, have an Amazon EC2 instance update Amazon SQS.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Update the application to store new order information in Amazon DynamoDB.  When a new order is created, trigger an AWS Step Functions workflow, mark the orders as ג€in progressג€, and print a package label to the warehouse. Once the label has been scanned and fulfilled, the application will trigger an AWS Lambda function that will mark the order as shipped and complete the workflow.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Store new order information in Amazon EFS. Have instances pull the new information from the NFS and send that information to printers in the warehouse. Once the label has been scanned, as it leaves the warehouse, have Amazon API Gateway call the instances to remove the order information from Amazon EFS.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 156804,
          "date": "Mon 20 Sep 2021 03:49",
          "username": "Konnonjoe16",
          "content": "I go for C.  Use DynamoDB Streams to trigger lambda then trigger step function.Yes.<br>AWS Batch is ruled out as it supports only EC2/Fargate based compute not lambdas.",
          "upvote_count": "182",
          "selected_answers": ""
        },
        {
          "id": 456233,
          "date": "Sun 07 Nov 2021 04:44",
          "username": "joe16",
          "content": "Yes.<br>AWS Batch is ruled out as it supports only EC2/Fargate based compute not lambdas.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 156975,
          "date": "Tue 21 Sep 2021 16:24",
          "username": "Nemer",
          "content": "C.  Step functions Standard for order fulfillment.",
          "upvote_count": "10",
          "selected_answers": ""
        },
        {
          "id": 524437,
          "date": "Sat 15 Jan 2022 22:14",
          "username": "pititcu667",
          "content": "c because step functions can be used to handle the steps. workflow service would have been better but yeah.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 499267,
          "date": "Sat 11 Dec 2021 10:27",
          "username": "cldy",
          "content": "C.  Update the application to store new order information in Amazon DynamoDB.  When a new order is created, trigger an AWS Step Functions workflow, mark the orders as ג€in progressג€, and print a package label to the warehouse. Once the label has been scanned and fulfilled, the application will trigger an AWS Lambda function that will mark the order as shipped and complete the workflow.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491118,
          "date": "Wed 01 Dec 2021 02:26",
          "username": "AzureDP900",
          "content": "C is right answer!",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 490359,
          "date": "Tue 30 Nov 2021 03:48",
          "username": "acloudguru",
          "content": "A does not make any sense. C should be the serverless and control whole process solution.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 437510,
          "date": "Wed 27 Oct 2021 11:56",
          "username": "student22",
          "content": "C<br>Step functions",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436154,
          "date": "Mon 25 Oct 2021 14:21",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435707,
          "date": "Thu 21 Oct 2021 16:45",
          "username": "blackgamer",
          "content": "The answer is C. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413250,
          "date": "Wed 20 Oct 2021 13:52",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 406135,
          "date": "Tue 19 Oct 2021 02:11",
          "username": "Kopa",
          "content": "C, Typical DynamoDB and AWS Step Functions usage",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357656,
          "date": "Mon 18 Oct 2021 00:41",
          "username": "ladhpradhyumna",
          "content": "Why not b?Because EC2 instance is part of the solution which does not fit the requirement of serverless",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 367888,
          "date": "Mon 18 Oct 2021 23:18",
          "username": "pradhyumna",
          "content": "Because EC2 instance is part of the solution which does not fit the requirement of serverless",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 351874,
          "date": "Fri 15 Oct 2021 06:21",
          "username": "Waiweng",
          "content": "it's C",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 334084,
          "date": "Tue 12 Oct 2021 05:21",
          "username": "KnightVictor",
          "content": "Answer is C.  keywords like \\\"human intervention\\\", workflow an be changed by step functions",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 268584,
          "date": "Mon 11 Oct 2021 07:29",
          "username": "Ebi",
          "content": "Answer is C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 254877,
          "date": "Sat 09 Oct 2021 10:29",
          "username": "petebear55",
          "content": "A: is not Serverless .. ans is C ... wish they would stop putting wrong answers in the answe r box",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 253899,
          "date": "Thu 07 Oct 2021 18:53",
          "username": "Bulti",
          "content": "Answer is C",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#611",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has developed a mobile game. The backend for the game runs on several virtual machines located in an on-premises data center. The business logic is exposed using a REST API with multiple functions. Player session data is stored in central file storage. Backend services use different API keys for throttling and to distinguish between live and test traffic.<br>The load on the game backend varies throughout the day. During peak hours, the server capacity is not sufficient. There are also latency issues when fetching player session data. Management has asked a solutions architect to present a cloud architecture that can handle the game's varying load and provide low-latency data access. The API model should not be changed.<br>Which solution meets these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#611",
          "answers": [
            {
              "choice": "<p>A. Implement the REST API using a Network Load Balancer (NLB). Run the business logic on an Amazon EC2 instance behind the NLB.  Store player session data in Amazon Aurora Serverless.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Implement the REST API using an Application Load Balancer (ALB). Run the business logic in AWS Lambda. Store player session data in Amazon DynamoDB with on-demand capacity.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Implement the REST API using Amazon API Gateway. Run the business logic in AWS Lambda. Store player session data in Amazon DynamoDB with on- demand capacity.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Implement the REST API using AWS AppSync. Run the business logic in AWS Lambda. Store player session data in Amazon Aurora Serverless.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 156986,
          "date": "Mon 20 Sep 2021 07:35",
          "username": "Nemer",
          "content": "C.  Api Gateway . DynamoDB typical gaming use case.<br>https://aws.amazon.com/blogs/database/amazon-dynamodb-gaming-use-cases-and-design-patterns/",
          "upvote_count": "23",
          "selected_answers": ""
        },
        {
          "id": 647724,
          "date": "Tue 16 Aug 2022 17:16",
          "username": "Ni_yot",
          "content": "C is good",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 524969,
          "date": "Sun 16 Jan 2022 14:39",
          "username": "pititcu667",
          "content": "c -> api lambda dynamo classic use case",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 493449,
          "date": "Sat 04 Dec 2021 02:32",
          "username": "vbal",
          "content": "Answer shld be B based upon API model cant be changed as both ALB & API Gateway have similar capabilities...https://dashbird.io/blog/aws-api-gateway-vs-application-load-balancer/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491122,
          "date": "Wed 01 Dec 2021 02:31",
          "username": "AzureDP900",
          "content": "C is perfect answer for this use case!",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 443233,
          "date": "Wed 03 Nov 2021 21:15",
          "username": "andylogan",
          "content": "It's C, typical use-case",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436156,
          "date": "Sun 31 Oct 2021 21:36",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413256,
          "date": "Fri 29 Oct 2021 17:57",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 358672,
          "date": "Fri 29 Oct 2021 01:49",
          "username": "blackgamer",
          "content": "C is the answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 353682,
          "date": "Sat 23 Oct 2021 01:46",
          "username": "Waiweng",
          "content": "it;s C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 344768,
          "date": "Sat 16 Oct 2021 19:37",
          "username": "gsw",
          "content": "always avoid making radical changes to the architecture unless the question specifies it",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 321745,
          "date": "Sat 09 Oct 2021 17:23",
          "username": "alisyech",
          "content": "C for sure",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 300612,
          "date": "Fri 08 Oct 2021 05:02",
          "username": "certainly",
          "content": "B would work. API gateway limit 10,000 Req. per Sec. while ALB doesn't have limit, hence it scale better",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 268585,
          "date": "Sat 02 Oct 2021 20:09",
          "username": "Ebi",
          "content": "I will with C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 266365,
          "date": "Tue 28 Sep 2021 01:02",
          "username": "01037",
          "content": "C is the best option here, but it needs lots of work.<br>Without anymore requirement, C is the answer.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 253903,
          "date": "Mon 27 Sep 2021 16:56",
          "username": "Bulti",
          "content": "C is the correct answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 244779,
          "date": "Mon 27 Sep 2021 00:02",
          "username": "T14102020",
          "content": "Correct is C.  API Gateway + Lambda + Dynamo",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#612",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>An enterprise company wants to allow its developers to purchase third-party software through AWS Marketplace. The company uses an AWS Organizations account structure with full features enabled, and has a shared services account in each organizational unit (OU) that will be used by procurement managers. The procurement team's policy indicates that developers should be able to obtain third-party software from an approved list only and use Private Marketplace in AWS<br>Marketplace to achieve this requirement. The procurement team wants administration of Private Marketplace to be restricted to a role named procurement- manager-role, which could be assumed by procurement managers. Other IAM users, groups, roles, and account administrators in the company should be denied<br>Private Marketplace administrative access.<br>What is the MOST efficient way to design an architecture to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#612",
          "answers": [
            {
              "choice": "<p>A. Create an IAM role named procurement-manager-role in all AWS accounts in the organization. Add the PowerUserAccess managed policy to the role. Apply an inline policy to all IAM users and roles in every AWS account to deny permissions on the AWSPrivateMarketplaceAdminFullAccess managed policy.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an IAM role named procurement-manager-role in all AWS accounts in the organization. Add the AdministratorAccess managed policy to the role. Define a permissions boundary with the AWSPrivateMarketplaceAdminFullAccess managed policy and attach it to all the developer roles.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create an IAM role named procurement-manager-role in all the shared services accounts in the organization. Add the AWSPrivateMarketplaceAdminFullAccess managed policy to the role. Create an organization root-level SCP to deny permissions to administer Private Marketplace to everyone except the role named procurement-manager-role. Create another organization root-level SCP to deny permissions to create an IAM role named procurement-manager-role to everyone in the organization.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create an IAM role named procurement-manager-role in all AWS accounts that will be used by developers. Add the AWSPrivateMarketplaceAdminFullAccess managed policy to the role. Create an SCP in Organizations to deny permissions to administer Private Marketplace to everyone except the role named procurement-manager-role. Apply the SCP to all the shared services accounts in the organization.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 157018,
          "date": "Mon 20 Sep 2021 00:37",
          "username": "NemerGladabhiNemerjoe16KelvinshammousRedKanestudent22",
          "content": "C. SCP to deny permissions to administer Private Marketplace to everyone except the role named procurement-manager-role.<br><br>https://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/I will go with C as Procurement manager need access from shared account. We don't want any other account have the proc-mag-role as goes with least permission principle.Changed to D. In C, there is the issue of ROOT-level SCP to deny permissions to create an IAM role named procurement-manager-role to EVERYONE in the organization..D is wrong. Developers should not have the procurement-manager-role.<br>\\\"...restricted to a role named procurement- manager-role, which could be assumed by procurement managers\\\"Yes, D looks correct.The issue is not with the word \\\"EVERYONE\\\", but with the entire useless statement: \\\"Create another organization root-level SCP to deny permissions to create an IAM role named procurement-manager-role to everyone in the organization.\\\": First, this could be done in the first SCP, second, denying permissions to create an IAM role named procurement-manager-role doesn't change anything.Without second SCP users/roles in other accounts that have full IAM access could create role with this name \\\"procurement-manager-role\\\" and assign any permission they want - since first SCP explicitly excludes \\\"procurement-manager-role\\\" from the DENY that would allow bypassing intended design of security rules.Good explanation. <br>C makes sense.",
          "upvote_count": "193931161",
          "selected_answers": ""
        },
        {
          "id": 400249,
          "date": "Mon 01 Nov 2021 09:11",
          "username": "Gladabhi",
          "content": "I will go with C as Procurement manager need access from shared account. We don't want any other account have the proc-mag-role as goes with least permission principle.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 163625,
          "date": "Mon 27 Sep 2021 23:45",
          "username": "Nemerjoe16KelvinshammousRedKanestudent22",
          "content": "Changed to D. In C, there is the issue of ROOT-level SCP to deny permissions to create an IAM role named procurement-manager-role to EVERYONE in the organization..D is wrong. Developers should not have the procurement-manager-role.<br>\\\"...restricted to a role named procurement- manager-role, which could be assumed by procurement managers\\\"Yes, D looks correct.The issue is not with the word \\\"EVERYONE\\\", but with the entire useless statement: \\\"Create another organization root-level SCP to deny permissions to create an IAM role named procurement-manager-role to everyone in the organization.\\\": First, this could be done in the first SCP, second, denying permissions to create an IAM role named procurement-manager-role doesn't change anything.Without second SCP users/roles in other accounts that have full IAM access could create role with this name \\\"procurement-manager-role\\\" and assign any permission they want - since first SCP explicitly excludes \\\"procurement-manager-role\\\" from the DENY that would allow bypassing intended design of security rules.Good explanation. <br>C makes sense.",
          "upvote_count": "931161",
          "selected_answers": ""
        },
        {
          "id": 456235,
          "date": "Sun 07 Nov 2021 15:32",
          "username": "joe16",
          "content": "D is wrong. Developers should not have the procurement-manager-role.<br>\\\"...restricted to a role named procurement- manager-role, which could be assumed by procurement managers\\\"",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 338885,
          "date": "Mon 25 Oct 2021 01:59",
          "username": "Kelvin",
          "content": "Yes, D looks correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 277769,
          "date": "Sun 17 Oct 2021 13:41",
          "username": "shammousRedKanestudent22",
          "content": "The issue is not with the word \\\"EVERYONE\\\", but with the entire useless statement: \\\"Create another organization root-level SCP to deny permissions to create an IAM role named procurement-manager-role to everyone in the organization.\\\": First, this could be done in the first SCP, second, denying permissions to create an IAM role named procurement-manager-role doesn't change anything.Without second SCP users/roles in other accounts that have full IAM access could create role with this name \\\"procurement-manager-role\\\" and assign any permission they want - since first SCP explicitly excludes \\\"procurement-manager-role\\\" from the DENY that would allow bypassing intended design of security rules.Good explanation. <br>C makes sense.",
          "upvote_count": "161",
          "selected_answers": ""
        },
        {
          "id": 330177,
          "date": "Wed 20 Oct 2021 05:47",
          "username": "RedKanestudent22",
          "content": "Without second SCP users/roles in other accounts that have full IAM access could create role with this name \\\"procurement-manager-role\\\" and assign any permission they want - since first SCP explicitly excludes \\\"procurement-manager-role\\\" from the DENY that would allow bypassing intended design of security rules.Good explanation. <br>C makes sense.",
          "upvote_count": "61",
          "selected_answers": ""
        },
        {
          "id": 458431,
          "date": "Sun 07 Nov 2021 16:13",
          "username": "student22",
          "content": "Good explanation. <br>C makes sense.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413258,
          "date": "Tue 02 Nov 2021 03:13",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 735505,
          "date": "Sun 04 Dec 2022 23:54",
          "username": "SureNot",
          "content": "D is wrong. You can apply SCP to OUs, not accounts",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 676272,
          "date": "Thu 22 Sep 2022 16:55",
          "username": "dcdcdc3Rahu",
          "content": "per the link provided below<br>https://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/<br><br>and per this paragraph within that link<br>\\\"As an additional control, I applied an SCP to all the organizational units in this example organization to restrict Private Marketplace administration access to an IAM role called procurement-manager. This guardrail prevents other IAM roles, users, or groups from accessing the Private Marketplace administration page, even administrators in any of these organizational units’ accounts.\\\"<br><br>I would choose DBut here the question also says \\\"Other IAM users, groups, roles, and account administrators in the company should be denied Private Marketplace administrative access\\\". That means Answer C only matches your point.",
          "upvote_count": "21",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 695062,
          "date": "Sat 15 Oct 2022 02:04",
          "username": "Rahu",
          "content": "But here the question also says \\\"Other IAM users, groups, roles, and account administrators in the company should be denied Private Marketplace administrative access\\\". That means Answer C only matches your point.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 637723,
          "date": "Wed 27 Jul 2022 03:27",
          "username": "hilft",
          "content": "D.  not C<br>never root level SCP",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 542755,
          "date": "Tue 08 Feb 2022 00:17",
          "username": "jj22222",
          "content": "C looks right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 530852,
          "date": "Sun 23 Jan 2022 23:01",
          "username": "AMKazi",
          "content": "Answer should be B.  - meets both requirements of procurement mgmt and dev access<br>C- only solving requirement of procurement manager. What about developer access to use the marketplace?<br>D- giving procurement manager role to Developers",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 513381,
          "date": "Thu 30 Dec 2021 14:11",
          "username": "cldy",
          "content": "C is correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 506909,
          "date": "Wed 22 Dec 2021 10:46",
          "username": "Ni_yot",
          "content": "C for me.The link attached in the write up is worth a read.https://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 499344,
          "date": "Sat 11 Dec 2021 11:50",
          "username": "cldy",
          "content": "C.  Create an IAM role named procurement-manager-role in all the shared services accounts in the organization. Add the AWSPrivateMarketplaceAdminFullAccess managed policy to the role. Create an organization root-level SCP to deny permissions to administer Private Marketplace to everyone except the role named procurement-manager-role. Create another organization root-level SCP to deny permissions to create an IAM role named procurement-manager-role to everyone in the organization.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491128,
          "date": "Wed 01 Dec 2021 02:38",
          "username": "AzureDP900",
          "content": "C is right!<br>https://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 490479,
          "date": "Tue 30 Nov 2021 07:59",
          "username": "acloudguru",
          "content": "C.  SCP to deny permissions to administer Private Marketplace to everyone except the role named procurement-manager-role.<br><br>https://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 443232,
          "date": "Sat 06 Nov 2021 14:46",
          "username": "andylogan",
          "content": "It's C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436163,
          "date": "Sat 06 Nov 2021 01:59",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 358739,
          "date": "Sat 30 Oct 2021 12:36",
          "username": "blackgamerblackgamer",
          "content": "C is the answer. D is wrong as the SCP applying to shared service account which is not being used by developer.Please refer following links for more details why C is correct. <br>https://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 358761,
          "date": "Sat 30 Oct 2021 14:59",
          "username": "blackgamer",
          "content": "Please refer following links for more details why C is correct. <br>https://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 350537,
          "date": "Wed 27 Oct 2021 14:54",
          "username": "beebatov",
          "content": "C is the Answer! D is giving procurement-manager-role to DEVELOPERS!!<br>Although its not the best practice to apply SCP at root level, but C is the most viable answer for me here.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 344020,
          "date": "Mon 25 Oct 2021 08:41",
          "username": "gsw",
          "content": "worth checking the Jon Bonso exams as this question is in one of the exam sets and he gives answer A.  PowerUserAccess is a IAM default user role for developers https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_job-functions.html",
          "upvote_count": "4",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#613",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A solutions architect is designing the data storage and retrieval architecture for a new application that a company will be launching soon. The application is designed to ingest millions of small records per minute from devices all around the world. Each record is less than 4 KB in size and needs to be stored in a durable location where it can be retrieved with low latency. The data is ephemeral and the company is required to store the data for 120 days only, after which the data can be deleted.<br>The solutions architect calculates that, during the course of a year, the storage requirements would be about 10-15 TB. <br>Which storage strategy is the MOST cost-effective and meets the design requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#613",
          "answers": [
            {
              "choice": "<p>A. Design the application to store each incoming record as a single .csv file in an Amazon S3 bucket to allow for indexed retrieval. Configure a lifecycle policy to delete data older than 120 days.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Design the application to store each incoming record in an Amazon DynamoDB table properly configured for the scale. Configure the DynamoDB Time to Live (TTL) feature to delete records older than 120 days.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Design the application to store each incoming record in a single table in an Amazon RDS MySQL database. Run a nightly cron job that executes a query to delete any records older than 120 days.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Design the application to batch incoming records before writing them to an Amazon S3 bucket. Update the metadata for the object to contain the list of records in the batch and use the Amazon S3 metadata search feature to retrieve the data. Configure a lifecycle policy to delete the data after 120 days.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 157061,
          "date": "Tue 21 Sep 2021 05:24",
          "username": "Nemeroscargeesashenka",
          "content": "B.  DynamoDB with TTL, cheaper for sustained throughput of small items + suited for fast retrievals. S3 cheaper for storage only, much higher costs with writes. RDS not designed for this use case.DynamoDB is a Key/Value storage. And it fits big data read/write. So it cannot be used in this situation.Hmmm.... \\\"The program is meant to continuously consume millions of tiny records per minute from devices located around the globe.\\\" If that doesn't say big data read/write than I don't know what is. Also, DynamoDB is perfect for this especially seeing that the 4k value is the limit size.",
          "upvote_count": "3124",
          "selected_answers": ""
        },
        {
          "id": 366344,
          "date": "Tue 26 Oct 2021 10:43",
          "username": "oscargeesashenka",
          "content": "DynamoDB is a Key/Value storage. And it fits big data read/write. So it cannot be used in this situation.Hmmm.... \\\"The program is meant to continuously consume millions of tiny records per minute from devices located around the globe.\\\" If that doesn't say big data read/write than I don't know what is. Also, DynamoDB is perfect for this especially seeing that the 4k value is the limit size.",
          "upvote_count": "24",
          "selected_answers": ""
        },
        {
          "id": 477667,
          "date": "Sat 13 Nov 2021 18:52",
          "username": "sashenka",
          "content": "Hmmm.... \\\"The program is meant to continuously consume millions of tiny records per minute from devices located around the globe.\\\" If that doesn't say big data read/write than I don't know what is. Also, DynamoDB is perfect for this especially seeing that the 4k value is the limit size.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 540780,
          "date": "Sat 05 Feb 2022 05:48",
          "username": "kyo",
          "content": "Only B can do it",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 531839,
          "date": "Tue 25 Jan 2022 05:51",
          "username": "cannottellname",
          "content": "BBBBBBBBBBB",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 514393,
          "date": "Sat 01 Jan 2022 07:14",
          "username": "cldy",
          "content": "B correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 509732,
          "date": "Sun 26 Dec 2021 18:55",
          "username": "vbalvbal",
          "content": "Answer: D; Anyone who thinks S3 Object Metadata Search is not possible: https://aws.amazon.com/blogs/architecture/swiftly-search-metadata-with-an-amazon-s3-serverless-architecture/I wld say building index have a cost attached which could be offset by adding more items in a batch ...",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 509738,
          "date": "Sun 26 Dec 2021 19:09",
          "username": "vbal",
          "content": "I wld say building index have a cost attached which could be offset by adding more items in a batch ...",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491211,
          "date": "Wed 01 Dec 2021 04:27",
          "username": "AzureDP900",
          "content": "B is correct!",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491127,
          "date": "Wed 01 Dec 2021 02:37",
          "username": "acloudguru",
          "content": "B.  DynamoDB with TTL, cheaper for sustained throughput of small items + suited for fast retrievals. S3 cheaper for storage only, much higher costs with writes. RDS not designed for this use case.",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 443231,
          "date": "Fri 05 Nov 2021 16:27",
          "username": "andylogan",
          "content": "It's B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436165,
          "date": "Fri 05 Nov 2021 07:17",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 429170,
          "date": "Tue 02 Nov 2021 21:22",
          "username": "DerekKeykirrim",
          "content": "A & C - wrong<br>B - should be correct<br>D - I am not aware of the API that you can use to search S3 object using used-defined matadata btw. 1.000 put requests cost 0,005 and PUT request header has limitation for user-defined metadata to 2 KBKendra and ElasticSearch will let you search S3 object metadata, but D sounds to me like they're saying it's a native function of S3 itself, which neither of those are.So I'm not saying D is right, just that other services can do it.<br><br>Re: PUT header request with limitation for user-defined metadata to 2KB, that should be OK, you're not storing 4KB data in metadata, you'd be combining multiple 4KB data pieces into a very large flat file.The metadata would only tell you which data pieces are in that very large flat file.",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 462199,
          "date": "Sat 06 Nov 2021 03:17",
          "username": "kirrim",
          "content": "Kendra and ElasticSearch will let you search S3 object metadata, but D sounds to me like they're saying it's a native function of S3 itself, which neither of those are.So I'm not saying D is right, just that other services can do it.<br><br>Re: PUT header request with limitation for user-defined metadata to 2KB, that should be OK, you're not storing 4KB data in metadata, you'd be combining multiple 4KB data pieces into a very large flat file.The metadata would only tell you which data pieces are in that very large flat file.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413259,
          "date": "Tue 02 Nov 2021 01:09",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 358767,
          "date": "Mon 25 Oct 2021 03:43",
          "username": "blackgamer",
          "content": "B is cost effective compared to C.  Also low latency.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 353691,
          "date": "Sun 24 Oct 2021 15:42",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 310441,
          "date": "Mon 18 Oct 2021 15:15",
          "username": "Ajeeshpv",
          "content": "B, millions of input with size less than 4 kb and low latency",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 292959,
          "date": "Fri 15 Oct 2021 05:54",
          "username": "Kian101037RedKanetomosabc1",
          "content": "going with BI'll go with B, since it's an exam.<br>But I think S3 is pretty cost-effective in this case, though I don't know what \\\"indexed retrieval\\\" is.<br>As long as we give enough prefix, I think it may meet the requirement, since S3 has at least\\\"3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per prefix in a bucket\\\".S3 is $5 per million requests, if you have 1 million per minute it's $216,000 per month. Roughly 6x cost of DynamoDBThanks for pointing this out.",
          "upvote_count": "1131",
          "selected_answers": ""
        },
        {
          "id": 304694,
          "date": "Mon 18 Oct 2021 00:32",
          "username": "01037RedKanetomosabc1",
          "content": "I'll go with B, since it's an exam.<br>But I think S3 is pretty cost-effective in this case, though I don't know what \\\"indexed retrieval\\\" is.<br>As long as we give enough prefix, I think it may meet the requirement, since S3 has at least\\\"3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per prefix in a bucket\\\".S3 is $5 per million requests, if you have 1 million per minute it's $216,000 per month. Roughly 6x cost of DynamoDBThanks for pointing this out.",
          "upvote_count": "131",
          "selected_answers": ""
        },
        {
          "id": 330206,
          "date": "Sun 24 Oct 2021 05:51",
          "username": "RedKanetomosabc1",
          "content": "S3 is $5 per million requests, if you have 1 million per minute it's $216,000 per month. Roughly 6x cost of DynamoDBThanks for pointing this out.",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 687510,
          "date": "Thu 06 Oct 2022 07:43",
          "username": "tomosabc1",
          "content": "Thanks for pointing this out.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 267612,
          "date": "Wed 13 Oct 2021 22:06",
          "username": "Ebi",
          "content": "Answer is B<br>Cost effective, low latency, TTL supports retention",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 254901,
          "date": "Mon 11 Oct 2021 00:53",
          "username": "petebear55",
          "content": "This is in the exam guys !!!answer is B Dynamo db is most suitable in these cases.'ingest millions of small records per minute from devices all around the world.'D IS RED HERRING",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#614",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company provides auction services for artwork and has users across North America and Europe. The company hosts its application in Amazon EC2 instances in the us-east-1 Region. Artists upload photos of their work as large-size, high-resolution image files from their mobile phones to a centralized Amazon S3 bucket created in the us-east-1 Region. The users in Europe are reporting slow performance for their image uploads.<br>How can a solutions architect improve the performance of the image upload process?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#614",
          "answers": [
            {
              "choice": "<p>A. Redeploy the application to use S3 multipart uploads.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an Amazon CloudFront distribution and point to the application as a custom origin.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Configure the buckets to use S3 Transfer Acceleration.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create an Auto Scaling group for the EC2 instances and create a scaling policy.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 157075,
          "date": "Mon 20 Sep 2021 11:27",
          "username": "Nemer",
          "content": "C.  Typical S3 Transfer Acceleration use case. Uses CloudFront’s globally distributed edge locations. <br>https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html<br>Exclude option A, as only EU customers have latency issues.",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 267615,
          "date": "Sun 17 Oct 2021 03:02",
          "username": "Ebi",
          "content": "Definitely C",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 497564,
          "date": "Thu 09 Dec 2021 10:57",
          "username": "cldy",
          "content": "C.  Configure the buckets to use S3 Transfer Acceleration.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491213,
          "date": "Wed 01 Dec 2021 04:29",
          "username": "AzureDP900",
          "content": "Transfer acceleration is correct. C is right answer",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 484750,
          "date": "Tue 23 Nov 2021 05:52",
          "username": "acloudguru",
          "content": "A does not make sense, should be C , to use Transfer acceleration for S3 in different region. hope I can have such easy question in my exam.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 443230,
          "date": "Sun 07 Nov 2021 04:31",
          "username": "andylogan",
          "content": "It's C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436166,
          "date": "Fri 05 Nov 2021 05:44",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413261,
          "date": "Thu 04 Nov 2021 22:21",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 358765,
          "date": "Mon 01 Nov 2021 02:42",
          "username": "blackgamer",
          "content": "C is the answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 353695,
          "date": "Sun 31 Oct 2021 10:32",
          "username": "Waiweng",
          "content": "it's C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 321747,
          "date": "Sat 30 Oct 2021 09:19",
          "username": "alisyech",
          "content": "i go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 292971,
          "date": "Sat 30 Oct 2021 06:04",
          "username": "Kian1",
          "content": "going with C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 254908,
          "date": "Sun 10 Oct 2021 17:19",
          "username": "petebear55",
          "content": "This question is very similar to one in teh exam .. where u will be asked to choose two answers ... the other answer is 'upload LARGER images' rather than the (which one would first go for ) smaller images",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 254289,
          "date": "Sun 10 Oct 2021 15:12",
          "username": "Bulti",
          "content": "Answer is C. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 244796,
          "date": "Tue 05 Oct 2021 08:24",
          "username": "T14102020",
          "content": "Correct is C. S3 Transfer Acceleration",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 232509,
          "date": "Sun 03 Oct 2021 07:31",
          "username": "jackdryan",
          "content": "I'll go with C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 231223,
          "date": "Fri 01 Oct 2021 13:04",
          "username": "cloudgc",
          "content": "C as the performance issue is only in uploading images from Europe.",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#615",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has developed a new release of a popular video game and wants to make it available for public download. The new release package is approximately<br>5 GB in size. The company provides downloads for existing releases from a Linux-based, publicly facing FTP site hosted in an on-premises data center. The company expects the new release will be downloaded by users worldwide. The company wants a solution that provides improved download performance and low transfer costs, regardless of a user's location.<br>Which solutions will meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#615",
          "answers": [
            {
              "choice": "<p>A. Store the game files on Amazon EBS volumes mounted on Amazon EC2 instances within an Auto Scaling group. Configure an FTP service on the EC2 instances. Use an Application Load Balancer in front of the Auto Scaling group. Publish the game download URL for users to download the package.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Store the game files on Amazon EFS volumes that are attached to Amazon EC2 instances within an Auto Scaling group. Configure an FTP service on each of the EC2 instances. Use an Application Load Balancer in front of the Auto Scaling group. Publish the game download URL for users to download the package.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Configure Amazon Route 53 and an Amazon S3 bucket for website hosting. Upload the game files to the S3 bucket. Use Amazon CloudFront for the website. Publish the game download URL for users to download the package.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Configure Amazon Route 53 and an Amazon S3 bucket for website hosting. Upload the game files to the S3 bucket. Set Requester Pays for the S3 bucket. Publish the game download URL for users to download the package.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 157094,
          "date": "Tue 21 Sep 2021 01:56",
          "username": "Nemer",
          "content": "C.  CloudFront for the website + game download URL.<br><br>As this a public download that allows anonymous access, option D is excluded.",
          "upvote_count": "16",
          "selected_answers": ""
        },
        {
          "id": 267616,
          "date": "Sun 17 Oct 2021 10:37",
          "username": "Ebi",
          "content": "C is the answer",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 694192,
          "date": "Thu 13 Oct 2022 20:12",
          "username": "loopback0",
          "content": "It's C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 495996,
          "date": "Tue 07 Dec 2021 13:47",
          "username": "cldy",
          "content": "C.  Configure Amazon Route 53 and an Amazon S3 bucket for website hosting. Upload the game files to the S3 bucket. Use Amazon CloudFront for the website. Publish the game download URL for users to download the package.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491216,
          "date": "Wed 01 Dec 2021 04:33",
          "username": "AzureDP900",
          "content": "C is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443229,
          "date": "Tue 02 Nov 2021 01:15",
          "username": "andylogan",
          "content": "It's C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436172,
          "date": "Fri 29 Oct 2021 18:43",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 415207,
          "date": "Thu 28 Oct 2021 05:48",
          "username": "mericov",
          "content": "C -><br>https://aws.amazon.com/blogs/aws/amazon-cloudfront-support-for-20-gb-objects/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413263,
          "date": "Tue 26 Oct 2021 08:41",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 406191,
          "date": "Sun 24 Oct 2021 04:20",
          "username": "Kopa",
          "content": "C, cloudfront more cost effective",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 353697,
          "date": "Tue 19 Oct 2021 17:52",
          "username": "Waiweng",
          "content": "it's C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 292972,
          "date": "Mon 18 Oct 2021 06:44",
          "username": "Kian1",
          "content": "going with C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 254295,
          "date": "Tue 12 Oct 2021 05:50",
          "username": "Bulti",
          "content": "answer is C. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 246160,
          "date": "Sat 09 Oct 2021 17:38",
          "username": "srinivasadarthvoodoopetebear55",
          "content": "D reduces the transfer costsD is not feasible because users are expected to have AWS accounts to absorb the download cost.butc where your coming from",
          "upvote_count": "121",
          "selected_answers": ""
        },
        {
          "id": 251702,
          "date": "Mon 11 Oct 2021 14:12",
          "username": "darthvoodoopetebear55",
          "content": "D is not feasible because users are expected to have AWS accounts to absorb the download cost.butc where your coming from",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 254917,
          "date": "Fri 15 Oct 2021 12:33",
          "username": "petebear55",
          "content": "butc where your coming from",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 244799,
          "date": "Tue 28 Sep 2021 01:38",
          "username": "T14102020",
          "content": "Correct is C.  CloudFront",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 232512,
          "date": "Mon 27 Sep 2021 23:03",
          "username": "jackdryan",
          "content": "I'll go with C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 208505,
          "date": "Sun 26 Sep 2021 21:33",
          "username": "CYL",
          "content": "C.  Since users are from worldwide, using cloudfront as a CDN will help to improve speed of download. Moreover, the game file is likely the same content for each user who does the download.",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#616",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A new startup is running a serverless application using AWS Lambda as the primary source of compute. New versions of the application must be made available to a subset of users before deploying changes to all users. Developers should also have the ability to abort the deployment and have access to an easy rollback<br><br>mechanism. A solutions architect decides to use AWS CodeDeploy to deploy changes when a new version is available.<br>Which CodeDeploy configuration should the solutions architect use?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#616",
          "answers": [
            {
              "choice": "<p>A. A blue/green deployment<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. A linear deployment<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. A canary deployment<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. An all-at-once deployment<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 714466,
          "date": "Wed 09 Nov 2022 11:20",
          "username": "Heeret22s",
          "content": "Why are we not considering the following points:<br>1)Its a new version of 'COMPLETE APPLICATION' .<br>2)We have to release it to subset of users (i.2 using Route53 we can have this distribution )<br>3)Rollback is available in Blue/green also <br><br>The right answers is A ,Blue/Green Deployment <br><br>just read this for more clarification:<br>Canary deployment works similarly to blue-green deployment, but uses a slightly different method. Instead of another full environment waiting to be switched over once deployment is finished, canary deployments cut over just a small subset of servers or nodes first, before finishing the others.Only these predefined deployment configurations are available for AWS Lambda compute platform:<br>Canary: Traffic is shifted in two increments. You can choose from predefined canary options. The options specify the percentage of traffic that's shifted to your updated Lambda function version in the first increment, and the interval, in minutes, before the remaining traffic is shifted in the second increment.<br><br>Linear: Traffic is shifted in equal increments with an equal number of minutes between each increment. You can choose from predefined linear options that specify the percentage of traffic that's shifted in each increment and the number of minutes between each increment.<br><br>AllAtOnce: All traffic is shifted from the original Lambda function to the updated Lambda function version at once.<br><br>Therefore, Blue/Green is not a valid answer here.<br><br>https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html#deployment-configuration-lambda",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 717677,
          "date": "Mon 14 Nov 2022 04:45",
          "username": "et22s",
          "content": "Only these predefined deployment configurations are available for AWS Lambda compute platform:<br>Canary: Traffic is shifted in two increments. You can choose from predefined canary options. The options specify the percentage of traffic that's shifted to your updated Lambda function version in the first increment, and the interval, in minutes, before the remaining traffic is shifted in the second increment.<br><br>Linear: Traffic is shifted in equal increments with an equal number of minutes between each increment. You can choose from predefined linear options that specify the percentage of traffic that's shifted in each increment and the number of minutes between each increment.<br><br>AllAtOnce: All traffic is shifted from the original Lambda function to the updated Lambda function version at once.<br><br>Therefore, Blue/Green is not a valid answer here.<br><br>https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html#deployment-configuration-lambda",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 694926,
          "date": "Fri 14 Oct 2022 19:11",
          "username": "Blair77",
          "content": "C for Canary !!! Let's go!",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 637340,
          "date": "Tue 26 Jul 2022 12:49",
          "username": "CloudHandsOn",
          "content": "C. <br>\\\"..subset of users.\\\" <- Canary is the job for this",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 562635,
          "date": "Mon 07 Mar 2022 14:08",
          "username": "gorodetskyChuky64",
          "content": "C: https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.htmlThis is the key \\\"program must be made accessible to a subset of users\\\"",
          "upvote_count": "21",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 611713,
          "date": "Sun 05 Jun 2022 09:32",
          "username": "Chuky64",
          "content": "This is the key \\\"program must be made accessible to a subset of users\\\"",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 528365,
          "date": "Thu 20 Jan 2022 12:23",
          "username": "GeniusMikeLiukadev",
          "content": "why not A? blue/green also support rollback /because it's a concept defined by AWS. lambda deployment modes only: canary, linear, all",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 656534,
          "date": "Thu 01 Sep 2022 20:17",
          "username": "kadev",
          "content": "because it's a concept defined by AWS. lambda deployment modes only: canary, linear, all",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 497704,
          "date": "Thu 09 Dec 2021 13:18",
          "username": "cldy",
          "content": "C.  A canary deployment",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491218,
          "date": "Wed 01 Dec 2021 04:35",
          "username": "AzureDP900",
          "content": "C is correct answer",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 486371,
          "date": "Thu 25 Nov 2021 03:02",
          "username": "pcops",
          "content": "C: new versions of the program must be made accessible to a subset of users. Definition of canary deployment - A canary deployment, or canary release, is a deployment pattern that allows you to roll out new code/features to a subset of users as an initial test",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443228,
          "date": "Sat 06 Nov 2021 14:37",
          "username": "andylogan",
          "content": "It's C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436173,
          "date": "Thu 21 Oct 2021 17:41",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413267,
          "date": "Mon 18 Oct 2021 16:03",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 406198,
          "date": "Wed 13 Oct 2021 13:26",
          "username": "Kopa",
          "content": "Its C since at serverless application ECS we can use canary.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 358773,
          "date": "Fri 08 Oct 2021 00:27",
          "username": "blackgamer",
          "content": "It is C, Canary deployment.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 353705,
          "date": "Tue 05 Oct 2021 22:11",
          "username": "Waiwengsurekye",
          "content": "it's A, sorry Codedeploy on use blue/green deployment for lambdaC is the Answer: https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html.<br>Question is about Deployment configuration.",
          "upvote_count": "43",
          "selected_answers": ""
        },
        {
          "id": 369609,
          "date": "Wed 13 Oct 2021 05:48",
          "username": "surekye",
          "content": "C is the Answer: https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html.<br>Question is about Deployment configuration.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 353700,
          "date": "Mon 04 Oct 2021 13:43",
          "username": "Waiweng",
          "content": "it's C",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 334090,
          "date": "Sat 02 Oct 2021 11:14",
          "username": "KnightVictor",
          "content": "would go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 322225,
          "date": "Sun 26 Sep 2021 12:32",
          "username": "nitinz",
          "content": "C is correct answer.",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#617",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A solutions architect is implementing federated access to AWS for users of the company's mobile application. Due to regulatory and security requirements, the application must use a custom-built solution for authenticating users and must use IAM roles for authorization.<br>Which of the following actions would enable authentication and authorization and satisfy the requirements? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: DE</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#617",
          "answers": [
            {
              "choice": "<p>A. Use a custom-built SAML-compatible solution for authentication and AWS SSO for authorization.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create a custom-built LDAP connector using Amazon API Gateway and AWS Lambda for authentication. Store authorization tokens in Amazon DynamoDB, and validate authorization requests using another Lambda function that reads the credentials from DynamoDB. <br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use a custom-built OpenID Connect-compatible solution with AWS SSO for authentication and authorization.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use a custom-built SAML-compatible solution that uses LDAP for authentication and uses a SAML assertion to perform authorization to the IAM identity provider.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Use a custom-built OpenID Connect-compatible solution for authentication and use Amazon Cognito for authorization.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 158176,
          "date": "Mon 20 Sep 2021 12:50",
          "username": "NemerDashLDashLLunchTimeLunchTimeCarupanotekkartStelSenacloudgurusashsz",
          "content": "DE. Custom-built SAML-compatible & OpenID Connect-compatible solutions. <br>A & C: AWS SSO does not support mobile apps.<br>B - no comment.Guys, the key thing is that SSO is an authentication service - not an authorization service. Whether is supports mobile app or not is the the key point here.Cognito is both an authentication and authorization service. The steps for Cognito authentication and authorization are:<br>User Login: User enters username and password and logs in with Cognito User Pool in which case a token will be provided by Cognito upon successful login. User pool provides features to control user sign up, sign in and user management.<br>Get Temporary Credentials: Identity pool can use authentication providers like Amazon, Cognito, Custom, Facebook, Google, OpenId, SAML, Twitter/Digits. Identity pool verifies that the token provided to itis a valid token generated by a registered authentication provider. Cognito Identity Pool will provide temporary credentials for accessing AWS resources.<br>User Authorization: Cognito will use IAM to authorize the user with necessary permissions with IAM role (authenticated and unauthenticated identities).AWS SSO does support mobile apps: https://aws.amazon.com/single-sign-on/faqs/Sorry, Nemer is correct. If you go to the link I posted you will see that it says \\\"Does AWS SSO support single sign-on to native mobile and desktop applications?<br>No. AWS SSO supports single sign-on to business applications through web browsers only. \\\" My apologies.You all do not have a clue...what you're posting bunch of locos. <br>https://aws.amazon.com/emr/features/spark/Answers A and E<br>A : OK, AWS SSO is compatible with SAML<br>B : KO, the requirements \\\"IAM roles for authorisation\\\" is not respected<br>C : KO, AWS SSO is not compatible with OIDC<br>D : KO, a solution cannot use SAML and LDAP at the same time, those are 2 distinct protocols<br>E : OK even though Cognito is more authentication than authorisation, it rests on IAM rolesAgree. SSO Can also do authorization via SSO >> Permission TabDoes AWS SSO support single sign-on to native mobile and desktop applications?<br><br>No. AWS SSO supports single sign-on to business applications through web browsers only.https://aws.amazon.com/single-sign-on/faqs/?nc1=h_ls: KO, a solution cannot use SAML and LDAP at the same time, those are 2 distinct protocols<br>Incorrect check your information",
          "upvote_count": "23512122112",
          "selected_answers": ""
        },
        {
          "id": 407194,
          "date": "Tue 12 Oct 2021 15:44",
          "username": "DashLDashL",
          "content": "Guys, the key thing is that SSO is an authentication service - not an authorization service. Whether is supports mobile app or not is the the key point here.Cognito is both an authentication and authorization service. The steps for Cognito authentication and authorization are:<br>User Login: User enters username and password and logs in with Cognito User Pool in which case a token will be provided by Cognito upon successful login. User pool provides features to control user sign up, sign in and user management.<br>Get Temporary Credentials: Identity pool can use authentication providers like Amazon, Cognito, Custom, Facebook, Google, OpenId, SAML, Twitter/Digits. Identity pool verifies that the token provided to itis a valid token generated by a registered authentication provider. Cognito Identity Pool will provide temporary credentials for accessing AWS resources.<br>User Authorization: Cognito will use IAM to authorize the user with necessary permissions with IAM role (authenticated and unauthenticated identities).",
          "upvote_count": "51",
          "selected_answers": ""
        },
        {
          "id": 407208,
          "date": "Wed 13 Oct 2021 07:52",
          "username": "DashL",
          "content": "Cognito is both an authentication and authorization service. The steps for Cognito authentication and authorization are:<br>User Login: User enters username and password and logs in with Cognito User Pool in which case a token will be provided by Cognito upon successful login. User pool provides features to control user sign up, sign in and user management.<br>Get Temporary Credentials: Identity pool can use authentication providers like Amazon, Cognito, Custom, Facebook, Google, OpenId, SAML, Twitter/Digits. Identity pool verifies that the token provided to itis a valid token generated by a registered authentication provider. Cognito Identity Pool will provide temporary credentials for accessing AWS resources.<br>User Authorization: Cognito will use IAM to authorize the user with necessary permissions with IAM role (authenticated and unauthenticated identities).",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 161094,
          "date": "Sat 25 Sep 2021 23:06",
          "username": "LunchTimeLunchTimeCarupano",
          "content": "AWS SSO does support mobile apps: https://aws.amazon.com/single-sign-on/faqs/Sorry, Nemer is correct. If you go to the link I posted you will see that it says \\\"Does AWS SSO support single sign-on to native mobile and desktop applications?<br>No. AWS SSO supports single sign-on to business applications through web browsers only. \\\" My apologies.You all do not have a clue...what you're posting bunch of locos. <br>https://aws.amazon.com/emr/features/spark/",
          "upvote_count": "212",
          "selected_answers": ""
        },
        {
          "id": 161097,
          "date": "Mon 27 Sep 2021 00:31",
          "username": "LunchTimeCarupano",
          "content": "Sorry, Nemer is correct. If you go to the link I posted you will see that it says \\\"Does AWS SSO support single sign-on to native mobile and desktop applications?<br>No. AWS SSO supports single sign-on to business applications through web browsers only. \\\" My apologies.You all do not have a clue...what you're posting bunch of locos. <br>https://aws.amazon.com/emr/features/spark/",
          "upvote_count": "12",
          "selected_answers": ""
        },
        {
          "id": 174188,
          "date": "Wed 29 Sep 2021 22:01",
          "username": "Carupano",
          "content": "You all do not have a clue...what you're posting bunch of locos. <br>https://aws.amazon.com/emr/features/spark/",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 424156,
          "date": "Sat 16 Oct 2021 05:00",
          "username": "tekkartStelSenacloudgurusashsz",
          "content": "Answers A and E<br>A : OK, AWS SSO is compatible with SAML<br>B : KO, the requirements \\\"IAM roles for authorisation\\\" is not respected<br>C : KO, AWS SSO is not compatible with OIDC<br>D : KO, a solution cannot use SAML and LDAP at the same time, those are 2 distinct protocols<br>E : OK even though Cognito is more authentication than authorisation, it rests on IAM rolesAgree. SSO Can also do authorization via SSO >> Permission TabDoes AWS SSO support single sign-on to native mobile and desktop applications?<br><br>No. AWS SSO supports single sign-on to business applications through web browsers only.https://aws.amazon.com/single-sign-on/faqs/?nc1=h_ls: KO, a solution cannot use SAML and LDAP at the same time, those are 2 distinct protocols<br>Incorrect check your information",
          "upvote_count": "2112",
          "selected_answers": ""
        },
        {
          "id": 458169,
          "date": "Fri 05 Nov 2021 09:07",
          "username": "StelSenacloudguru",
          "content": "Agree. SSO Can also do authorization via SSO >> Permission TabDoes AWS SSO support single sign-on to native mobile and desktop applications?<br><br>No. AWS SSO supports single sign-on to business applications through web browsers only.https://aws.amazon.com/single-sign-on/faqs/?nc1=h_ls",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 487919,
          "date": "Sat 27 Nov 2021 08:10",
          "username": "acloudguru",
          "content": "Does AWS SSO support single sign-on to native mobile and desktop applications?<br><br>No. AWS SSO supports single sign-on to business applications through web browsers only.https://aws.amazon.com/single-sign-on/faqs/?nc1=h_ls",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 581237,
          "date": "Tue 05 Apr 2022 14:03",
          "username": "sashsz",
          "content": ": KO, a solution cannot use SAML and LDAP at the same time, those are 2 distinct protocols<br>Incorrect check your information",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 692332,
          "date": "Tue 11 Oct 2022 20:29",
          "username": "Ni_yot",
          "content": "like D and E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 650226,
          "date": "Mon 22 Aug 2022 13:46",
          "username": "asfsdfsdf",
          "content": "This is clearly documented in AWS docs:<br>For D see diagram:<br>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_saml.html<br>for E:<br>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc_cognito.html<br>SSO is not for mobile apps",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: DE"
        },
        {
          "id": 512482,
          "date": "Wed 29 Dec 2021 18:20",
          "username": "Sat12345",
          "content": "Does AWS SSO support single sign-on to native mobile and desktop applications?<br><br>No. AWS SSO supports single sign-on to business applications through web browsers only.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 491920,
          "date": "Wed 01 Dec 2021 21:23",
          "username": "AzureDP900",
          "content": "D,E is correct !",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: DE"
        },
        {
          "id": 447095,
          "date": "Tue 02 Nov 2021 18:56",
          "username": "johnnsmith",
          "content": "D is wrong. To use role for authorization, you have to use STS assumerole API. There is nothing in D that calls STS API. AWS SSO and AWS Cognito can call STS API. So it is A and E. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443217,
          "date": "Tue 26 Oct 2021 11:06",
          "username": "andylogan",
          "content": "It's D, E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435745,
          "date": "Fri 22 Oct 2021 08:57",
          "username": "tgv",
          "content": "DDD EEE<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 413269,
          "date": "Wed 13 Oct 2021 13:06",
          "username": "WhyIronMan",
          "content": "I'll go with D,E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 359248,
          "date": "Tue 12 Oct 2021 04:48",
          "username": "blackgamer",
          "content": "D & E. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 353708,
          "date": "Sun 10 Oct 2021 21:37",
          "username": "Waiweng",
          "content": "it's D,E",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 292974,
          "date": "Sat 09 Oct 2021 20:39",
          "username": "Kian1",
          "content": "will go with DE",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 267622,
          "date": "Wed 06 Oct 2021 04:08",
          "username": "Ebi",
          "content": "SSO is not purposed for end users and mobile apps.<br>I will go with DE",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 254301,
          "date": "Tue 05 Oct 2021 02:42",
          "username": "Bulti",
          "content": "D&E is correct. AWS SSO does not support mobile authentication.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 244805,
          "date": "Mon 04 Oct 2021 11:44",
          "username": "T14102020",
          "content": "Correct is DE.  A and C: AWS SSO does not support mobile apps.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 232518,
          "date": "Fri 01 Oct 2021 21:25",
          "username": "jackdryan",
          "content": "I'll go with D,E",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 227756,
          "date": "Thu 30 Sep 2021 20:35",
          "username": "NNHAN",
          "content": "I choose B, D. ",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#618",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has developed a custom tool used in its workflow that runs within a Docker container. The company must perform manual steps each time the container code is updated to make the container image available to new workflow executions. The company wants to automate this process to eliminate manual effort and ensure a new container image is generated every time the tool code is updated.<br>Which combination of actions should a solutions architect take to meet these requirements? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: ACF</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#618",
          "answers": [
            {
              "choice": "<p>A. Configure an Amazon ECR repository for the tool. Configure an AWS CodeCommit repository containing code for the tool being deployed to the container image in Amazon ECR.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Configure an AWS CodeDeploy application that triggers an application version update that pulls the latest tool container image from Amazon ECR, updates the container with code from the source AWS CodeCommit repository, and pushes the updated container image to Amazon ECR.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Configuration an AWS CodeBuild project that pulls the latest tool container image from Amazon ECR, updates the container with code from the source AWS CodeCommit repository, and pushes the updated container image to Amazon ECR.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Configure an AWS CodePipeline pipeline that sources the tool code from the AWS CodeCommit repository and initiates an AWS CodeDeploy application update.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>E. Configure an Amazon EventBridge rule that triggers on commits to the AWS CodeCommit repository for the tool. Configure the event to trigger an update to the tool container image in Amazon ECR. Push the updated container image to Amazon ECR.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>F. Configure an AWS CodePipeline pipeline that sources the tool code from the AWS CodeCommit repository and initiates an AWS CodeBuild build.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 158615,
          "date": "Thu 30 Sep 2021 15:39",
          "username": "directconnect",
          "content": "The answer is ACF.  The pipeline should trigger the CodeBuild project which will store the result in ECR using CodeCommit as source. CodeDeploy has no part to play in this.",
          "upvote_count": "18",
          "selected_answers": ""
        },
        {
          "id": 208519,
          "date": "Mon 11 Oct 2021 18:54",
          "username": "CYL",
          "content": "ACF.  We are building new image, hence what we need are ECR to store the image, code build to build the image, and Codepipeline to see this end to end. Code Deploy is not needed as we are not deploying to the container.",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 601593,
          "date": "Sat 14 May 2022 15:11",
          "username": "bobsmith2000",
          "content": "C, F for sure.<br>B and D are nonsense.<br>Between A and E. <br><br>Why A?<br>From it we only need \\\"Configure an Amazon ECR repository for the tool.\\\". The rest is crap. C and F cover all the process from pulling to CodeCommit to pushing to ECR.<br>Why the hell the added a second sentence in A \\\"Configure an AWS CodeCommit repository containing code for the tool being deployed to the container image in Amazon ECR.\\\" ?<br>Whose sick mind is this a product of?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496619,
          "date": "Wed 08 Dec 2021 08:55",
          "username": "cldy",
          "content": "A.  Configure an Amazon ECR repository for the tool. Configure an AWS CodeCommit repository containing code for the tool being deployed to the container image in Amazon ECR.<br>C.  Configuration an AWS CodeBuild project that pulls the latest tool container image from Amazon ECR, updates the container with code from the source AWS CodeCommit repository, and pushes the updated container image to Amazon ECR.<br>F.  Configure an AWS CodePipeline pipeline that sources the tool code from the AWS CodeCommit repository and initiates an AWS CodeBuild build.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 491928,
          "date": "Wed 01 Dec 2021 21:35",
          "username": "AzureDP900",
          "content": "ACF is correct.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: ACF"
        },
        {
          "id": 483852,
          "date": "Mon 22 Nov 2021 05:20",
          "username": "acloudguru",
          "content": "ACF.  We are building new image, hence what we need are ECR to store the image, code build to build the image, and Codepipeline to see this end to end. Code Deploy is not needed as we are not deploying to the container.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ACF"
        },
        {
          "id": 443216,
          "date": "Tue 02 Nov 2021 13:50",
          "username": "andylogan",
          "content": "A, C, F",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436177,
          "date": "Thu 28 Oct 2021 04:01",
          "username": "tgvdenccctgv",
          "content": "AAA CCC FFF<br>---IIII tttthink yyyyour kkkeyboard iiis bbbrokenit helps me to spot my answer more easily when I go through the questions the second time",
          "upvote_count": "224",
          "selected_answers": ""
        },
        {
          "id": 436478,
          "date": "Thu 28 Oct 2021 18:13",
          "username": "denccctgv",
          "content": "IIII tttthink yyyyour kkkeyboard iiis bbbrokenit helps me to spot my answer more easily when I go through the questions the second time",
          "upvote_count": "24",
          "selected_answers": ""
        },
        {
          "id": 437025,
          "date": "Sun 31 Oct 2021 19:54",
          "username": "tgv",
          "content": "it helps me to spot my answer more easily when I go through the questions the second time",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 413271,
          "date": "Wed 27 Oct 2021 02:58",
          "username": "WhyIronMan",
          "content": "I'll go with A,C,F",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 359281,
          "date": "Tue 26 Oct 2021 01:25",
          "username": "blackgamer",
          "content": "ACF is correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 353711,
          "date": "Sun 24 Oct 2021 08:40",
          "username": "Waiweng",
          "content": "A,C, F",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 292987,
          "date": "Sat 23 Oct 2021 07:28",
          "username": "Kian1",
          "content": "going with ACF",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 277023,
          "date": "Fri 22 Oct 2021 09:45",
          "username": "rcher",
          "content": "Ok with ACF, but i wonder why must CodeBuild pull the latest image while building the new code? I thought its just a matter of building an existing DockerFile , unless its importing a base image.<br><br>Configuration an AWS CodeBuild project that pulls the latest tool container image from Amazon ECR,",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 267624,
          "date": "Wed 20 Oct 2021 20:58",
          "username": "Ebi",
          "content": "ACF is the answer",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 254324,
          "date": "Wed 20 Oct 2021 18:38",
          "username": "Bulti",
          "content": "ACF is the right answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 244808,
          "date": "Wed 20 Oct 2021 04:41",
          "username": "T14102020",
          "content": "Correct is ACF.  CodeBuild+ Pipeline + without CodeDeploy",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 232525,
          "date": "Mon 18 Oct 2021 22:06",
          "username": "jackdryan",
          "content": "I'll go with A,C,F",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#619",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company hosts an application on Amazon EC2 instance and needs to store files in Amazon S3. The files should never traverse the public internet, and only the application EC2 instances are granted access to a specific Amazon S3 bucket. A solutions architect has created a VPC endpoint for Amazon S3 and connected the endpoint to the application VPC. <br>Which additional steps should the solutions architect take to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#619",
          "answers": [
            {
              "choice": "<p>A. Assign an endpoint policy to the endpoint that restricts access to a specific S3 bucket. Attach a bucket policy to the S3 bucket that grants access to the VPC endpoint. Add the gateway prefix list to a NACL of the instances to limit access to the application EC2 instances only.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Attach a bucket policy to the S3 bucket that grants access to application EC2 instances only using the aws:SourceIp condition. Update the VPC route table so only the application EC2 instances can access the VPC endpoint.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Assign an endpoint policy to the VPC endpoint that restricts access to a specific S3 bucket. Attach a bucket policy to the S3 bucket that grants access to the VPC endpoint. Assign an IAM role to the application EC2 instances and only allow access to this role in the S3 bucket's policy.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Assign an endpoint policy to the VPC endpoint that restricts access to S3 in the current Region. Attach a bucket policy to the S3 bucket that grants access to the VPC private subnets only. Add the gateway prefix list to a NACL to limit access to the application EC2 instances only.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 158143,
          "date": "Fri 24 Sep 2021 12:45",
          "username": "Nemerkirrim",
          "content": "C.  S3 endpoint policy to restrict access to specific bucket,bucket policy to grant access to specific VPC endpoint + specific role.C is the best answer, I'm not crazy about the wording though.\\\"Only allow access to this role in the S3 bucket's policy\\\" ignores that the very same answer also says the the VPCE needs to be permitted in the bucket policy, too.",
          "upvote_count": "192",
          "selected_answers": ""
        },
        {
          "id": 462243,
          "date": "Sat 06 Nov 2021 23:00",
          "username": "kirrim",
          "content": "C is the best answer, I'm not crazy about the wording though.\\\"Only allow access to this role in the S3 bucket's policy\\\" ignores that the very same answer also says the the VPCE needs to be permitted in the bucket policy, too.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 156782,
          "date": "Fri 24 Sep 2021 10:05",
          "username": "Konnon",
          "content": "The answer is C.  Bucket policy allows VPCE. VPCE policy restrict to specific bucket. IAM allows the user to use S3.",
          "upvote_count": "13",
          "selected_answers": ""
        },
        {
          "id": 513955,
          "date": "Fri 31 Dec 2021 09:43",
          "username": "cldy",
          "content": "C is correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 507013,
          "date": "Wed 22 Dec 2021 12:16",
          "username": "Ni_yot",
          "content": "C for me.https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-access.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496358,
          "date": "Tue 07 Dec 2021 23:23",
          "username": "AzureDP900",
          "content": "This question is in Neal Davis Practice test 5",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 494910,
          "date": "Mon 06 Dec 2021 06:08",
          "username": "vramchn",
          "content": "C.  Role + policy",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 491935,
          "date": "Wed 01 Dec 2021 21:46",
          "username": "AzureDP900",
          "content": "Adrian Cantrill explained very well about Gateway endpoint policy , It is C",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 491930,
          "date": "Wed 01 Dec 2021 21:39",
          "username": "AzureDP900",
          "content": "I will go with C",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 443219,
          "date": "Sat 06 Nov 2021 20:28",
          "username": "andylogan",
          "content": "It's C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436184,
          "date": "Fri 05 Nov 2021 23:02",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413272,
          "date": "Wed 03 Nov 2021 23:51",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 353713,
          "date": "Wed 03 Nov 2021 10:23",
          "username": "Waiweng",
          "content": "it's C",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 296210,
          "date": "Tue 02 Nov 2021 09:07",
          "username": "kiev",
          "content": "Bucket policy +Role #C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 267628,
          "date": "Sat 30 Oct 2021 16:17",
          "username": "Ebi",
          "content": "I will go with C",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 254933,
          "date": "Wed 27 Oct 2021 00:40",
          "username": "petebear55",
          "content": "C: Remember best practice when it comes to difficult questions like this lads !!! \\\"ROLE\\\"",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 254327,
          "date": "Mon 25 Oct 2021 06:54",
          "username": "Bulti",
          "content": "C is correct.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 244815,
          "date": "Sun 24 Oct 2021 06:53",
          "username": "T14102020",
          "content": "Correct is C.  without NACL + withoutaws:SourceIp",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#620",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A financial services company has an on-premises environment that ingests market data feeds from stock exchanges, transforms the data, and sends the data to an internal Apache Kafka cluster. Management wants to leverage AWS services to build a scalable and near-real-time solution with consistent network performance to provide stock market data to a web application.<br>Which steps should a solutions architect take to build the solution? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: ACD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#620",
          "answers": [
            {
              "choice": "<p>A. Establish an AWS Direct Connect connection from the on-premises data center to AWS.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an Amazon EC2 Auto Scaling group to pull the messages from the on-premises Kafka cluster and use the Amazon Consumer Library to put the data into an Amazon Kinesis data stream.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create an Amazon EC2 Auto Scaling group to pull the messages from the on-premises Kafka cluster and use the Amazon Kinesis Producer Library to put the data into a Kinesis data stream.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a WebSocket API in Amazon API Gateway, create an AWS Lambda function to process an Amazon Kinesis data stream, and use the @connections command to send callback messages to connected clients.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Create a GraphQL API in AWS AppSync, create an AWS Lambda function to process the Amazon Kinesis data stream, and use the @connections command to send callback messages to connected clients.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>F. Establish a Site-to-Site VPN from the on-premises data center to AWS.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 163051,
          "date": "Tue 28 Sep 2021 03:52",
          "username": "pengcpKelvin1477",
          "content": "ACD, not E.  Refer https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-how-to-call-websocket-api-connections.htmlyes support this as callback is only allowed for websocket",
          "upvote_count": "205",
          "selected_answers": ""
        },
        {
          "id": 238326,
          "date": "Fri 15 Oct 2021 14:58",
          "username": "Kelvin1477",
          "content": "yes support this as callback is only allowed for websocket",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 625036,
          "date": "Thu 30 Jun 2022 07:24",
          "username": "jyrajan69",
          "content": "ACD, A is obvious because of consistency, B is wrong because there is no AWS library and D because @callback is a feature of Websocket API",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 491939,
          "date": "Wed 01 Dec 2021 21:55",
          "username": "AzureDP900",
          "content": "ACD is right answer!",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ACD"
        },
        {
          "id": 443227,
          "date": "Sun 07 Nov 2021 02:09",
          "username": "andylogan",
          "content": "It's A C D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435746,
          "date": "Sun 07 Nov 2021 01:45",
          "username": "tgv",
          "content": "AAA CCC DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433266,
          "date": "Sat 30 Oct 2021 19:51",
          "username": "blackgamer",
          "content": "ACD for sure.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413274,
          "date": "Fri 29 Oct 2021 11:03",
          "username": "WhyIronMan",
          "content": "I'll go with A,C,D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 353719,
          "date": "Tue 26 Oct 2021 18:01",
          "username": "Waiweng",
          "content": "it's ACD",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 342560,
          "date": "Tue 26 Oct 2021 07:02",
          "username": "Amitv2706",
          "content": "@connections command for call back doesnt seem to be available in Appsync( but yes with API gateway) as it manages these constructs internally.<br> <br>Seeing this ACD is correct.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 293063,
          "date": "Tue 26 Oct 2021 04:06",
          "username": "Kian1",
          "content": "going with ACD",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 267630,
          "date": "Sat 23 Oct 2021 17:28",
          "username": "Ebi",
          "content": "ACD is correct",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 254328,
          "date": "Thu 21 Oct 2021 17:59",
          "username": "Bulti",
          "content": "ACD is correct. E is incorrect because @connections to have the backend service connect back to the connected clients is not a feature of GraphQL API using AppSync.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 244819,
          "date": "Sun 17 Oct 2021 04:39",
          "username": "T14102020",
          "content": "Correct is ACD.  <br>Direct Connect <br>+ Transfer Kafka content by Producer into Kinesis Data Stream <br>+ Websocket to connect to web application clients.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 236220,
          "date": "Thu 14 Oct 2021 23:24",
          "username": "hedglin",
          "content": "ACD : I don't think GraphQL API han @connection command.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 232535,
          "date": "Thu 14 Oct 2021 17:51",
          "username": "jackdryan",
          "content": "I'll go with A,C,D",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 208528,
          "date": "Sun 10 Oct 2021 08:39",
          "username": "CYL",
          "content": "ACD.  Direct Connect to ensure reliable network connection between on premise to VPC, transfer Kafka content into Kinese Data Stream and then use websocket to connect to web application clients.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 167220,
          "date": "Tue 05 Oct 2021 00:53",
          "username": "Joe666",
          "content": "ACD are correct",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#621",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A fitness tracking company serves users around the world, with its primary markets in North America and Asia. The company needs to design an infrastructure for its read-heavy user authorization application with the following requirements:<br>✑ Be resilient to problems with the application in any Region.<br>✑ Write to a database in a single Region.<br>✑ Read from multiple Regions.<br>✑ Support resiliency across application tiers in each Region.<br>✑ Support the relational database semantics reflected in the application.<br>Which combination of steps should a solutions architect take? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: CE</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#621",
          "answers": [
            {
              "choice": "<p>A. Use an Amazon Route 53 geoproximity routing policy combined with a multivalue answer routing policy.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Deploy web, application, and MySQL database servers to Amazon EC2 instance in each Region. Set up the application so that reads and writes are local to the Region. Create snapshots of the web, application, and database servers and store the snapshots in an Amazon S3 bucket in both Regions. Set up cross- Region replication for the database layer.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use an Amazon Route 53 geolocation routing policy combined with a failover routing policy.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Set up web, application, and Amazon RDS for MySQL instances in each Region. Set up the application so that reads are local and writes are partitioned based on the user. Set up a Multi-AZ failover for the web, application, and database servers. Set up cross-Region replication for the database layer.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>E. Set up active-active web and application servers in each Region. Deploy an Amazon Aurora global database with clusters in each Region. Set up the application to use the in-Region Aurora database endpoints. Create snapshots of the web application servers and store them in an Amazon S3 bucket in both Regions.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 211035,
          "date": "Mon 20 Sep 2021 08:14",
          "username": "bbnbnuyhkeosSonujunkopablobairatHasitha99",
          "content": "C,E <br>C because \\\"failover routing\\\" gives resiliency<br>E because rest of the options dont make sense for read- heavy and write to central requirementE \\\"...snapshots of the web application servers...\\\" is for what?Be robust to application-related issues in any Region.A,E<br>From https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-multivalue<br>\\\"Multivalue answer routing lets you configure Amazon Route 53 to return multiple values, such as IP addresses for your web servers, in response to DNS queries. You can specify multiple values for almost any record, but multivalue answer routing also lets you check the health of each resource, so Route 53 returns only values for healthy resources. It's not a substitute for a load balancer, but the ability to return multiple health-checkable IP addresses is a way to use DNS to improve availability and load balancing.\\\"Selected Anser : C, E.  <br>The question says, most of the revenue comes from North America & Asia. So we can deploy our infrastructure by prioritising that. Then we can serve all North American Users from the North American region and Asia users from Asia deployments ( geolocation routing).<br><br>Why not A? A is a valid answer. But, if we set up geoproximity base routing, it will route traffic based on the closeness of AWS resources and users. In other terms, we can't give higher priority to our higher revenue regions.",
          "upvote_count": "352161",
          "selected_answers": ""
        },
        {
          "id": 214598,
          "date": "Mon 20 Sep 2021 19:00",
          "username": "keosSonujunko",
          "content": "E \\\"...snapshots of the web application servers...\\\" is for what?Be robust to application-related issues in any Region.",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 564030,
          "date": "Wed 09 Mar 2022 13:35",
          "username": "Sonujunko",
          "content": "Be robust to application-related issues in any Region.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 427572,
          "date": "Mon 18 Oct 2021 10:59",
          "username": "pablobairatHasitha99",
          "content": "A,E<br>From https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-multivalue<br>\\\"Multivalue answer routing lets you configure Amazon Route 53 to return multiple values, such as IP addresses for your web servers, in response to DNS queries. You can specify multiple values for almost any record, but multivalue answer routing also lets you check the health of each resource, so Route 53 returns only values for healthy resources. It's not a substitute for a load balancer, but the ability to return multiple health-checkable IP addresses is a way to use DNS to improve availability and load balancing.\\\"Selected Anser : C, E.  <br>The question says, most of the revenue comes from North America & Asia. So we can deploy our infrastructure by prioritising that. Then we can serve all North American Users from the North American region and Asia users from Asia deployments ( geolocation routing).<br><br>Why not A? A is a valid answer. But, if we set up geoproximity base routing, it will route traffic based on the closeness of AWS resources and users. In other terms, we can't give higher priority to our higher revenue regions.",
          "upvote_count": "61",
          "selected_answers": ""
        },
        {
          "id": 582123,
          "date": "Thu 07 Apr 2022 04:36",
          "username": "Hasitha99",
          "content": "Selected Anser : C, E.  <br>The question says, most of the revenue comes from North America & Asia. So we can deploy our infrastructure by prioritising that. Then we can serve all North American Users from the North American region and Asia users from Asia deployments ( geolocation routing).<br><br>Why not A? A is a valid answer. But, if we set up geoproximity base routing, it will route traffic based on the closeness of AWS resources and users. In other terms, we can't give higher priority to our higher revenue regions.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436238,
          "date": "Thu 21 Oct 2021 09:26",
          "username": "tgv",
          "content": "AAA EEE<br>---<br>The first important thing to note is that users are from all over the world and not only from North America and Asia and that you have to be resilient to problem with the application in ANY REGION.<br><br>What I don't like about Failover is that it works by creating 2 records (primary + secondary)<br>Since you have to be resilient to problem with the application in ANY Region, how are you configuring the failover policy/ies?",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 698723,
          "date": "Wed 19 Oct 2022 08:19",
          "username": "dmscountera",
          "content": "As per the Q, you need to read/be resilient in ANY region not from just 2.<br>So multi-value supports up to 8 IPs > failover ~2<br>8 > 2 =><br>AE",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: AE"
        },
        {
          "id": 652468,
          "date": "Sat 27 Aug 2022 07:28",
          "username": "kadev",
          "content": "many people confuse Aand C, this is explain:<br>\\\"multivalue answer routing policy may cause the users to be randomly sent to other healthy regions\\\" => not good for performance<br>and the point of this Q is \\\"resiliency\\\" => if request failed, it can route to another enpoint => failover",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 635515,
          "date": "Sat 23 Jul 2022 11:45",
          "username": "Student1950",
          "content": "I would vote for A and E. <br>Multi value routing >> checks health of one or more DNS records and send traffic only to healthy record.<br>Fail-Over: used in active - passive traffic flow<br>If E is selected, network is active-active, and we need multivalve DNS routing and not failover DNS routing.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 597312,
          "date": "Thu 05 May 2022 14:52",
          "username": "bobsmith2000",
          "content": "E for sure.<br>Between A and C. <br>That a tough one.<br>We have global users and have to proved a failover.<br>On one hand with geoproximity policy we can serve the content for global users from only two regions. In case of geolocation we must set up default region front users outside Asia and North America, but it's not mentioned in C. <br>On the other hand, multi-answer is not about failover, because it's random.<br>So with A we cover global users, but get random distribution b/w two regions.<br>With C we cover only two region but provide failover.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 582132,
          "date": "Thu 07 Apr 2022 04:52",
          "username": "Hasitha99",
          "content": "The question says, most of the revenue comes from North America & Asia. So we can deploy our infrastructure by prioritising that. Then we can serve all North American Users from the North American region and Asia users from Asia deployments ( geolocation routing).<br><br>Why not A? A is a valid answer. But, if we set up geoproximity base routing, it will route traffic based on the closeness of AWS resources and users. In other terms, we can't give higher priority to our higher revenue regions.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: CE"
        },
        {
          "id": 494385,
          "date": "Sun 05 Dec 2021 14:49",
          "username": "cldy",
          "content": "A.  Use an Amazon Route 53 geoproximity routing policy combined with a multivalue answer routing policy.<br>E.  Set up active-active web and application servers in each Region. Deploy an Amazon Aurora global database with clusters in each Region. Set up the application to use the in-Region Aurora database endpoints. Create snapshots of the web application servers and store them in an Amazon S3 bucket in both Regions.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 483991,
          "date": "Mon 22 Nov 2021 09:55",
          "username": "backfringe",
          "content": "I go for CE",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 449473,
          "date": "Mon 01 Nov 2021 03:38",
          "username": "CloudMan01",
          "content": "A is correct, as the question says there are users all around the world but the primary markets are in North America and Asia. To have better resilience use Geoproximity routing policy – Use when you want to route traffic based on the location of your resources and, optionally, shift traffic from resources in one location to resources in another.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 447279,
          "date": "Sat 30 Oct 2021 11:28",
          "username": "johnnsmithRVivek",
          "content": "If you choose E, you have to choose A because the application is in active-active mode. If you choose C, it will become active-standby mode.under normal condition DNS will rresolve to the region user is closese t (goelocation policy), only when the region fails , failover policy is applied. So it is Active Active",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 510301,
          "date": "Mon 27 Dec 2021 13:54",
          "username": "RVivek",
          "content": "under normal condition DNS will rresolve to the region user is closese t (goelocation policy), only when the region fails , failover policy is applied. So it is Active Active",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 447249,
          "date": "Sat 30 Oct 2021 04:03",
          "username": "Viper57",
          "content": "Answer E is either incorrect or badly written.<br><br>EBS volume snapshots are stored in S3, however you cannot choose what bucket they are stored in nor can they be accessed through the S3 api.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 443236,
          "date": "Sun 24 Oct 2021 22:00",
          "username": "andylogan",
          "content": "It's C, E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 442217,
          "date": "Fri 22 Oct 2021 13:00",
          "username": "student22student22",
          "content": "C,E<br><br>Why not A? Failover routing is better than multivalue answer for this case, and geolocation can be used here with no issues. <br><br>https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.htmlSo, we don't need geoproximity.",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 442219,
          "date": "Sun 24 Oct 2021 07:47",
          "username": "student22",
          "content": "So, we don't need geoproximity.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 438196,
          "date": "Fri 22 Oct 2021 12:35",
          "username": "student22student22",
          "content": "A,E<br>A vs C - This applications is for 'users around the world'. So, Geoproximity is more suitable. It was for users in the given two regions, I'd have selected C. Changing to C,E",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 458476,
          "date": "Sat 06 Nov 2021 22:38",
          "username": "student22",
          "content": "Changing to C,E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 430583,
          "date": "Tue 19 Oct 2021 05:39",
          "username": "near22DerekKeyViper57",
          "content": "C,D<br>B,E make no sense, You cannot save any aws snapshot to s3 bucket.You are completely wrong.<br>In this case: You can back up the data on your Amazon EBS volumes to Amazon S3 by taking point-in-time snapshots.The underlying snapshot is stored in S3, however you cannot access the snapshots in any buckets.",
          "upvote_count": "111",
          "selected_answers": ""
        },
        {
          "id": 433710,
          "date": "Tue 19 Oct 2021 23:50",
          "username": "DerekKeyViper57",
          "content": "You are completely wrong.<br>In this case: You can back up the data on your Amazon EBS volumes to Amazon S3 by taking point-in-time snapshots.The underlying snapshot is stored in S3, however you cannot access the snapshots in any buckets.",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 447248,
          "date": "Tue 26 Oct 2021 23:07",
          "username": "Viper57",
          "content": "The underlying snapshot is stored in S3, however you cannot access the snapshots in any buckets.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413277,
          "date": "Sun 17 Oct 2021 17:04",
          "username": "WhyIronMan",
          "content": "I'll go with C,E",
          "upvote_count": "4",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#622",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company needs to create a centralized logging architecture for all of its AWS accounts. The architecture should provide near-real-time data analysis for all AWS<br>CloudTrail logs and VPC Flow Logs across all AWS accounts. The company plans to use Amazon Elasticsearch Service (Amazon ES) to perform log analysis in the logging account.<br>Which strategy a solutions architect use to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#622",
          "answers": [
            {
              "choice": "<p>A. Configure CloudTrail and VPC Flow Logs in each AWS account to send data to a centralized Amazon S3 bucket in the logging account. Create and AWS Lambda function to load data from the S3 bucket to Amazon ES in the logging account.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Configure CloudTrail and VPC Flow Logs to send data to a log group in Amazon CloudWatch account. Configure a CloudWatch subscription filter in each AWS account to send data to Amazon Kinesis Data Firehouse in the logging account. Load data from Kinesis Data Firehouse into Amazon ES in the logging account.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Configure CloudTrail and VPC Flow Logs to send data to a separate Amazon S3 bucket in each AWS account. Create an AWS Lambda function triggered by S3 events to copy the data to a centralized logging bucket. Create another Lambda function to load data from the S3 bucket to Amazon ES in the logging account.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Configure CloudTrail and VPC Flow Logs to send data to a log group in Amazon CloudWatch Logs in each AWS account. Create AWS Lambda functions in each AWS accounts to subscribe to the log groups and stream the data to an Amazon S3 bucket in the logging account. Create another Lambda function to load data from the S3 bucket to Amazon ES in the logging account.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 211610,
          "date": "Mon 20 Sep 2021 10:03",
          "username": "bbnbnuyhcertainlysayakanKopaViper57student22",
          "content": "B.  It is well defined here - https://www.cloudjourney.io/articles/publiccloud/central_logging_part_2-su/https://aws.amazon.com/solutions/implementations/centralized-logging/Thanks certainly. This is what I need.The B answer is saying: \\\"Configure a CloudWatch subscription filter in each AWS account to send data to Amazon Kinesis Data Firehouse \\\" on the link it is described to send data to Amazon Kinesis DataStream then Lambda and after that to Kinesis FireHose, it looks that Kinesis DataStream not mention on the answer. Im again for B but it looks suspicious.CloudWatch subscription filter support sending to Kinesis data streams and Firehose so B looks correct.Thanks. I also read the question as \\\"... send data to a log group in each account\\\" So, my answer is B.  If it's really taking about a central cloudwatch account,the answer is A. <br><br>Site admins, verify please?",
          "upvote_count": "1931211",
          "selected_answers": ""
        },
        {
          "id": 302437,
          "date": "Tue 19 Oct 2021 03:02",
          "username": "certainlysayakan",
          "content": "https://aws.amazon.com/solutions/implementations/centralized-logging/Thanks certainly. This is what I need.",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 327982,
          "date": "Sat 23 Oct 2021 18:00",
          "username": "sayakan",
          "content": "Thanks certainly. This is what I need.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 406852,
          "date": "Thu 28 Oct 2021 19:25",
          "username": "KopaViper57student22",
          "content": "The B answer is saying: \\\"Configure a CloudWatch subscription filter in each AWS account to send data to Amazon Kinesis Data Firehouse \\\" on the link it is described to send data to Amazon Kinesis DataStream then Lambda and after that to Kinesis FireHose, it looks that Kinesis DataStream not mention on the answer. Im again for B but it looks suspicious.CloudWatch subscription filter support sending to Kinesis data streams and Firehose so B looks correct.Thanks. I also read the question as \\\"... send data to a log group in each account\\\" So, my answer is B.  If it's really taking about a central cloudwatch account,the answer is A. <br><br>Site admins, verify please?",
          "upvote_count": "211",
          "selected_answers": ""
        },
        {
          "id": 457329,
          "date": "Sun 07 Nov 2021 08:40",
          "username": "Viper57",
          "content": "CloudWatch subscription filter support sending to Kinesis data streams and Firehose so B looks correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 442221,
          "date": "Fri 05 Nov 2021 15:10",
          "username": "student22",
          "content": "Thanks. I also read the question as \\\"... send data to a log group in each account\\\" So, my answer is B.  If it's really taking about a central cloudwatch account,the answer is A. <br><br>Site admins, verify please?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 236569,
          "date": "Fri 01 Oct 2021 16:13",
          "username": "Kelvin1477DerekKey",
          "content": "I think A still a correct option..<br>Based on AWS documentation: A trail enables CloudTrail to deliver log files to an Amazon S3 bucket<br>https://docs.aws.amazon.com/AmazonS3/latest/dev/cloudtrail-logging.htmlCloudTrail delivers to both S3 and CloudWatch",
          "upvote_count": "51",
          "selected_answers": ""
        },
        {
          "id": 433718,
          "date": "Sat 30 Oct 2021 03:46",
          "username": "DerekKey",
          "content": "CloudTrail delivers to both S3 and CloudWatch",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 656211,
          "date": "Thu 01 Sep 2022 13:52",
          "username": "kadev",
          "content": "B for sure, CW loggrpup supcription supports to kinesis firehose now<br>A.  you cant trigger event when S3 object update for log file updating, it's so expensive. if you run lambda as scheduled => it not near-realtime",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 653428,
          "date": "Mon 29 Aug 2022 11:56",
          "username": "gnic",
          "content": "the keyword is \\\"near real time\\\"<br>I was for A, but B is better",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 642728,
          "date": "Fri 05 Aug 2022 06:49",
          "username": "fdoxxx",
          "content": "The answer is A - why not B? the service Amazon Kinesis Data Firehouse does not exists - there is Amazon Kinesis Data Firehose - this typo is on purpose imho.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 640781,
          "date": "Mon 01 Aug 2022 19:30",
          "username": "shuchtgnic",
          "content": "It cannot be B because firehose cannot output to ElasticSearchit can",
          "upvote_count": "11",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 653427,
          "date": "Mon 29 Aug 2022 11:55",
          "username": "gnic",
          "content": "it can",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 637679,
          "date": "Wed 27 Jul 2022 01:43",
          "username": "hilft",
          "content": "the keyword here is real time. B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 613006,
          "date": "Wed 08 Jun 2022 03:21",
          "username": "Anhdd",
          "content": "Should be B.  Due to \\\"near-real-time data analysis\\\" -> Use Kinesis Data Firehouse to send data log to ES is best practice",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 600514,
          "date": "Thu 12 May 2022 09:44",
          "username": "alexph169",
          "content": "Near real time is the keyword. Can not be Lambda here that is an async call mechanism.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 549195,
          "date": "Thu 17 Feb 2022 07:17",
          "username": "jyrajan69",
          "content": "The requirement says near real time, based on that Kinesis will satisfy this, so the only answer likely is B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 539158,
          "date": "Wed 02 Feb 2022 21:11",
          "username": "Jonfernz",
          "content": "Firehose for near-real time.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 499218,
          "date": "Sat 11 Dec 2021 09:59",
          "username": "cldy",
          "content": "B.  Configure CloudTrail and VPC Flow Logs to send data to a log group in Amazon CloudWatch account. Configure a CloudWatch subscription filter in each AWS account to send data to Amazon Kinesis Data Firehouse in the logging account. Load data from Kinesis Data Firehouse into Amazon ES in the logging account.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496633,
          "date": "Wed 08 Dec 2021 09:21",
          "username": "bill_smoke",
          "content": "Could someone please confirm whether these question sets are still on the SAA-C02 exam for December? I'm taking my test in a week and want to make sure this is all legit.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 496364,
          "date": "Tue 07 Dec 2021 23:34",
          "username": "AzureDP900",
          "content": "B is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492873,
          "date": "Fri 03 Dec 2021 01:51",
          "username": "Rho_Ohm",
          "content": ">>> Ans: B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 490310,
          "date": "Tue 30 Nov 2021 02:08",
          "username": "acloudguru",
          "content": "B, near-real-time",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 443238,
          "date": "Sat 06 Nov 2021 12:29",
          "username": "andylogan",
          "content": "It's B",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#623",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A financial company is using a high-performance compute cluster running on Amazon EC2 instances to perform market simulations. A DNS record must be created in an Amazon Route 53 private hosted zone when instances start. The DNS record must be removed after instances are terminated.<br>Currently the company uses a combination of Amazon CloudWatch Events and AWS Lambda to create the DNS record. The solution worked well in testing with small clusters, but in production with clusters containing thousands of instances the company sees the following error in the Lambda logs:<br>HTTP 400 error (Bad request).<br>The response header also includes a status code element with a value of `Throttling` and a status message element with a value of `Rate exceeded`.<br>Which combination of steps should the Solutions Architect take to resolve these issues? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: CDE</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#623",
          "answers": [
            {
              "choice": "<p>A. Configure an Amazon SOS FIFO queue and configure a CloudWatch Events rule to use this queue as a target. Remove the Lambda target from the CloudWatch Events rule.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Configure an Amazon Kinesis data stream and configure a CloudWatch Events rule to use this queue as a target. Remove the Lambda target from the CloudWatch Events rule.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Update the CloudWatch Events rule to trigger on Amazon EC2 ג€Instance Launch Successfulג€ and ג€Instance Terminate Successfulג€ events for the Auto Scaling group used by the cluster.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Configure a Lambda function to retrieve messages from an Amazon SQS queue. Modify the Lambda function to retrieve a maximum of 10 messages then batch the messages by Amazon Route 53 API call type and submit. Delete the messages from the SQS queue after successful API calls.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Configure an Amazon SQS standard queue and configure the existing CloudWatch Events rule to use this queue as a target. Remove the Lambda target from the CloudWatch Events rule.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>F. Configure a Lambda function to read data from the Amazon Kinesis data stream and configure the batch window to 5 minutes. Modify the function to make a single API call to Amazon Route 53 with all records read from the kinesis data stream.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 211679,
          "date": "Mon 20 Sep 2021 02:16",
          "username": "bbnbnuyhpablobairatKelvinbeso",
          "content": "C, D, E <br>You have to introduce a SQS: FIFO has limited throughput so may be a normal SQS queue with batching that can overcome the rate limitsACD<br>If you use UPSERT to introduce the DNS records, if it does not exists, it creates it, if it exists, it update the values (in case of duplicates). For deleting, you use a delete, if it exists, it deletes it, if it was already deleted(duplicated message in the queue), it does nothing.<br><br>The goal here is to support thousands of instances launching and terminating, with a SQS FIFO queue this requirement is not fullfilled. And it was the original problem with Lambda and the concurrency.ACD is better as you need FIFO mode to ensure processing DNS records exactly once.CloudWatch--> SQS--> Lambda (batch) --> R53",
          "upvote_count": "27563",
          "selected_answers": ""
        },
        {
          "id": 427582,
          "date": "Sat 23 Oct 2021 01:22",
          "username": "pablobairat",
          "content": "ACD<br>If you use UPSERT to introduce the DNS records, if it does not exists, it creates it, if it exists, it update the values (in case of duplicates). For deleting, you use a delete, if it exists, it deletes it, if it was already deleted(duplicated message in the queue), it does nothing.<br><br>The goal here is to support thousands of instances launching and terminating, with a SQS FIFO queue this requirement is not fullfilled. And it was the original problem with Lambda and the concurrency.",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 339270,
          "date": "Fri 08 Oct 2021 21:33",
          "username": "Kelvin",
          "content": "ACD is better as you need FIFO mode to ensure processing DNS records exactly once.",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 218331,
          "date": "Mon 20 Sep 2021 17:25",
          "username": "beso",
          "content": "CloudWatch--> SQS--> Lambda (batch) --> R53",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 267536,
          "date": "Wed 29 Sep 2021 00:59",
          "username": "EbiLCC92Ebi",
          "content": "I will go with ACDFIFO SQS is limited 300 message/second. CDE is correct.We need FIFO queue here for exactly-once-processing feature as well as order",
          "upvote_count": "1254",
          "selected_answers": ""
        },
        {
          "id": 367783,
          "date": "Mon 18 Oct 2021 19:18",
          "username": "LCC92",
          "content": "FIFO SQS is limited 300 message/second. CDE is correct.",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 285143,
          "date": "Mon 04 Oct 2021 08:28",
          "username": "Ebi",
          "content": "We need FIFO queue here for exactly-once-processing feature as well as order",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 681442,
          "date": "Wed 28 Sep 2022 08:13",
          "username": "JohnPi",
          "content": "CDE is the answer",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: CDE"
        },
        {
          "id": 659990,
          "date": "Mon 05 Sep 2022 11:27",
          "username": "aqiao",
          "content": "Even the default message groups support 300 requests , you can enable high performance option to improve high throughput:https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/high-throughput-fifo.html",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ACD"
        },
        {
          "id": 577925,
          "date": "Wed 30 Mar 2022 01:23",
          "username": "jj22222",
          "content": "ACD looks right",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ACD"
        },
        {
          "id": 555091,
          "date": "Thu 24 Feb 2022 07:02",
          "username": "jyrajan69",
          "content": "If you are choosing E, then you are okay with duplicate DNS records, which means that when you delete the records you have to figure out the timestamp so that you do not delete the latest entry. Yes you do have limited throughput but thats where D comes in with batching, now you can get 3000 TPS for FIFO. So my answer will have to be A,C,D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 506967,
          "date": "Wed 22 Dec 2021 11:19",
          "username": "tkanmani76",
          "content": "Answer C, D, E - <br>If we would have gone with A, C, D - which makes sense from FIFO perspective, the option D does not mention 'SQS FIFO' instead just mentions SQS. Hence C, D, E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491949,
          "date": "Wed 01 Dec 2021 22:21",
          "username": "AzureDP900",
          "content": "CDE is perfect answer, This question in Neal Davis practice test. <br><br>The errors in the Lambda logs indicate that throttling is occurring. Throttling is intended to protect your resources and downstream applications. Though Lambda automatically scales to accommodate incoming traffic, functions can still be throttled for various reasons.<br><br>In this case it is most likely that the throttling is not occurring in Lambda itself but in API calls made to Amazon Route 53. In Route 53 you are limited (by default) to five requests per second per AWS account. If you submit more than five requests per second, Amazon Route 53 returns an HTTP 400 error (Bad request). The response header also includes a Code element with a value of Throttling and a Message element with a value of Rate exceeded.<br><br>The resolution here is to place the data for the DNS records into an SQS queue where they can buffer. AWS Lambda can then poll the queue and process the messages, making sure to batch the messages to reduce the likelihood of receiving more errors.",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 443737,
          "date": "Thu 04 Nov 2021 05:59",
          "username": "Cotter",
          "content": "CDE better than ADEFIFO SQS is limited 300 message/second as commented below.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443240,
          "date": "Wed 03 Nov 2021 07:50",
          "username": "andylogan",
          "content": "It's C, D, E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436280,
          "date": "Sun 24 Oct 2021 18:11",
          "username": "tgv",
          "content": "CCC DDD EEE<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 413280,
          "date": "Thu 21 Oct 2021 04:01",
          "username": "WhyIronMan",
          "content": "I'll go with C,D,E",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 365386,
          "date": "Sun 17 Oct 2021 11:08",
          "username": "Chibuzo1",
          "content": "The Correct Answer is C D E. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 363148,
          "date": "Sat 16 Oct 2021 16:24",
          "username": "vkbajoria",
          "content": "C, D , E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357303,
          "date": "Thu 14 Oct 2021 13:05",
          "username": "Santoshhhhh",
          "content": "BDE- SQS for decoupling , no FIFO as it has limit ...kinesis is not decoupling solution",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 355311,
          "date": "Mon 11 Oct 2021 07:09",
          "username": "Waiweng",
          "content": "it's C,D,E",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 333333,
          "date": "Fri 08 Oct 2021 19:03",
          "username": "anandbabu",
          "content": "BCF is corrrect answer",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#624",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A North American company with headquarters on the East Coast is deploying a new web application running on Amazon EC2 in the us-east-1 Region. The application should dynamically scale to meet user demand and maintain resiliency. Additionally, the application must have disaster recover capabilities in an active-passive configuration with the us-west-1 Region.<br>Which steps should a solutions architect take after creating a VPC in the us-east-1 Region?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#624",
          "answers": [
            {
              "choice": "<p>A. Create a VPC in the us-west-1 Region. Use inter-Region VPC peering to connect both VPCs. Deploy an Application Load Balancer (ALB) spanning multiple Availability Zones (AZs) to the VPC in the us-east-1 Region. Deploy EC2 instances across multiple AZs in each Region as part of an Auto Scaling group spanning both VPCs and served by the ALB. <br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Deploy an Application Load Balancer (ALB) spanning multiple Availability Zones (AZs) to the VPC in the us-east-1 Region. Deploy EC2 instances across multiple AZs as part of an Auto Scaling group served by the ALB.  Deploy the same solution to the us-west-1 Region. Create an Amazon Route 53 record set with a failover routing policy and health checks enabled to provide high availability across both Regions.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create a VPC in the us-west-1 Region. Use inter-Region VPC peering to connect both VPCs. Deploy an Application Load Balancer (ALB) that spans both VPCs. Deploy EC2 instances across multiple Availability Zones as part of an Auto Scaling group in each VPC served by the ALB.  Create an Amazon Route 53 record that points to the ALB. <br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Deploy an Application Load Balancer (ALB) spanning multiple Availability Zones (AZs) to the VPC in the us-east-1 Region. Deploy EC2 instances across multiple AZs as part of an Auto Scaling group served by the ALB.  Deploy the same solution to the us-west-1 Region. Create separate Amazon Route 53 records in each Region that point to the ALB in the Region. Use Route 53 health checks to provide high availability across both Regions.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 211220,
          "date": "Thu 23 Sep 2021 20:55",
          "username": "porlarowl",
          "content": "I support B. <br>A new web application in a active-passive DR mode.<br>a Route 53 record set with a failover routing policy.",
          "upvote_count": "27",
          "selected_answers": ""
        },
        {
          "id": 660020,
          "date": "Mon 05 Sep 2022 12:01",
          "username": "aqiao",
          "content": "ALB can not cross region, so A and C rule out. Route 53 is a global service but not region, D rules out",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 577656,
          "date": "Tue 29 Mar 2022 16:09",
          "username": "jj22222",
          "content": "b looks right",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 561320,
          "date": "Sat 05 Mar 2022 10:02",
          "username": "pal40sg",
          "content": "A new web application in a active-passive DR mode.<br>a Route 53 record set with a failover routing policy.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 532308,
          "date": "Tue 25 Jan 2022 18:48",
          "username": "shotty1",
          "content": "It is definitely B",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 521493,
          "date": "Tue 11 Jan 2022 12:37",
          "username": "pititcu667",
          "content": "comes down to the route53 being a global service. i initially voted d.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 491950,
          "date": "Wed 01 Dec 2021 22:25",
          "username": "AzureDP900",
          "content": "B Correct answer",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 462263,
          "date": "Sun 07 Nov 2021 14:07",
          "username": "kirrim",
          "content": "There is no reason for the two regions to intercommunicate with each other, so I see no need for the inter-Region peering.That rules out A and C. <br><br>Between B vs D. .. Route53 doesn't have per-region records.It's a global service.So D is wrong.B should work great.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 443242,
          "date": "Sat 06 Nov 2021 06:22",
          "username": "andylogan",
          "content": "It's B with failover routing policy",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436279,
          "date": "Fri 05 Nov 2021 16:42",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433282,
          "date": "Thu 04 Nov 2021 18:02",
          "username": "blackgamer",
          "content": "Definitely B. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413282,
          "date": "Thu 04 Nov 2021 07:11",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 354641,
          "date": "Wed 03 Nov 2021 21:07",
          "username": "Waiweng",
          "content": "ir's B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 327240,
          "date": "Wed 03 Nov 2021 05:59",
          "username": "ExtHo",
          "content": "DDid not mention the routing policy to be used on Amazon Route 53. The question requires that the second region acts as a passive backup, which means only the main region receives all the traffic so you need to specifically use failover routing policy in Amazon Route 53.So B is correct as per requirement",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 321739,
          "date": "Mon 01 Nov 2021 06:08",
          "username": "alisyech",
          "content": "i choose B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 293328,
          "date": "Wed 27 Oct 2021 14:10",
          "username": "Kian1",
          "content": "going with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 267546,
          "date": "Mon 25 Oct 2021 06:40",
          "username": "Ebi",
          "content": "I will go with B",
          "upvote_count": "4",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#625",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company standardized its method of deploying applications to AWS using AWS CodePipeline and AWS CloudFormation. The applications are in TypeScript and<br>Python. The company has recently acquired another business that deploys applications to AWS using Python scripts.<br>Developers from the newly acquired company are hesitant to move their applications under CloudFormation because it would require that they learn a new domain-specific language and eliminate their access to language features, such as looping.<br>How can the acquired applications quickly be brought up to deployment standards while addressing the developers' concerns?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: D</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#625",
          "answers": [
            {
              "choice": "<p>A. Create Cloud Formation templates and re-use parts of the Python scripts as Instance user data. Use the AWS Cloud Development Kit (AWS CDK) to deploy the application using these templates. Incorporate the AWS CDK into CodePipeline and deploy the application to AWS using these templates.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use a third-party resource provisioning engine inside AWS CodeBuild to standardize the deployment processes of the existing and acquired company. Orchestrate the CodeBuild job using CodePipeline.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Standardize on AWS OpsWorks. Integrate OpsWorks with CodePipeline. Have the developers create Chef recipes to deploy their applications on AWS.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Define the AWS resources using TypeScript or Python. Use the AWS Cloud Development Kit (AWS CDK) to create CloudFormation templates from the developers' code, and use the AWS CDK to create CloudFormation stacks. Incorporate the AWS CDK as a CodeBuild job in CodePipeline.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 540698,
          "date": "Sat 05 Feb 2022 00:35",
          "username": "AMKazi",
          "content": "D as it lets developers use their skills",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 554863,
          "date": "Wed 23 Feb 2022 21:37",
          "username": "pititcu667",
          "content": "answer should be d",
          "upvote_count": "5",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 644721,
          "date": "Wed 10 Aug 2022 02:20",
          "username": "Rocky2222",
          "content": "With this solution, the developers no longer need to learn the AWS CloudFormation specific language as they can continue writing TypeScript or Python scripts. The AWS CDK stacks can be converted to AWS CloudFormation templates which can be integrated into the company deployment process.",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 630790,
          "date": "Wed 13 Jul 2022 08:00",
          "username": "adsdadasdadSureNotfdoxxx",
          "content": "PEOPLE TERRAFORM. Its BIn real world but not in AWS exam :)<br>Here D is the answer.when you have a hammer everything looks like a nail ;-) It's D",
          "upvote_count": "211",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 735873,
          "date": "Mon 05 Dec 2022 12:18",
          "username": "SureNot",
          "content": "In real world but not in AWS exam :)<br>Here D is the answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 639368,
          "date": "Fri 29 Jul 2022 20:45",
          "username": "fdoxxx",
          "content": "when you have a hammer everything looks like a nail ;-) It's D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 613483,
          "date": "Wed 08 Jun 2022 21:18",
          "username": "hilft",
          "content": "It is D. ",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 521756,
          "date": "Tue 11 Jan 2022 21:24",
          "username": "Ni_yot",
          "content": "Agree its D based on this link",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 513239,
          "date": "Thu 30 Dec 2021 11:23",
          "username": "krisvija12",
          "content": "Answer should be : D <br>Ref : https://docs.aws.amazon.com/cdk/v2/guide/home.html",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#626",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has a single AWS master billing account, which is the root of the AWS Organizations hierarchy.<br>The company has multiple AWS accounts within this hierarchy, all organized into organization units (OUs). More OUs and AWS accounts will continue to be created as other parts of the business migrate applications to AWS. These business units may need to use different AWS services. The Security team is implementing the following requirements for all current and future AWS accounts:<br>✑ Control policies must be applied across all accounts to prohibit AWS servers.<br>✑ Exceptions to the control policies are allowed based on valid use cases.<br>Which solution will meet these requirements with minimal optional overhead?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: D</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#626",
          "answers": [
            {
              "choice": "<p>A. Use an SCP in Organizations to implement a deny list of AWS servers. Apply this SCP at the level. For any specific exceptions for an OU, create a new SCP for that OU and add the required AWS services to the allow list.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use an SCP in Organizations to implement a deny list of AWS service. Apply this SCP at the root level and each OU. Remove the default AWS managed SCP from the root level and all OU levels. For any specific exceptions, modify the SCP attached to that OU, and add the required AWS services to the allow list.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use an SCP in Organizations to implement a deny list of AWS service. Apply this SCP at each OU level. Leave the default AWS managed SCP at the root level. For any specific executions for an OU, create a new SCP for that OU.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use an SCP in Organizations to implement an allow list of AWS services. Apply this SCP at the root level. Remove the default AWS managed SCP from the root level and all OU levels. For any specific exceptions for an OU, modify the SCP attached to that OU, and add the required AWS services to the allow list.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 255779,
          "date": "Wed 06 Oct 2021 23:42",
          "username": "Bultitekkarttomosabc1",
          "content": "Correct answer is C.  When you use a Deny list, you cannot explicitly allow access to services at OU or account levels. You need to explicitly deny access to services and that's why the term deny list. By default, all services are explicitly allowed starting at the root level. So you need to explicitly create an SCP at each OU level where you need to implement the control policy of denying access to services. In exceptional circumstances on a use case basis, you need to allow access to the services that already have an allow access from root to this OU level where you are creating an exception. Only C satisfies this criteria. D is not correct because it doesn't create an SCP that allow access at all level from the OU in question upto the root level. So even if you create an SCP that allows access to a service, access won't be granted as it's not been explicitly allowed at all level above this OU.Here the correct answer must be D. <br><br>1 - The allowed rights work with as the intersection of the rights given by SCP at root, OU and IAM Policies. Therefore if you implement on a SCP at OU level a Deny of an AWS Server you then wish to grant, the only option is to Modify your SCP, which rules out answers A and C which recommend you to Create a new SCP<br><br>2 - In answers A, B and C it is suggested to Implement an Explicit Deny, and for options B and C, this Deny is at Root Level. It is not possible with this strategy to allow exceptions with this configurations because Explicit Deny takes precedence over Explicit Allow, then Implicit Deny, then Implicit Allow.The only way to address this problem is to set Implicit Deny at the Root Level, so then with our Explicit Allow on SCP at OU Level, it overrides the Implicit Deny, which is what is proposed in Answer D : it is an Allow list of AWS Services not including the restricted AWS Servers which are Implicitly Denied.Your explanation is not correct. D is wrong.<br><br>Using Allow List Strategy, to allow a permission, SCPs with allow statement must be added to the account and every OU above it including root. Every SCP in the hierarchy must explicitly allow the APIs you want to use.<br>Explicit allow at a lower level of organization hierarchy cannot overwrite the implicit deny at a higher level.",
          "upvote_count": "2361",
          "selected_answers": ""
        },
        {
          "id": 424151,
          "date": "Sun 31 Oct 2021 19:20",
          "username": "tekkarttomosabc1",
          "content": "Here the correct answer must be D. <br><br>1 - The allowed rights work with as the intersection of the rights given by SCP at root, OU and IAM Policies. Therefore if you implement on a SCP at OU level a Deny of an AWS Server you then wish to grant, the only option is to Modify your SCP, which rules out answers A and C which recommend you to Create a new SCP<br><br>2 - In answers A, B and C it is suggested to Implement an Explicit Deny, and for options B and C, this Deny is at Root Level. It is not possible with this strategy to allow exceptions with this configurations because Explicit Deny takes precedence over Explicit Allow, then Implicit Deny, then Implicit Allow.The only way to address this problem is to set Implicit Deny at the Root Level, so then with our Explicit Allow on SCP at OU Level, it overrides the Implicit Deny, which is what is proposed in Answer D : it is an Allow list of AWS Services not including the restricted AWS Servers which are Implicitly Denied.Your explanation is not correct. D is wrong.<br><br>Using Allow List Strategy, to allow a permission, SCPs with allow statement must be added to the account and every OU above it including root. Every SCP in the hierarchy must explicitly allow the APIs you want to use.<br>Explicit allow at a lower level of organization hierarchy cannot overwrite the implicit deny at a higher level.",
          "upvote_count": "61",
          "selected_answers": ""
        },
        {
          "id": 686783,
          "date": "Wed 05 Oct 2022 12:51",
          "username": "tomosabc1",
          "content": "Your explanation is not correct. D is wrong.<br><br>Using Allow List Strategy, to allow a permission, SCPs with allow statement must be added to the account and every OU above it including root. Every SCP in the hierarchy must explicitly allow the APIs you want to use.<br>Explicit allow at a lower level of organization hierarchy cannot overwrite the implicit deny at a higher level.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 234866,
          "date": "Sat 02 Oct 2021 18:40",
          "username": "dutchy1988cloudgcaws_arn_name",
          "content": "Prohibit all AWS servers (should be services i guess) can only be achieved by whitelisting method. This means that you will have to remove the AWS managed SCP from the root. <br>Whitelist SCP on the root of your organisation makes sure that any new account will apply these settings. SCP never grants access but can allow you to make use of AWS services. <br>With that baseline set, granting a new set of AWS services in a separate SCP attaching it to the new account in your organisation complies here for the minimal operational overhead.<br><br>only D will statisfy.<br><br>One more negative for C.  once you implement a deny on a toplevel. it will override any allow in a child OU. not that it is stated within this question. but with that in mind that it could be the case, whitelisting makes more sense for me.D would have been the answer if 'These business units may need to use different AWS services' was not required.<br><br>With D we are giving the same AWS Services to all the units.No, D state that \\\"modify the SCP attached to that OU\\\" not the root SCP",
          "upvote_count": "2123",
          "selected_answers": ""
        },
        {
          "id": 237845,
          "date": "Mon 04 Oct 2021 09:16",
          "username": "cloudgcaws_arn_name",
          "content": "D would have been the answer if 'These business units may need to use different AWS services' was not required.<br><br>With D we are giving the same AWS Services to all the units.No, D state that \\\"modify the SCP attached to that OU\\\" not the root SCP",
          "upvote_count": "23",
          "selected_answers": ""
        },
        {
          "id": 411427,
          "date": "Sun 31 Oct 2021 02:24",
          "username": "aws_arn_name",
          "content": "No, D state that \\\"modify the SCP attached to that OU\\\" not the root SCP",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 735877,
          "date": "Mon 05 Dec 2022 12:27",
          "username": "SureNot",
          "content": "C is wrong.<br>1.Attach Deny SAP to all OUs.<br>2. Attach Allow SCP to the OU.<br>They don't say to Detach Deny SCP from the OU - so explicit Deny will be here and win!",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 717578,
          "date": "Mon 14 Nov 2022 00:39",
          "username": "Relaxeasy",
          "content": "C makes more sense",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 686799,
          "date": "Wed 05 Oct 2022 13:00",
          "username": "tomosabc1",
          "content": "C is correct. For explanation, please refer to Bulti's answer.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 676488,
          "date": "Thu 22 Sep 2022 20:52",
          "username": "dcdcdc3",
          "content": "D Cannot work if SCP is not attached to Every Level of OU including root. C can work but is too much overhead;<br>A may have incomplete wording but as is, it is working solution, as the SCP is attached \\\"at the Level\\\". In A, it nowhere says to \\\"attach deny to root level\\\".<br>Here is the whole text for A:<br>\\\"A.  Use an SCP in Organizations to implement a deny list of AWS servers. Apply this SCP at the level. For any specific exceptions for an OU, create a new SCP for that OU and add the required AWS services to the allow list.\\\"<br>The New SCP will not have a Deny for specific service and will have an Allow statement..",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 660616,
          "date": "Tue 06 Sep 2022 01:23",
          "username": "aqiaoaqiao",
          "content": "Three key points in SCP:<br>1 Explicit deny actions has the highest priority;<br>2 Accounts under sub OU inherit the parent OU permissions;<br>3 Explicit allow actions overrides default FullAWSAccess on root organizations;<br>4 Once a deny actions applied on a some OU, even an explicit allow action added on sub OU, all the accounts directly under this OU and its sub OU have no permission to perform the action.Here is the official statement:<br>If an action is blocked by a Deny statement, then all OUs and accounts affected by that SCP are denied access to that action. An SCP at a lower level can't add a permission after it is blocked by an SCP at a higher level. SCPs can only filter; they never add permissions.<br>You can get the details here :https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_inheritance_auth.html<br>So only D satisfied.Actually there is no need to remove default permission on root OU, like key point 3 said, it will be overrode by explicit allow lists",
          "upvote_count": "31",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 660618,
          "date": "Tue 06 Sep 2022 01:24",
          "username": "aqiao",
          "content": "Here is the official statement:<br>If an action is blocked by a Deny statement, then all OUs and accounts affected by that SCP are denied access to that action. An SCP at a lower level can't add a permission after it is blocked by an SCP at a higher level. SCPs can only filter; they never add permissions.<br>You can get the details here :https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_inheritance_auth.html<br>So only D satisfied.Actually there is no need to remove default permission on root OU, like key point 3 said, it will be overrode by explicit allow lists",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 653465,
          "date": "Mon 29 Aug 2022 13:47",
          "username": "gnic",
          "content": "it's D",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 646778,
          "date": "Sun 14 Aug 2022 16:28",
          "username": "Harithareddynn",
          "content": "Minimal operational overhead compared to C",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 637320,
          "date": "Tue 26 Jul 2022 12:03",
          "username": "CloudHandsOn",
          "content": "C. <br>i chose C as the first answer",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 627009,
          "date": "Mon 04 Jul 2022 15:48",
          "username": "Enigmaaaaaa",
          "content": "A - will not work as a deny is on the root level so no specification - there is no way to add the permission back lower in the hierarchy<br>B - Same for A<br>C - Can work - deny on OU level and leave AWS Full access to all accounts at root (I can only assume we also leave for all OU levels) - for exceptions create a new deny SCP and replace it - however it has an operational overhead as it requires attaching it to every OU and every new OU<br>D-cannot work if FullAccess is replaced with specific access SCP it should be applied to all level including OU and account levels (intersection).<br><br>Overall all answers are not fully complete but I have to go with C",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 603872,
          "date": "Thu 19 May 2022 14:07",
          "username": "bobsmith2000",
          "content": "Both C and D will work.<br>But we need a solution with the LAST operational overhead.<br><br>C) There's no shared policy. So every time we must edit the OU SCP<br>D) We must specify common resources on the root level with an allow list (allow explicitly with implicit deny for the rest), and then we are able to both deny or allow any specific services: additional allow will be merged with the root SCP, and explicit deny will override the root's allow. So that we make changes only if needed, not every time when create an account",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 538456,
          "date": "Wed 02 Feb 2022 09:23",
          "username": "Ishu_awsguy",
          "content": "Correct answer is C. <br>We need allow at the root as per the question says \\\" a variety of services needs to be used by business units\\\"<br>Deny SCP is being applied on all OU's in option C. <br>For any specific service allow for any OU, we can replace or edit the OU SCP. <br>It has the least overhead.<br>https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_strategies.html#orgs_policies_denylist",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 507982,
          "date": "Thu 23 Dec 2021 16:38",
          "username": "vbalIshu_awsguy",
          "content": "C says create new SCP for Exception Allow after it have been explicitly Denied...Doesn't make sense if you already have an Deny it is gonna take precedence over explicit Allow in newly created SCP; Answer is D. the SCP is being applied on OU level.<br>No precedence. <br>precedence is for default allow policy. <br>and new policy is to be created for any change.",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 538457,
          "date": "Wed 02 Feb 2022 09:26",
          "username": "Ishu_awsguy",
          "content": "the SCP is being applied on OU level.<br>No precedence. <br>precedence is for default allow policy. <br>and new policy is to be created for any change.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 507554,
          "date": "Thu 23 Dec 2021 03:56",
          "username": "Suresh108",
          "content": "Inclined towards CCCCC. <br><br>Question is asking about minimal operational overhead.<br>https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_strategies.html#orgs_policies_denylist<br><br>The default configuration of AWS Organizations supports using SCPs as deny lists. Using a deny list strategy, account administrators can delegate all services and actions until you create and attach an SCP that denies a specific service or set of actions. Deny statements require less maintenance, because you don't need to update them when AWS adds new services. Deny statements usually use less space, thus making it easier to stay within the maximum size for SCPs. In a statement where the Effect element has a value of Deny, you can also restrict access to specific resources, or define conditions for when SCPs are in effect.<br><br>https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_inheritance_auth.html",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 497696,
          "date": "Thu 09 Dec 2021 13:08",
          "username": "cldy",
          "content": "C.  Use an SCP in Organizations to implement a deny list of AWS service. Apply this SCP at each OU level. Leave the default AWS managed SCP at the root level. For any specific executions for an OU, create a new SCP for that OU.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 491957,
          "date": "Wed 01 Dec 2021 22:37",
          "username": "AzureDP900",
          "content": "C correct",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        }
      ]
    },
    {
      "question_id": "#627",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A healthcare company runs a production workload on AWS that stores highly sensitive personal information. The security team mandates that, for auditing purposes, any AWS API action using AWS account root user credentials must automatically create a high-priority ticket in the company's ticketing system. The ticketing system has a monthly 3-hour maintenance window when no tickets can be created.<br>To meet security requirements, the company enabled AWS CloudTrail logs and wrote a scheduled AWS Lambda function that uses Amazon Athena to query API actions performed by the root user. The Lambda function submits any actions found to the ticketing system API. During a recent security audit, the security team discovered that several tickets were not created because the ticketing system was unavailable due to planned maintenance.<br>Which combination of steps should a solutions architect take to ensure that the incidents are reported to the ticketing system even during planned maintenance?<br>(Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: DE</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#627",
          "answers": [
            {
              "choice": "<p>A. Create an Amazon SNS topic to which Amazon CloudWatch alarms will be published. Configure a CloudWatch alarm to invoke the Lambda function.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an Amazon SQS queue to which Amazon CloudWatch alarms will be published. Configure a CloudWatch alarm to publish to the SQS queue.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Modify the Lambda function to be triggered by messages published to an Amazon SNS topic. Update the existing application code to retry every 5 minutes if the ticketing system's API endpoint is unavailable.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Modify the Lambda function to be triggered when there are messages in the Amazon SQS queue and to return successfully when the ticketing system API has processed the request.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Create an Amazon EventBridge rule that triggers on all API events where the invoking user identity is root. Configure the EventBridge rule to write the event to an Amazon SQS queue.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 216034,
          "date": "Thu 23 Sep 2021 03:14",
          "username": "RajarshiDashLtekkarttekkarttekkart",
          "content": "D and EA - Uses SNS topics. Will not work.<br>B - Uses CloudWatch Alarms. It is required to use a CloudWatch Event/EventBridge rule<br>C - Correct.<br>D - doesn't have reties to address the situation when the ticketing system is down.<br>E - CorrectYou are right, but following your logic, it should be A & C because C requires SNS<br>C offers a solution for the Ticketing System unavailable. None of the solution based on SQS triggers a solution based on its availabilityBut the phrasal of answer A is not OK : \\\"CW Alarm to invoke the Lambda function\\\" <br><br>Why need an Event and a queue, the Lambda is already scheduled... unless when the event is \\\"the ticketing system is available\\\" not \\\"the invoking user identity is root\\\" in question E. .. E does not address the main concern which is the unavailability of ticketing systemConsidering D&E as answers.<br>1 - SQS, as Event source mapping for Lambda, where errors such as unavailable ticketing system block processing until errors are solved or items expire.<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-retries.html<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventsourcemapping.html<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations<br><br>With Dead Letter Queuing option as an alternative solution for on-failure destination :<br>https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html<br><br>2 - SNS is possible as a destination from Event Source Mapping, having SQS->SNS->Lambda, plus for multiple destination notifications such as email sending would be useful, hence C&E could be feasible assuming this link between SQS and SNS.",
          "upvote_count": "234113",
          "selected_answers": ""
        },
        {
          "id": 395250,
          "date": "Thu 21 Oct 2021 14:42",
          "username": "DashLtekkarttekkarttekkart",
          "content": "A - Uses SNS topics. Will not work.<br>B - Uses CloudWatch Alarms. It is required to use a CloudWatch Event/EventBridge rule<br>C - Correct.<br>D - doesn't have reties to address the situation when the ticketing system is down.<br>E - CorrectYou are right, but following your logic, it should be A & C because C requires SNS<br>C offers a solution for the Ticketing System unavailable. None of the solution based on SQS triggers a solution based on its availabilityBut the phrasal of answer A is not OK : \\\"CW Alarm to invoke the Lambda function\\\" <br><br>Why need an Event and a queue, the Lambda is already scheduled... unless when the event is \\\"the ticketing system is available\\\" not \\\"the invoking user identity is root\\\" in question E. .. E does not address the main concern which is the unavailability of ticketing systemConsidering D&E as answers.<br>1 - SQS, as Event source mapping for Lambda, where errors such as unavailable ticketing system block processing until errors are solved or items expire.<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-retries.html<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventsourcemapping.html<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations<br><br>With Dead Letter Queuing option as an alternative solution for on-failure destination :<br>https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html<br><br>2 - SNS is possible as a destination from Event Source Mapping, having SQS->SNS->Lambda, plus for multiple destination notifications such as email sending would be useful, hence C&E could be feasible assuming this link between SQS and SNS.",
          "upvote_count": "4113",
          "selected_answers": ""
        },
        {
          "id": 424168,
          "date": "Thu 28 Oct 2021 14:19",
          "username": "tekkarttekkarttekkart",
          "content": "You are right, but following your logic, it should be A & C because C requires SNS<br>C offers a solution for the Ticketing System unavailable. None of the solution based on SQS triggers a solution based on its availabilityBut the phrasal of answer A is not OK : \\\"CW Alarm to invoke the Lambda function\\\" <br><br>Why need an Event and a queue, the Lambda is already scheduled... unless when the event is \\\"the ticketing system is available\\\" not \\\"the invoking user identity is root\\\" in question E. .. E does not address the main concern which is the unavailability of ticketing systemConsidering D&E as answers.<br>1 - SQS, as Event source mapping for Lambda, where errors such as unavailable ticketing system block processing until errors are solved or items expire.<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-retries.html<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventsourcemapping.html<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations<br><br>With Dead Letter Queuing option as an alternative solution for on-failure destination :<br>https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html<br><br>2 - SNS is possible as a destination from Event Source Mapping, having SQS->SNS->Lambda, plus for multiple destination notifications such as email sending would be useful, hence C&E could be feasible assuming this link between SQS and SNS.",
          "upvote_count": "113",
          "selected_answers": ""
        },
        {
          "id": 424178,
          "date": "Thu 28 Oct 2021 21:13",
          "username": "tekkarttekkart",
          "content": "But the phrasal of answer A is not OK : \\\"CW Alarm to invoke the Lambda function\\\" <br><br>Why need an Event and a queue, the Lambda is already scheduled... unless when the event is \\\"the ticketing system is available\\\" not \\\"the invoking user identity is root\\\" in question E. .. E does not address the main concern which is the unavailability of ticketing systemConsidering D&E as answers.<br>1 - SQS, as Event source mapping for Lambda, where errors such as unavailable ticketing system block processing until errors are solved or items expire.<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-retries.html<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventsourcemapping.html<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations<br><br>With Dead Letter Queuing option as an alternative solution for on-failure destination :<br>https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html<br><br>2 - SNS is possible as a destination from Event Source Mapping, having SQS->SNS->Lambda, plus for multiple destination notifications such as email sending would be useful, hence C&E could be feasible assuming this link between SQS and SNS.",
          "upvote_count": "13",
          "selected_answers": ""
        },
        {
          "id": 424214,
          "date": "Sun 31 Oct 2021 15:49",
          "username": "tekkart",
          "content": "Considering D&E as answers.<br>1 - SQS, as Event source mapping for Lambda, where errors such as unavailable ticketing system block processing until errors are solved or items expire.<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-retries.html<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventsourcemapping.html<br>https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations<br><br>With Dead Letter Queuing option as an alternative solution for on-failure destination :<br>https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html<br><br>2 - SNS is possible as a destination from Event Source Mapping, having SQS->SNS->Lambda, plus for multiple destination notifications such as email sending would be useful, hence C&E could be feasible assuming this link between SQS and SNS.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 218345,
          "date": "Thu 23 Sep 2021 19:25",
          "username": "besoshammousKelvin",
          "content": "B and D, CloudWatch--> SQS--> Lambda-->Ticketing systemYou need EventBridge to trigger root API calls only and then take action. Option B is too broad and doesn't satisfy the requirement of detecting \\\"API actions performed by the root user\\\".You need CloudWatch Events (aka EventBridge) but not CloudWatch Alarm in this case. So D and E. ",
          "upvote_count": "1314",
          "selected_answers": ""
        },
        {
          "id": 277831,
          "date": "Sun 17 Oct 2021 06:15",
          "username": "shammous",
          "content": "You need EventBridge to trigger root API calls only and then take action. Option B is too broad and doesn't satisfy the requirement of detecting \\\"API actions performed by the root user\\\".",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 339284,
          "date": "Wed 20 Oct 2021 01:33",
          "username": "Kelvin",
          "content": "You need CloudWatch Events (aka EventBridge) but not CloudWatch Alarm in this case. So D and E. ",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 638188,
          "date": "Wed 27 Jul 2022 17:56",
          "username": "hilft",
          "content": "B and D, CloudWatch--> SQS--> Lambda",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 607768,
          "date": "Thu 26 May 2022 20:49",
          "username": "bobsmith2000",
          "content": "Right by the book!",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: DE"
        },
        {
          "id": 543381,
          "date": "Tue 08 Feb 2022 23:41",
          "username": "jj22222",
          "content": "D and E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 519737,
          "date": "Sat 08 Jan 2022 20:19",
          "username": "CloudChef",
          "content": "D and E",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: DE"
        },
        {
          "id": 515889,
          "date": "Mon 03 Jan 2022 16:54",
          "username": "Ni_yot",
          "content": "D and Eis good choice.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 514347,
          "date": "Sat 01 Jan 2022 05:10",
          "username": "cldy",
          "content": "D and E. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491968,
          "date": "Wed 01 Dec 2021 22:57",
          "username": "AzureDP900",
          "content": "D,E <br><br>The existing system can be modified to use Amazon EventBridge instead of using AWS CloudTrail with Amazon Athena. Eventbridge can be configured with a rule that checks all AWS API calls via CloudTrail. The rule can be configured to look for the usage or the root user account. Eventbridge can then be configured with an Amazon SQS queue as a target that puts a message in the queue waiting to be processed.<br>The Lambda function can then be configured to poll the queue for messages (event-source mapping), process the event synchronously and only return a successful result when the ticketing system has processed the request. The message will be deleted only if the result is successful, allowing for retries.<br>This system will ensure that the important events are not missed when the ticketing system is unavailable.",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: DE"
        },
        {
          "id": 449834,
          "date": "Sun 07 Nov 2021 00:25",
          "username": "nirukkirrim",
          "content": "D & E<br>Eventbridge => https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-what-is.html<br>SQS permissions => https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-use-resource-based.html#eb-sqs-permissions<br>Search for root => https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-logging-monitoring.html also look at the policy.+1 for citing documentation on how to make this work<br><br>A & B are wrong because CloudWatch Alarms is based on metrics, not an event/action (that's CloudWatch Events)<br>C is eliminated because it could have only worked in combo with A, and A is wrong<br>D is valid per your links<br>E is valid per your links<br><br>(Note that you'd probably have to be careful with D that you don't have a Lambda function running for a LONG time trying to reach the API!Might require some extra work here to avoid that)",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 462600,
          "date": "Sun 07 Nov 2021 08:41",
          "username": "kirrim",
          "content": "+1 for citing documentation on how to make this work<br><br>A & B are wrong because CloudWatch Alarms is based on metrics, not an event/action (that's CloudWatch Events)<br>C is eliminated because it could have only worked in combo with A, and A is wrong<br>D is valid per your links<br>E is valid per your links<br><br>(Note that you'd probably have to be careful with D that you don't have a Lambda function running for a LONG time trying to reach the API!Might require some extra work here to avoid that)",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443306,
          "date": "Tue 02 Nov 2021 09:56",
          "username": "andylogan",
          "content": "It's D E <br>Since we need CloudWatch Events (aka EventBridge) but not CloudWatch Alarm in this case.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436285,
          "date": "Tue 02 Nov 2021 05:43",
          "username": "tgv",
          "content": "DDD EEE<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435683,
          "date": "Mon 01 Nov 2021 17:36",
          "username": "denccc",
          "content": "it's D and E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433760,
          "date": "Mon 01 Nov 2021 14:46",
          "username": "DerekKey",
          "content": "A& B - wrong -> CloudWatch alarms base on metrics<br>C - wrong - no services in correct answers that write to SNS<br>D - correct - Lambda -> SQS<br>E - correct - EventBridge = CW Events -> SQS",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 433290,
          "date": "Mon 01 Nov 2021 11:32",
          "username": "blackgamer",
          "content": "I believe D and E. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413287,
          "date": "Wed 27 Oct 2021 22:41",
          "username": "WhyIronMan",
          "content": "I'll go with D,E<br><br>SNS does not serve for this purpose",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 406933,
          "date": "Tue 26 Oct 2021 09:32",
          "username": "Kopa",
          "content": "Im for D & E, E more faster then B. ",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#628",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A solutions architect is migrating an existing workload to AWS Fargate. The task can only run in a private subnet within the VPC where there is no direct connectivity from outside the system to the application. When the Fargate task is launched, the task fails with the following error:<br>CannotPullContainerError: API error (500): Get https://111122223333.dkr.ecr.us-east-1.amazonaws.com/v2/: net/http: request canceled while waiting for connection<br>How should the solutions architect correct this error?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#628",
          "answers": [
            {
              "choice": "<p>A. Ensure the task is set to ENABLED for the auto-assign public IP setting when launching the task.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Ensure the task is set to DISABLED for the auto-assign public IP setting when launching the task. Configure a NAT gateway in the public subnet in the VPC to route requests to the internet.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Ensure the task is set to DISABLED for the auto-assign public IP setting when launching the task. Configure a NAT gateway in the private subnet in the VPC to route requests to the internet.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Ensure the network mode is set to bridge in the Fargate task definition.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 211978,
          "date": "Mon 20 Sep 2021 19:28",
          "username": "asldavid",
          "content": "B.  https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_cannot_pull_image.html",
          "upvote_count": "22",
          "selected_answers": ""
        },
        {
          "id": 212916,
          "date": "Wed 22 Sep 2021 12:02",
          "username": "lionoporlarowlpetebear55Kelvin1477",
          "content": "B is the correct answer. The NAT needs to be in public subnet.<br>https://stackoverflow.com/questions/48368499/stopped-cannotpullcontainererror-api-error-500I understand that \\\"Configure a NAT GW in the private subnet\\\" dose not mean Creating a NAT GW. If it means creating a NAT GW, the answer should be B.  On the other hand, it means attaching a NAT GW to subnet, the answer should be C.  I am not sure, cause I am not a English native speaker.THINK YOUR RIGHT.. however because they have asked you to choose between public and private in the answers .. knowing aws this leads to one of these being the answer .. so in exam i would put b .. for publicyes agree, NAT gw always public facing caused need public IP to communicate with ECR",
          "upvote_count": "12221",
          "selected_answers": ""
        },
        {
          "id": 213176,
          "date": "Fri 24 Sep 2021 15:36",
          "username": "porlarowlpetebear55",
          "content": "I understand that \\\"Configure a NAT GW in the private subnet\\\" dose not mean Creating a NAT GW. If it means creating a NAT GW, the answer should be B.  On the other hand, it means attaching a NAT GW to subnet, the answer should be C.  I am not sure, cause I am not a English native speaker.THINK YOUR RIGHT.. however because they have asked you to choose between public and private in the answers .. knowing aws this leads to one of these being the answer .. so in exam i would put b .. for public",
          "upvote_count": "22",
          "selected_answers": ""
        },
        {
          "id": 255209,
          "date": "Tue 05 Oct 2021 02:18",
          "username": "petebear55",
          "content": "THINK YOUR RIGHT.. however because they have asked you to choose between public and private in the answers .. knowing aws this leads to one of these being the answer .. so in exam i would put b .. for public",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 225810,
          "date": "Fri 01 Oct 2021 02:36",
          "username": "Kelvin1477",
          "content": "yes agree, NAT gw always public facing caused need public IP to communicate with ECR",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 621292,
          "date": "Thu 23 Jun 2022 22:46",
          "username": "kangtamo",
          "content": "Agree with B. ",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 491970,
          "date": "Wed 01 Dec 2021 23:00",
          "username": "AzureDP900",
          "content": "B is right <br><br>When a Fargate task is launched, its elastic network interface requires a route to the internet to pull container<br>images. If you receive an error similar to the following when launching a task, it is because a route to the internet<br>does not exist:<br>CannotPullContainerError: API error (500): Get https://111122223333.dkr.ecr.us-east-1.amazonaws.com/v2/:<br>net/http: request canceled while waiting for connection”<br>To resolve this issue, you can:<br>o For tasks in public subnets, specify ENABLED for Auto-assign public IP when launching the task.<br>o For tasks in private subnets, specify DISABLED for Auto-assign public IP when launching the task, and<br>configure a NAT gateway in your VPC to route requests to the internet.",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 443313,
          "date": "Thu 04 Nov 2021 18:54",
          "username": "andylogan",
          "content": "It's B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443131,
          "date": "Mon 01 Nov 2021 13:49",
          "username": "nsei",
          "content": "Answer is B.  NAT gateway should be in the public subnet.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436287,
          "date": "Sun 31 Oct 2021 17:08",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433292,
          "date": "Thu 28 Oct 2021 03:48",
          "username": "blackgamer",
          "content": "B.  NAT gateway needs to be in public subnet.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 430797,
          "date": "Mon 25 Oct 2021 02:47",
          "username": "AndyTokyo608DerekKey",
          "content": "I go with CFor tasks in public subnets, specify ENABLED for Auto-assign public IP when launching the taskStrange. Read the question again.<br>\\\"The task can only run in a private subnet within the VPC where there is no direct connectivity from outside the system to the application\\\"",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 433762,
          "date": "Sat 30 Oct 2021 18:05",
          "username": "DerekKey",
          "content": "Strange. Read the question again.<br>\\\"The task can only run in a private subnet within the VPC where there is no direct connectivity from outside the system to the application\\\"",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413288,
          "date": "Wed 20 Oct 2021 18:21",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 355387,
          "date": "Wed 20 Oct 2021 12:34",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 355318,
          "date": "Fri 15 Oct 2021 08:06",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 293341,
          "date": "Mon 11 Oct 2021 15:44",
          "username": "Kian1",
          "content": "going with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 284663,
          "date": "Fri 08 Oct 2021 22:32",
          "username": "Ebi",
          "content": "B is my choice",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 259121,
          "date": "Thu 07 Oct 2021 17:20",
          "username": "kopper2019kopper2019",
          "content": "B, NAT GW must in a public subnet in order to workhttps://aws.amazon.com/blogs/compute/task-networking-in-aws-fargate/<br>https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-configure-network.html",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 259122,
          "date": "Fri 08 Oct 2021 10:19",
          "username": "kopper2019",
          "content": "https://aws.amazon.com/blogs/compute/task-networking-in-aws-fargate/<br>https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-configure-network.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 255802,
          "date": "Wed 06 Oct 2021 18:13",
          "username": "Bulti",
          "content": "Answer is B.  There is no difference between configuring and creating as far as this question is concerned. And we all know that NAT Gateway needs to be created in a Public Subnet. It needs to be accessed from the private subnet via a route table attached to it thatroutes outbound traffic to the NAT Gateway which is in the public subnet and from there to the internet via the Internet Gateway attached to the VPC. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 255212,
          "date": "Tue 05 Oct 2021 17:18",
          "username": "petebear55",
          "content": "B . aws are sh**s ... sent to persecute us poor students of aws !! . they throw red herring questions in like this .. knowing most would go for C. . but this is not the case .. it needs to be PUBLIC so select B ... be aware of this in the exam ... your thinking should go opposite to what your instinct is saying !! .. it is the same in my previous answers when they mention uploading files and mention small or large... go for large even though instinct says small ...Wizzlabs have a good couple of questions similar to this one and very good explanations from people whom took exam etc ...But for now lets choose B",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#629",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is running a two-tier web-based application in an on-premises data center. The application user consists of a single server running a stateful application. The application connects to a PostgreSQL database running on a separate server. The application's user base is expected to grow significantly, so the company is migrating the application and database to AWS. The solution will use Amazon Aurora PostgreSQL, Amazon EC2 Auto Scaling, and Elastic Load<br>Balancing.<br>Which solution will provide a consistent user experience that will allow the application and database tiers to scale?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#629",
          "answers": [
            {
              "choice": "<p>A. Enable Aurora Auto Scaling for Aurora Replicas. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Enable Aurora Auto Scaling for Aurora writes. Use an Application Load Balancer with the round robin routing algorithm and sticky sessions enabled.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Enable Aurora Auto Scaling for Aurora Replicas. Use an Application Load Balancer with the robin routing and sticky sessions enabled.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Enable Aurora Scaling for Aurora writers. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 218348,
          "date": "Sat 25 Sep 2021 12:02",
          "username": "beso",
          "content": "C, <br>Aurora Auto Scaling enables your Aurora DB cluster to handle sudden increases in connectivity or workload. When the connectivity or workload decreases, Aurora Auto Scaling removes unnecessary Aurora Replicas so that you don't pay for unused provisioned DB instances",
          "upvote_count": "22",
          "selected_answers": ""
        },
        {
          "id": 644708,
          "date": "Wed 10 Aug 2022 01:23",
          "username": "MarkChoi",
          "content": "It's C",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 496545,
          "date": "Wed 08 Dec 2021 06:22",
          "username": "cldy",
          "content": "C.  Enable Aurora Auto Scaling for Aurora Replicas. Use an Application Load Balancer with the robin routing and sickly sessions enabled.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 491972,
          "date": "Wed 01 Dec 2021 23:02",
          "username": "AzureDP900",
          "content": "C is right !",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443315,
          "date": "Fri 05 Nov 2021 12:46",
          "username": "andylogan",
          "content": "It's C with Aurora Replicas",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 443173,
          "date": "Wed 03 Nov 2021 13:32",
          "username": "nsei",
          "content": "C is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 438239,
          "date": "Tue 02 Nov 2021 14:22",
          "username": "student22",
          "content": "C<br> Auto Scaling for Aurora Replicas + ALB with sticky sessions",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 436289,
          "date": "Mon 01 Nov 2021 01:18",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413290,
          "date": "Fri 29 Oct 2021 07:45",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 406943,
          "date": "Sun 24 Oct 2021 22:13",
          "username": "Kopa",
          "content": "C also for me",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 355183,
          "date": "Fri 22 Oct 2021 22:06",
          "username": "Waiweng",
          "content": "it's C",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 321743,
          "date": "Thu 21 Oct 2021 07:41",
          "username": "alisyech",
          "content": "i choose C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 277421,
          "date": "Thu 14 Oct 2021 23:56",
          "username": "rcherkirrim",
          "content": "ALB cause its Web application (Although i can argue that NLB can scale better,just that you need to do SSL termination at the web app)<br><br>Aurora scale read replica, haven't heard of writes (Correct me if i am wrong)<br><br>C thenThe Least Outstanding Requests algo is only supported on the ALB, not the NLB that I could find.So it's definitely C in my mind",
          "upvote_count": "42",
          "selected_answers": ""
        },
        {
          "id": 462637,
          "date": "Sun 07 Nov 2021 07:28",
          "username": "kirrim",
          "content": "The Least Outstanding Requests algo is only supported on the ALB, not the NLB that I could find.So it's definitely C in my mind",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 259266,
          "date": "Thu 14 Oct 2021 05:24",
          "username": "Ebi",
          "content": "C is the correct answer.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 259107,
          "date": "Sat 09 Oct 2021 07:32",
          "username": "Bulti",
          "content": "Answer is C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 244927,
          "date": "Sat 02 Oct 2021 22:15",
          "username": "T14102020",
          "content": "Correct is C. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 232598,
          "date": "Sat 02 Oct 2021 01:25",
          "username": "jackdryan",
          "content": "I'll go with C",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#630",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A solutions architect is designing a network for a new cloud deployment. Each account will need autonomy to modify route tables and make changes. Centralized and controlled egress internet connectivity is also needed. The cloud footprint is expected to grow to thousands of AWS accounts.<br>Which architecture will meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: D</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#630",
          "answers": [
            {
              "choice": "<p>A. A centralized transit VPC with a VPN connection to a standalone VPC in each account. Outbound internet traffic will be controlled by firewall appliances.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. A centralized shared VPC with a subnet for each account. Outbound internet traffic will be controlled through a fleet of proxy servers.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. A shared services VPC to host central assets to include a fleet of firewalls with a route to the internet. Each spoke VPC will peer to the central VPC. <br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. A shared transit gateway to which each VPC will be attached. Outbound internet access will route through a fleet of VPN-attached firewalls.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 216151,
          "date": "Mon 20 Sep 2021 21:28",
          "username": "MarkDillon1075",
          "content": "D - https://docs.aws.amazon.com/whitepapers/latest/building-scalable-secure-multi-vpc-network-infrastructure/centralized-egress-to-internet.html",
          "upvote_count": "24",
          "selected_answers": ""
        },
        {
          "id": 229778,
          "date": "Wed 22 Sep 2021 00:43",
          "username": "Chris_1990",
          "content": "Looks like D<br><br>Answer C is wrong, because there is a default limit of 50 VPS peerings per VPC, which can be increased to a amximum of 125 (https://docs.aws.amazon.com/vpc/latest/userguide/amazon-vpc-limits.html). Since the cloud footprint is expected to grow to thousands of AWS accounts, VPC peering with one central VPC would not work. Transit Gateway can hadle up to 5000 attachments and therefore is the better choice here.",
          "upvote_count": "10",
          "selected_answers": ""
        },
        {
          "id": 622757,
          "date": "Sun 26 Jun 2022 20:59",
          "username": "kangtamo",
          "content": "Agree with D. ",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 496387,
          "date": "Wed 08 Dec 2021 00:13",
          "username": "AzureDP900",
          "content": "I will go with D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 462655,
          "date": "Sat 06 Nov 2021 11:35",
          "username": "kirrimKopa",
          "content": "A would not scale beyond 100 VPN connections to a VPC<br>B would not scale beyond 200 subnets in a single VPC (you can increase the subnet quota beyond 200, but ultimately this doesn't scale because your CIDR and minimum subnet size would limit you at some point)<br>C would not scale beyond the VPC peering limit of 50 (you can increase this to 125, but not beyond that)<br>D would scale the most, but even that is not infinite, you'd have a limit of 5,000 TGW attachments (can be increased), or 10k static routes per TGW (one for each VPC CIDR), or 50Gbps throughput, or the VPN throughput of your firewalls.good explanation",
          "upvote_count": "91",
          "selected_answers": ""
        },
        {
          "id": 493812,
          "date": "Sat 04 Dec 2021 17:51",
          "username": "Kopa",
          "content": "good explanation",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 448894,
          "date": "Thu 04 Nov 2021 10:20",
          "username": "moon2351",
          "content": "Answer is D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443323,
          "date": "Wed 03 Nov 2021 05:39",
          "username": "andylogan",
          "content": "It's D with shared transit gateway",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436292,
          "date": "Mon 01 Nov 2021 19:47",
          "username": "tgv",
          "content": "DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413291,
          "date": "Mon 01 Nov 2021 17:54",
          "username": "WhyIronMan",
          "content": "I'll go with D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 409119,
          "date": "Wed 27 Oct 2021 05:59",
          "username": "student2020student2020ryu10_09",
          "content": "D looks good except \\\"VPN-attached firewalls\\\". What is this? Did they mean VPC attached firewalls?Architecture for D is explained here:<br>https://docs.aws.amazon.com/whitepapers/latest/building-scalable-secure-multi-vpc-network-infrastructure/centralized-egress-to-internet.htmlUsing an EC2 instance for centralized outbound<br><br>Using a software-based firewall appliance (on EC2) from AWS Marketplace as an egress point is similar to the NAT gateway setup. This option can be used if you want to leverage the layer 7 firewall/Intrusion Prevention/Detection System (IPS/IDS) capabilities of the various vendor offerings.<br><br>In Figure 12, we replace NAT Gateway with an EC2 instance (with SNAT enabled on EC2 instance). There are few key considerations with this",
          "upvote_count": "321",
          "selected_answers": ""
        },
        {
          "id": 409125,
          "date": "Fri 29 Oct 2021 03:21",
          "username": "student2020",
          "content": "Architecture for D is explained here:<br>https://docs.aws.amazon.com/whitepapers/latest/building-scalable-secure-multi-vpc-network-infrastructure/centralized-egress-to-internet.html",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 480592,
          "date": "Thu 18 Nov 2021 11:17",
          "username": "ryu10_09",
          "content": "Using an EC2 instance for centralized outbound<br><br>Using a software-based firewall appliance (on EC2) from AWS Marketplace as an egress point is similar to the NAT gateway setup. This option can be used if you want to leverage the layer 7 firewall/Intrusion Prevention/Detection System (IPS/IDS) capabilities of the various vendor offerings.<br><br>In Figure 12, we replace NAT Gateway with an EC2 instance (with SNAT enabled on EC2 instance). There are few key considerations with this",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 355385,
          "date": "Tue 26 Oct 2021 12:56",
          "username": "Waiweng",
          "content": "it's D",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 303817,
          "date": "Thu 14 Oct 2021 09:48",
          "username": "certainlynitinznitinzcertainly",
          "content": "I will go with B.  https://aws.amazon.com/blogs/networking-and-content-delivery/how-to-use-aws-privatelink-to-secure-and-scale-web-filtering-using-explicit-proxy/. D.  how do you route internet traffic thru VPN connected firewall?Seems B to me.Changing to Dchange my Answer to D.  B says \\\" A centralized shared VPC with a subnet for each account\\\" this would not allow to grow to support 1000s AWS account",
          "upvote_count": "2111",
          "selected_answers": ""
        },
        {
          "id": 313496,
          "date": "Sat 16 Oct 2021 05:19",
          "username": "nitinznitinz",
          "content": "Seems B to me.Changing to D",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 318744,
          "date": "Sat 16 Oct 2021 09:22",
          "username": "nitinz",
          "content": "Changing to D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 334126,
          "date": "Sun 17 Oct 2021 07:52",
          "username": "certainly",
          "content": "change my Answer to D.  B says \\\" A centralized shared VPC with a subnet for each account\\\" this would not allow to grow to support 1000s AWS account",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 293350,
          "date": "Tue 12 Oct 2021 17:25",
          "username": "Kian1",
          "content": "going with D transit gateway",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 283423,
          "date": "Mon 11 Oct 2021 14:45",
          "username": "Trap_D0_r",
          "content": "D<br>This is *THE* use case for a Transit Gateway. All the other information in answers is a distraction.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 264480,
          "date": "Tue 05 Oct 2021 20:36",
          "username": "Ebi",
          "content": "I will go with D",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 255827,
          "date": "Tue 05 Oct 2021 19:31",
          "username": "Bulti",
          "content": "D is the correct answer as it is the only scalable option listed.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 250202,
          "date": "Fri 01 Oct 2021 12:25",
          "username": "spring21",
          "content": "D: AWS Transit Gateway helps you design and implement networks at scale by acting as a cloud router. As your network grows, the complexity of managing incremental connections can slow you down. AWS Transit Gateway connects VPCs and on-premises networks through a central hub. This simplifies your network and puts an end to complex peering relationships -- each new connection is only made once.",
          "upvote_count": "5",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#631",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A solutions architect needs to migrate 50 TB of NFS data to Amazon S3. The files are on several NFS file servers on corporate network. These are dense file systems containing tens of millions of small files. The system operators have configured the file interface on an AWS Snowball Edge device and are using a shell script to copy data.<br>Developers report that copying the data to the Snowball Edge device is very slow. The solutions architect suspects this may be related to the overhead of encrypting all the small files and transporting them over the network.<br>Which changes can be made to speed up the data transfer?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#631",
          "answers": [
            {
              "choice": "<p>A. Cluster two Snowball Edge devices together to increase the throughput of the devices.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Change the solution to use the S3 Adapter instead of the file interface on the Snowball Edge device.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Increase the number of parallel copy jobs to increase the throughput of the Snowball Edge device.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Connect directly to the USB interface on the Snowball Edge device and copy the files locally.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 211793,
          "date": "Sun 19 Sep 2021 19:38",
          "username": "Gmail78mrphuongbnStelSen",
          "content": "C- Perform multiple copy operations at one time – If your workstation is powerful enough, you can perform multiple snowball cp commands at one time. You can do this by running each command from a separate terminal window, in separate instances of the Snowball client, all connected to the same Snowball.<br>https://docs.aws.amazon.com/snowball/latest/ug/performance.htmlSometimes the fastest way to transfer data with Snowball is to transfer data in parallel.<br>https://docs.aws.amazon.com/snowball/latest/ug/transfer-petabytes.html#parallel-usageAgree with Answer-C.  One more supporting link: https://aws.amazon.com/blogs/storage/best-practices-for-accelerating-data-migrations-using-aws-snowball-edge/ (Section: Parallelize data transfers)",
          "upvote_count": "3411",
          "selected_answers": ""
        },
        {
          "id": 455531,
          "date": "Sat 06 Nov 2021 14:46",
          "username": "mrphuongbn",
          "content": "Sometimes the fastest way to transfer data with Snowball is to transfer data in parallel.<br>https://docs.aws.amazon.com/snowball/latest/ug/transfer-petabytes.html#parallel-usage",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 458221,
          "date": "Sat 06 Nov 2021 19:17",
          "username": "StelSen",
          "content": "Agree with Answer-C.  One more supporting link: https://aws.amazon.com/blogs/storage/best-practices-for-accelerating-data-migrations-using-aws-snowball-edge/ (Section: Parallelize data transfers)",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 225200,
          "date": "Tue 21 Sep 2021 03:05",
          "username": "taoteching1PAUGURUshammousstudent22student22AkaAka4HellGate",
          "content": "Answer = B - The data transfer rate using the file interface is typically between 25 MB/s and 40 MB/s. If you need to transfer data faster than this, use the Amazon S3 Adapter for Snowball, which has a data transfer rate typically between 250 MB/s and 400 MB/s. <br>https://docs.aws.amazon.com/snowball/latest/developer-guide/using-adapter.html<br>https://docs.aws.amazon.com/snowball/latest/developer-guide/BestPractices.htmlThe last link you posted clearly states: <br>\\\"This following list is ordered from largest to smallest positive impact on performance:<br>1 Perform multiple write operations at one time – To do this, run each command from multiple terminal windows on a computer with a network connection to a single AWS Snowball Edge device.\\\"<br>So I say C. Check the note below the list that satisfy the requirement.Yes. It looks like B is the correct answer:<br>https://docs.aws.amazon.com/snowball/latest/developer-guide/BestPractices.html<br>The data transfer rate using the file interface is typically between 25 MB/s and 40 MB/s. If you need to transfer data faster than this, use the Amazon S3 Adapter for Snowball, which has a data transfer rate typically between 250 MB/s and 400 MB/s.So, you have to use Amazon S3 Adapter for Snowball first even if you're planning to increase the speed with multiple parallel write operations.I don't think there is such pre-requisite... the two options can be done separately without dependency on each other.S3 Adapter is designed for this situation over programatical approach in C. ",
          "upvote_count": "16531212",
          "selected_answers": ""
        },
        {
          "id": 238478,
          "date": "Thu 23 Sep 2021 09:18",
          "username": "PAUGURUshammousstudent22student22AkaAka4HellGate",
          "content": "The last link you posted clearly states: <br>\\\"This following list is ordered from largest to smallest positive impact on performance:<br>1 Perform multiple write operations at one time – To do this, run each command from multiple terminal windows on a computer with a network connection to a single AWS Snowball Edge device.\\\"<br>So I say C. Check the note below the list that satisfy the requirement.Yes. It looks like B is the correct answer:<br>https://docs.aws.amazon.com/snowball/latest/developer-guide/BestPractices.html<br>The data transfer rate using the file interface is typically between 25 MB/s and 40 MB/s. If you need to transfer data faster than this, use the Amazon S3 Adapter for Snowball, which has a data transfer rate typically between 250 MB/s and 400 MB/s.So, you have to use Amazon S3 Adapter for Snowball first even if you're planning to increase the speed with multiple parallel write operations.I don't think there is such pre-requisite... the two options can be done separately without dependency on each other.S3 Adapter is designed for this situation over programatical approach in C. ",
          "upvote_count": "531212",
          "selected_answers": ""
        },
        {
          "id": 277844,
          "date": "Mon 11 Oct 2021 11:24",
          "username": "shammousstudent22student22AkaAka4",
          "content": "Check the note below the list that satisfy the requirement.Yes. It looks like B is the correct answer:<br>https://docs.aws.amazon.com/snowball/latest/developer-guide/BestPractices.html<br>The data transfer rate using the file interface is typically between 25 MB/s and 40 MB/s. If you need to transfer data faster than this, use the Amazon S3 Adapter for Snowball, which has a data transfer rate typically between 250 MB/s and 400 MB/s.So, you have to use Amazon S3 Adapter for Snowball first even if you're planning to increase the speed with multiple parallel write operations.I don't think there is such pre-requisite... the two options can be done separately without dependency on each other.",
          "upvote_count": "3121",
          "selected_answers": ""
        },
        {
          "id": 438251,
          "date": "Sat 30 Oct 2021 06:01",
          "username": "student22student22AkaAka4",
          "content": "Yes. It looks like B is the correct answer:<br>https://docs.aws.amazon.com/snowball/latest/developer-guide/BestPractices.html<br>The data transfer rate using the file interface is typically between 25 MB/s and 40 MB/s. If you need to transfer data faster than this, use the Amazon S3 Adapter for Snowball, which has a data transfer rate typically between 250 MB/s and 400 MB/s.So, you have to use Amazon S3 Adapter for Snowball first even if you're planning to increase the speed with multiple parallel write operations.I don't think there is such pre-requisite... the two options can be done separately without dependency on each other.",
          "upvote_count": "121",
          "selected_answers": ""
        },
        {
          "id": 442249,
          "date": "Sun 31 Oct 2021 07:17",
          "username": "student22AkaAka4",
          "content": "So, you have to use Amazon S3 Adapter for Snowball first even if you're planning to increase the speed with multiple parallel write operations.I don't think there is such pre-requisite... the two options can be done separately without dependency on each other.",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 504566,
          "date": "Sun 19 Dec 2021 02:31",
          "username": "AkaAka4",
          "content": "I don't think there is such pre-requisite... the two options can be done separately without dependency on each other.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 535942,
          "date": "Sun 30 Jan 2022 06:16",
          "username": "HellGate",
          "content": "S3 Adapter is designed for this situation over programatical approach in C. ",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 658102,
          "date": "Sat 03 Sep 2022 07:35",
          "username": "aqiao",
          "content": "According to this link:https://docs.aws.amazon.com/snowball/latest/developer-guide/performance.html. For small files, you should transfer them in batch. The biggest difference between B and C is S3 adapter used with program, but file interface is a GUI",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 625152,
          "date": "Thu 30 Jun 2022 11:20",
          "username": "TechX",
          "content": "C for me. <br>The question said that: \\\"The solutions architect feels this is due to the overhead associated with encrypting and transferring all the little data across the network.\\\" -> we have network issue. <br>While from the AWS documentation, they clearly note that: \\\"Because the computer workstation from which or to which you make the data transfer is considered to be the bottleneck for transferring data, we highly recommend that your workstation be a powerful computer. It should be able to meet high demands in terms of processing, memory, and networking\\\" https://docs.aws.amazon.com/snowball/latest/ug/using-adapter.html",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 577827,
          "date": "Tue 29 Mar 2022 20:35",
          "username": "jj22222",
          "content": "C.  Increase the number of parallel copy jobs to increase the throughput of the Snowball Edge device.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 555053,
          "date": "Thu 24 Feb 2022 04:32",
          "username": "jyrajan69TechX",
          "content": "This statement is imp 'architect feels this is due to the overhead associated with encrypting and transferring all the little data across the network.' So based on this, S3 Adapter with higher transfer rates will not resolve this issue, must go with C. agree with you, from the AWS documentation, they clearly note that: \\\"Because the computer workstation from which or to which you make the data transfer is considered to be the bottleneck for transferring data, we highly recommend that your workstation be a powerful computer. It should be able to meet high demands in terms of processing, memory, and networking\\\"<br>https://docs.aws.amazon.com/snowball/latest/ug/using-adapter.html",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 625151,
          "date": "Thu 30 Jun 2022 11:18",
          "username": "TechX",
          "content": "agree with you, from the AWS documentation, they clearly note that: \\\"Because the computer workstation from which or to which you make the data transfer is considered to be the bottleneck for transferring data, we highly recommend that your workstation be a powerful computer. It should be able to meet high demands in terms of processing, memory, and networking\\\"<br>https://docs.aws.amazon.com/snowball/latest/ug/using-adapter.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 525720,
          "date": "Mon 17 Jan 2022 12:31",
          "username": "pititcu667",
          "content": "Question is center around snowball.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 491985,
          "date": "Wed 01 Dec 2021 23:57",
          "username": "AzureDP900",
          "content": "C <br>Perform multiple copy operations at one time by running each command from a separate terminal window, in separate instances of the Snowball client” is the correct answer",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 475991,
          "date": "Thu 11 Nov 2021 06:13",
          "username": "Liongeek",
          "content": "From my understanding, it's as simple as this:<br>If you change to s3 adapter of course you could get higher transfer rate, but you won't cause you'r still using only ONE CPU thread to copy the files. You want to use all your CPU cores/threads to shorten the ENCRYPTION TIME? Run parallel copies then :)",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 450558,
          "date": "Sat 06 Nov 2021 13:31",
          "username": "Bigbearcn",
          "content": "I will go with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443328,
          "date": "Mon 01 Nov 2021 04:21",
          "username": "andylogan",
          "content": "It's B to useS3 Adapter first",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433561,
          "date": "Tue 26 Oct 2021 07:05",
          "username": "blackgamer",
          "content": "C is the answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 432709,
          "date": "Sat 23 Oct 2021 19:05",
          "username": "johnyc55",
          "content": "Note<br>The data transfer rate using the file interface is typically between 25 MB/s and 40 MB/s. If you need to transfer data faster than this, use the Amazon S3 adapter for Snowball, which has a data transfer rate typically between 250 MB/s and 400 MB/s. For more information, see Transferring Files Using the Amazon S3 Interface.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 413301,
          "date": "Sat 23 Oct 2021 11:59",
          "username": "WhyIronMan",
          "content": "I'll go with B<br>B and C are right, but the ORDER is:<br>1 - set the Amazon S3 Adapter for Snowball<br>2 - start multiple copies after set S3 Adapter for Snowball<br><br>the first thing to do is set the S3 Adapter for Snowball, otherwise the multiple copies will throw the same problem again.",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 413292,
          "date": "Thu 21 Oct 2021 04:19",
          "username": "WhyIronManWhyIronManWhyIronManstudent22",
          "content": "I'll go with BAfter a second tough, changing to CNo, nvm, going back to B. .. <br>the order is:<br>1 - set the Amazon S3 Adapter for Snowball<br>2 - start multiple copies after set S3 Adapter for Snowball<br><br>the first thing to do is set the S3 Adapter for Snowball, otherwise the multiple copies will throw the same problem again.Yes. B is right.",
          "upvote_count": "1132",
          "selected_answers": ""
        },
        {
          "id": 413293,
          "date": "Fri 22 Oct 2021 13:01",
          "username": "WhyIronManWhyIronManstudent22",
          "content": "After a second tough, changing to CNo, nvm, going back to B. .. <br>the order is:<br>1 - set the Amazon S3 Adapter for Snowball<br>2 - start multiple copies after set S3 Adapter for Snowball<br><br>the first thing to do is set the S3 Adapter for Snowball, otherwise the multiple copies will throw the same problem again.Yes. B is right.",
          "upvote_count": "132",
          "selected_answers": ""
        },
        {
          "id": 413300,
          "date": "Fri 22 Oct 2021 17:22",
          "username": "WhyIronManstudent22",
          "content": "No, nvm, going back to B. .. <br>the order is:<br>1 - set the Amazon S3 Adapter for Snowball<br>2 - start multiple copies after set S3 Adapter for Snowball<br><br>the first thing to do is set the S3 Adapter for Snowball, otherwise the multiple copies will throw the same problem again.Yes. B is right.",
          "upvote_count": "32",
          "selected_answers": ""
        },
        {
          "id": 449956,
          "date": "Tue 02 Nov 2021 02:12",
          "username": "student22",
          "content": "Yes. B is right.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 368747,
          "date": "Wed 20 Oct 2021 22:45",
          "username": "vkbajoria",
          "content": "It is C for me. Eventhough B sounds very convincing as well. Plus it provide faster speed then File Interface.<br><br>But According to AWS, if transfer is started with File Interface, it should be continue till end. Therefore, opening multiple window will speed things up. If we want to start over, then obviously s3 Interface would be faster.<br>Here is the link: https://docs.aws.amazon.com/snowball/latest/developer-guide/using-fileinterface.html#fileinterface-overview",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 367468,
          "date": "Wed 20 Oct 2021 21:50",
          "username": "gcg27NerdMe",
          "content": "Correct answer is C, this question is exacted from Bonso examYes, you are correct I also saw the exact same question. Answer is C. ",
          "upvote_count": "43",
          "selected_answers": ""
        },
        {
          "id": 450340,
          "date": "Sat 06 Nov 2021 05:21",
          "username": "NerdMe",
          "content": "Yes, you are correct I also saw the exact same question. Answer is C. ",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#632",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is planning on hosting its ecommerce platform on AWS using a multi-tier web application designed for a NoSQL database. The company plans to use the us-west-2 Region as its primary Region. The company wants to ensure that copies of the application and data are available in second Region, us-west-1, for disaster recovery. The company wants to keep the time to fail over as low as possible. Failing back to the primary Region should be possible without administrative interaction after the primary service is restored.<br>Which design should the solutions architect use?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: A</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#632",
          "answers": [
            {
              "choice": "<p>A. Use AWS CloudFormation StackSets to create the stacks in both Regions with Auto Scaling groups for the web and application tiers. Asynchronously replicate static content between Regions using Amazon S3 cross-Region replication. Use an Amazon Route 53 DNS failover routing policy to direct users to the secondary site in us-west-1 in the event of an outage. Use Amazon DynamoDB global tables for the database tier.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use AWS CloudFormation StackSets to create the stacks in both Regions with Auto Scaling groups for the web and application tiers. Asynchronously replicate static content between Regions using Amazon S3 cross-Region replication. Use an Amazon Route 53 DNS failover routing policy to direct users to the secondary site in us-west-1 in the event of an outage Deploy an Amazon Aurora global database for the database tier.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use AWS Service Catalog to deploy the web and application servers in both Regions Asynchronously replicate static content between the two Regions using Amazon S3 cross-Region replication. Use Amazon Route 53 health checks to identify a primary Region failure and update the public DNS entry listing to the secondary Region in the event of an outage. Use Amazon RDS for MySQL with cross-Region replication for the database tier.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use AWS CloudFormation StackSets to create the stacks in both Regions using Auto Scaling groups for the web and application tiers. Asynchronously replicate static content between Regions using Amazon S3 cross-Region replication. Use Amazon CloudFront with static files in Amazon S3, and multi-Region origins for the front-end web tier. Use Amazon DynamoDB tables in each Region with scheduled backups to Amazon S3.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 211314,
          "date": "Fri 24 Sep 2021 22:43",
          "username": "porlarowlGmail78",
          "content": "I support A. <br>because the platform designed for NoSQL... should be DynamoDB global table.Agree with A - https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GlobalTables.html",
          "upvote_count": "245",
          "selected_answers": ""
        },
        {
          "id": 211797,
          "date": "Sun 26 Sep 2021 16:59",
          "username": "Gmail78",
          "content": "Agree with A - https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GlobalTables.html",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 264465,
          "date": "Sun 03 Oct 2021 19:42",
          "username": "Ebi",
          "content": "A for sure",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 502939,
          "date": "Thu 16 Dec 2021 14:21",
          "username": "Binoj_1985",
          "content": "Service catalog not required since cross account is not required. So CFT is enough. Also, failover for website can be done by Route53",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 498332,
          "date": "Fri 10 Dec 2021 06:44",
          "username": "cldy",
          "content": "A.  Use AWS CloudFormation StackSets to create the stacks in both Regions with Auto Scaling groups for the web and application tiers. Asynchronously replicate static content between Regions using Amazon S3 cross-Region replication. Use an Amazon Route 53 DNS failover routing policy to direct users to the secondary site in us-west-1 in the event of an outage. Use Amazon DynamoDB global tables for the database tier.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491988,
          "date": "Thu 02 Dec 2021 00:01",
          "username": "AzureDP900",
          "content": "A is right",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 488660,
          "date": "Sun 28 Nov 2021 02:28",
          "username": "acloudguru",
          "content": "Dynamo DB is NoSql solution, Cloudformation is for Iaas,for C, use service catalogue for what?",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 443332,
          "date": "Thu 04 Nov 2021 07:56",
          "username": "andylogan",
          "content": "It's A with NoSQL DynamoDB",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436312,
          "date": "Sat 30 Oct 2021 09:33",
          "username": "tgv",
          "content": "AAA<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433567,
          "date": "Thu 28 Oct 2021 07:25",
          "username": "blackgamer",
          "content": "A.  Dynamo DB is NoSql solution",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413297,
          "date": "Thu 21 Oct 2021 04:29",
          "username": "WhyIronMan",
          "content": "I'll go with A",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 355915,
          "date": "Tue 19 Oct 2021 17:15",
          "username": "Waiweng",
          "content": "it's A",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 293361,
          "date": "Tue 19 Oct 2021 13:57",
          "username": "Kian1",
          "content": "going with A",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 265241,
          "date": "Sat 16 Oct 2021 13:28",
          "username": "kopper2019",
          "content": "A for sure, NoSQL and Failover policy using Route 53",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 255844,
          "date": "Sat 02 Oct 2021 06:16",
          "username": "Bulti",
          "content": "A is correct",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 244881,
          "date": "Tue 28 Sep 2021 11:11",
          "username": "rscloud",
          "content": "A<br>Route53 DNS Failover, DynamoDB global table fulfill req.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 232613,
          "date": "Mon 27 Sep 2021 16:04",
          "username": "jackdryan",
          "content": "I'll go with A",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#633",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company hosts a blog post application on AWS using Amazon API Gateway, Amazon DynamoDB, and AWS Lambda. The application currently does not use<br>API keys to authorize requests. The API model is as follows:<br>GET/posts/[postid] to get post details<br>GET/users[userid] to get user details<br>GET/comments/[commentid] to get comments details<br>The company has noticed users are actively discussing topics in the comments section, and the company wants to increase user engagement by marking the comments appears in real time.<br>Which design should be used to reduce comment latency and improve user experience?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#633",
          "answers": [
            {
              "choice": "<p>A. Use edge-optimized API with Amazon CloudFront to cache API responses.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Modify the blog application code to request GET comment[commented] every 10 seconds.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use AWS AppSync and leverage WebSockets to deliver comments.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Change the concurrency limit of the Lambda functions to lower the API response time.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 212935,
          "date": "Mon 20 Sep 2021 02:37",
          "username": "lionoA_New_Guybeso",
          "content": "C, https://aws.amazon.com/appsync/Why this one?AWS AppSync is a fully managed service supports real-time updates.",
          "upvote_count": "1614",
          "selected_answers": ""
        },
        {
          "id": 216665,
          "date": "Thu 23 Sep 2021 22:21",
          "username": "A_New_Guy",
          "content": "Why this one?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 218369,
          "date": "Fri 24 Sep 2021 01:24",
          "username": "beso",
          "content": "AWS AppSync is a fully managed service supports real-time updates.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 284672,
          "date": "Fri 08 Oct 2021 07:25",
          "username": "Ebi",
          "content": "I go with C",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 632539,
          "date": "Sun 17 Jul 2022 12:58",
          "username": "CloudHandsOnCloudHandsOn",
          "content": "I believe that it is D (at first, thought it was C). Here is my explanation:<br>For short term, you can choose C, and just increase PC on the Lambda to handle load as it increases. However, the question asks about best DESIGN which is more long term -> \\\"Which design should be adopted..\\\". Over time, you may be finding yourself stuck with paying more in costs if you go with C.  Smart Guy goes with D.  Answer is DDDDDDD!!!!I wish they had an edit button :(. CORRECTION below:<br><br>I believe that it is C (at first, thought it was D). Here is my explanation:<br>For short term, you can choose D, and just increase PC on the Lambda to handle load as it increases. However, the question asks about best DESIGN which is more long term -> \\\"Which design should be adopted..\\\". Over time, you may be finding yourself stuck with paying more in costs if you go with D.  Smart Guy goes with C.  Answer is CCCCCCC!!!!",
          "upvote_count": "12",
          "selected_answers": ""
        },
        {
          "id": 632542,
          "date": "Sun 17 Jul 2022 13:08",
          "username": "CloudHandsOn",
          "content": "I wish they had an edit button :(. CORRECTION below:<br><br>I believe that it is C (at first, thought it was D). Here is my explanation:<br>For short term, you can choose D, and just increase PC on the Lambda to handle load as it increases. However, the question asks about best DESIGN which is more long term -> \\\"Which design should be adopted..\\\". Over time, you may be finding yourself stuck with paying more in costs if you go with D.  Smart Guy goes with C.  Answer is CCCCCCC!!!!",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 626572,
          "date": "Sun 03 Jul 2022 15:32",
          "username": "aandc",
          "content": "keyword \\\"in real time\\\" -> APPSYNC",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 582780,
          "date": "Fri 08 Apr 2022 10:58",
          "username": "Hasitha99",
          "content": "AppSync is graphql based solution that supports real-time updates.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 576684,
          "date": "Mon 28 Mar 2022 09:17",
          "username": "kenchou73",
          "content": "https://docs.aws.amazon.com/appsync/latest/devguide/graphql-overview.html",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 494954,
          "date": "Mon 06 Dec 2021 07:53",
          "username": "cldy",
          "content": "C.  Use AWS AppSync and leverage WebSockets to deliver comments.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 491989,
          "date": "Thu 02 Dec 2021 00:04",
          "username": "AzureDP900",
          "content": "I will go with C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 484885,
          "date": "Tue 23 Nov 2021 10:11",
          "username": "backfringe",
          "content": "I go with C <br>https://docs.aws.amazon.com/appsync/latest/devguide/real-time-websocket-client.html",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 482607,
          "date": "Sat 20 Nov 2021 15:21",
          "username": "ElGuru",
          "content": "\\\"Which design should be adopted to enhance user experience and decrease comment latency?\\\"<br><br>Having to change to GraphQL shouldn't be relevant since the question doesn't ask about the Easiest way.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 443336,
          "date": "Sun 07 Nov 2021 01:05",
          "username": "andylogan",
          "content": "It's C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 440578,
          "date": "Tue 02 Nov 2021 01:14",
          "username": "Suresh108",
          "content": "CCCCCC <br><br>https://aws.amazon.com/blogs/mobile/appsync-realtime/",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 434865,
          "date": "Tue 02 Nov 2021 00:02",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 413310,
          "date": "Tue 19 Oct 2021 06:02",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 366488,
          "date": "Tue 12 Oct 2021 00:29",
          "username": "oscargeeWhyIronManblackgamerblackgamer",
          "content": "Not C! The question says: Get xxx means it is using RESTful query. Websocket doen't have such thing.It's C. .. Go study TCP/IP and HTTP protocols and leave us alone pleaseThe problem with C is that AppSync designed for GraphQL but the question is about REST api. Moreover, Oscar free is right that websocket doesn’t work in that way. Only polling is solution here if not rewriting the app.No solution seems to be complete here, but I will go with D as it is not at least wrong although not a complete solution.",
          "upvote_count": "4311",
          "selected_answers": ""
        },
        {
          "id": 413309,
          "date": "Tue 12 Oct 2021 03:26",
          "username": "WhyIronManblackgamerblackgamer",
          "content": "It's C. .. Go study TCP/IP and HTTP protocols and leave us alone pleaseThe problem with C is that AppSync designed for GraphQL but the question is about REST api. Moreover, Oscar free is right that websocket doesn’t work in that way. Only polling is solution here if not rewriting the app.No solution seems to be complete here, but I will go with D as it is not at least wrong although not a complete solution.",
          "upvote_count": "311",
          "selected_answers": ""
        },
        {
          "id": 433575,
          "date": "Thu 28 Oct 2021 12:11",
          "username": "blackgamerblackgamer",
          "content": "The problem with C is that AppSync designed for GraphQL but the question is about REST api. Moreover, Oscar free is right that websocket doesn’t work in that way. Only polling is solution here if not rewriting the app.No solution seems to be complete here, but I will go with D as it is not at least wrong although not a complete solution.",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 433581,
          "date": "Sat 30 Oct 2021 16:30",
          "username": "blackgamer",
          "content": "No solution seems to be complete here, but I will go with D as it is not at least wrong although not a complete solution.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 355923,
          "date": "Sat 09 Oct 2021 16:49",
          "username": "Waiweng",
          "content": "it's C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 344059,
          "date": "Sat 09 Oct 2021 10:16",
          "username": "gsw",
          "content": "aws generally don't recommend changing the entire architecture for a solution unless specified in the question which makes C a difficult choice... D makes more sense",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#634",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has a VPC with two domain controllers running Active Directory in the default configuration. The VPC DHCP options set is configured to use the IP addresses of the two domain controllers. There is a VPC interface endpoint defined; but instances within the VPC are not able to resolve the private endpoint addresses.<br>Which strategies would resolve this issue? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: AB</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#634",
          "answers": [
            {
              "choice": "<p>A. Define an outbound Amazon Route 53 Resolver. Set a conditional forward rule for the Active Directory domain to the Active Directory servers. Update the VPC DHCP options set to AmazonProvidedDNS.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Update the DNS service on the Active Directory servers to forward all non-authoritative queries to the VPC Resolver.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Define an inbound Amazon Route 53 Resolver. Set a conditional forward rule for the Active Directory domain to the Active Directory servers. Update the VPC DHCP options set to AmazonProvidedDNS.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Update the DNS service on the client instances to split DNS queries between the Active Directory servers and the VPC Resolver.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>E. Update the DNS service on the Active Directory servers to forward all queries to the VPC Resolver.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 246669,
          "date": "Sat 25 Sep 2021 05:22",
          "username": "MichaelRTonyGeMichaelR",
          "content": "I think its A, B. AwsDNS is set in DHCP options.AWS resources resolve other resources as a result, but forward AD domain queries to AD servers via an Outbound resolver endpoint.Users hitting the AD servers from on-prem would then have non-authoritative queries pushed to the AWS resolver.A is incorrect, an outbound resolver is for DNS queries that you want to forward outside your VPC.  For example, this is used for resolving outside domain names.as far as I know, you can't create a forward rule in an inbound resolver. Correct me if I\\\"m wrong",
          "upvote_count": "2914",
          "selected_answers": ""
        },
        {
          "id": 370624,
          "date": "Mon 25 Oct 2021 00:06",
          "username": "TonyGe",
          "content": "A is incorrect, an outbound resolver is for DNS queries that you want to forward outside your VPC.  For example, this is used for resolving outside domain names.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 246671,
          "date": "Thu 30 Sep 2021 19:57",
          "username": "MichaelR",
          "content": "as far as I know, you can't create a forward rule in an inbound resolver. Correct me if I\\\"m wrong",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 212937,
          "date": "Wed 22 Sep 2021 10:35",
          "username": "liono",
          "content": "B &C are correct options",
          "upvote_count": "19",
          "selected_answers": ""
        },
        {
          "id": 708701,
          "date": "Mon 31 Oct 2022 20:57",
          "username": "Cal88Cal88",
          "content": "The correct answer is AB as most comments are stating.<br><br>For anyone who thinks that A is not correct because outbound resolver will forward to on-premise DNS server.<br>Remember , our goal is to resolve records in our domain which in the question is hosted in the AD so we need to forward these requests if they don't match the private hosts for the VPC. <br>The DNS being hosted inside the VPC or on premise is not relevant since you are specifying an ip in the forward rule , so technically you can forward to the AD which inside the VPC<br>in AWS Docs:<br>https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resolver-forwarding-outbound-queries.html#resolver-forwarding-outbound-queries-rule-values<br><br>Target IP addresses<br>When a DNS query matches the name that you specify in Domain name, the outbound endpoint forwards the query to the IP addresses that you specify here. These are typically the IP addresses for DNS resolvers on your network.<br><br>so it could be any IP weather its inside or outside the VPCNotice in the documentation it says typically its inside your network , it does not mean this is the only way to do it but it means that in most cases this what will happen.<br>The use case in the question applies to using outbound resolver",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 708704,
          "date": "Mon 31 Oct 2022 21:05",
          "username": "Cal88",
          "content": "Notice in the documentation it says typically its inside your network , it does not mean this is the only way to do it but it means that in most cases this what will happen.<br>The use case in the question applies to using outbound resolver",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 700992,
          "date": "Fri 21 Oct 2022 16:30",
          "username": "nsvijay04b1",
          "content": "ABis answer. why?<br>A) correct-outbound resolver has conditional fwd rules to resolve hybridDNS + VPC DHCP options must be reverted to other EC2 can resolve DNS<br>B) correct - AD servers to use inbound resolver for non-authorititative queries to reach instances<br>C) wrong -There is no conditional fwd rules for inbound resolvers<br>D) wrong - splitting DNS server based on type of app seems illogical for me<br>E) wrong -AD servers need to resolve internal queries as well, not makes sense",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: AB"
        },
        {
          "id": 648823,
          "date": "Fri 19 Aug 2022 10:33",
          "username": "RVD",
          "content": "To resolve the AWS services CNAME it needs to forward the queries to AWS DNS which on prem DNS trying to forward, here question is about ec2 is not able to resolve the endpoint DNS. EC2->ADDNS->Inboud Resolver.",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: BC"
        },
        {
          "id": 640056,
          "date": "Sun 31 Jul 2022 12:15",
          "username": "Enigmaaaaaa",
          "content": "AB<br>First we set all Instances to forward all queries to AmazonDNS (to resolve private interface names) and then other queries *.example.corp.com will be forwarded with the outbound endpoint to the AD servers",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 557096,
          "date": "Sun 27 Feb 2022 02:33",
          "username": "Sonujunko",
          "content": "A , B <br>https://aws.amazon.com/blogs/networking-and-content-delivery/integrating-your-directory-services-dns-resolution-with-amazon-route-53-resolvers/",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: AB"
        },
        {
          "id": 520732,
          "date": "Mon 10 Jan 2022 09:12",
          "username": "pititcu667pititcu667",
          "content": "Guys i initially said a.b then I noticed the domain controllers are inside the vpc .so changing to bc.I made a mistake it's ab forwarding requires outbound.",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 554865,
          "date": "Wed 23 Feb 2022 21:40",
          "username": "pititcu667",
          "content": "I made a mistake it's ab forwarding requires outbound.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496406,
          "date": "Wed 08 Dec 2021 01:06",
          "username": "AzureDP900",
          "content": "I will go with A & B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 475997,
          "date": "Thu 11 Nov 2021 06:25",
          "username": "Liongeek",
          "content": "B&C for me. Same question appeared on Udemy test",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 463729,
          "date": "Sun 07 Nov 2021 14:12",
          "username": "Salmariaz",
          "content": "Should be A and B , as outbound endpoint not necessarily mean that the servers should be onprem for conditional forwarder rule to kick in, instead they can reside in another VPC too and it allows DNS queries from your VPC to the VPC where the AD servers run.<br>Option C would also work with an inbound endpoint pointing to the 2 AD server IPs, but definitely not with forwarding rules. So clearly ruled out.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 443341,
          "date": "Sun 07 Nov 2021 03:28",
          "username": "andylogan",
          "content": "It's A, B - An outbound resolver",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 434870,
          "date": "Sat 06 Nov 2021 20:26",
          "username": "tgv",
          "content": "AAA BBB<br>---<br>https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resolver.html",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 433582,
          "date": "Tue 02 Nov 2021 11:46",
          "username": "blackgamer",
          "content": "The answer is A & B.  Thanks Waiweng for useful reference.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 427597,
          "date": "Mon 01 Nov 2021 06:56",
          "username": "pablobairat",
          "content": "B & C<br>\\\"An outbound resolver is for DNS queries that you want to forward outside your VPC\\\" -> So A is discarted since everything is inside the VPC",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413311,
          "date": "Sat 30 Oct 2021 04:24",
          "username": "WhyIronMan",
          "content": "I'll go with B,C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 409689,
          "date": "Fri 29 Oct 2021 21:14",
          "username": "botohin687Shenannigan",
          "content": "Answer A &B <br>https://aws.amazon.com/blogs/aws/new-amazon-route-53-resolver-for-hybrid-clouds/I could see this being correct if the domain controllers were hosted on premise but in this case the DC's are hosted on the VPC as such I am going with:<br>BC",
          "upvote_count": "22",
          "selected_answers": ""
        },
        {
          "id": 418050,
          "date": "Sun 31 Oct 2021 04:04",
          "username": "Shenannigan",
          "content": "I could see this being correct if the domain controllers were hosted on premise but in this case the DC's are hosted on the VPC as such I am going with:<br>BC",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#635",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has a photo sharing social networking application. To provide a consistent experience for users, the company performs some image processing on the photos uploaded by users before publishing on the application. The image processing is implemented using a set of Python libraries.<br>The current architecture is as follows:<br>✑ The image processing Python code runs in a single Amazon EC2 instance and stores the processed images in an Amazon S3 bucket named ImageBucket.<br>✑ The front-end application, hosted in another bucket, loads the images from ImageBucket to display to users.<br>With plans for global expansion, the company wants to implement changes in its existing architecture to be able to scale for increased demand on the application and reduce management complexity as the application scales.<br>Which combination of changes should a solutions architect make? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#635",
          "answers": [
            {
              "choice": "<p>A. Place the image processing EC2 instance into an Auto Scaling group.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use AWS Lambda to run the image processing tasks.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use Amazon Rekognition for image processing.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use Amazon CloudFront in front of ImageBucket.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Deploy the applications in an Amazon ECS cluster and apply Service Auto Scaling.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 218878,
          "date": "Sun 26 Sep 2021 23:45",
          "username": "cpdDashLmemester",
          "content": "\\\"reduce management complexity as the application scales\\\"; both A and E involves managing underlying host (unless its Fargate for E). I'd use lambda to answer this requirement i.e., B.  And D is obvious answer.The question doesn't say if the image processing can complete within a lambda's timeout period of 15 minutes or less. So the answer should be ADIt also doesn't say it can't...",
          "upvote_count": "2337",
          "selected_answers": ""
        },
        {
          "id": 396278,
          "date": "Sat 23 Oct 2021 03:02",
          "username": "DashLmemester",
          "content": "The question doesn't say if the image processing can complete within a lambda's timeout period of 15 minutes or less. So the answer should be ADIt also doesn't say it can't...",
          "upvote_count": "37",
          "selected_answers": ""
        },
        {
          "id": 404114,
          "date": "Tue 26 Oct 2021 19:24",
          "username": "memester",
          "content": "It also doesn't say it can't...",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 264454,
          "date": "Sun 10 Oct 2021 04:45",
          "username": "Ebi",
          "content": "Answer is BD,<br>B changes existing architecture from EC2 to Lambda with minimum management overhead",
          "upvote_count": "15",
          "selected_answers": ""
        },
        {
          "id": 715038,
          "date": "Thu 10 Nov 2022 09:21",
          "username": "Heer",
          "content": "The line from the question is super important that 'Company wants to make changes in its existing architecture ' and which is EC2 .So picking lambda would be an architecture changeSo A & D looks to be a better choice as per the question ,else my personal preference would be Lambda",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 653300,
          "date": "Mon 29 Aug 2022 07:43",
          "username": "kadevkadevkadev",
          "content": "Because AWS is the best , AWS can do anything ( AWS said) lol =>Lambda can process image ( because first sentence => dont care about timeout or many libs ..) => BAfter kidding, <br>\\\"to scale for increased demand on the application and reduce management complexity \\\"<br>- Auto scaling with Ec2, or Ecsfor processing event from S3, need add more modules: SQS, CW event, lambda to audjust Scaling size<br>=> Lambda is the best optionwe are in exam, not your project.",
          "upvote_count": "111",
          "selected_answers": ""
        },
        {
          "id": 653302,
          "date": "Mon 29 Aug 2022 07:47",
          "username": "kadev",
          "content": "After kidding, <br>\\\"to scale for increased demand on the application and reduce management complexity \\\"<br>- Auto scaling with Ec2, or Ecsfor processing event from S3, need add more modules: SQS, CW event, lambda to audjust Scaling size<br>=> Lambda is the best option",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 653301,
          "date": "Mon 29 Aug 2022 07:44",
          "username": "kadev",
          "content": "we are in exam, not your project.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 555103,
          "date": "Thu 24 Feb 2022 07:47",
          "username": "jyrajan69",
          "content": "D is definitely one choice. For those choosing B, you are considering the complexity. The question states that currently there are a lot of python libraries needed to process, so if using B then you must configure this as layers that Lambda must pull in, adding to the complexity. Now with answer A, you are catering for growth with scaling the EC2 instances, not adding any more complexity and that should be A.  Answer A and D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 506699,
          "date": "Wed 22 Dec 2021 05:36",
          "username": "tkanmani76",
          "content": "D for sure. It's not A as its mentioned that firm wants to change the architecture. Between B and E, Lambda would be a good choice and more operationally efficient over ECS.Its much faster when it comes to scaling over ECS. Hence will choose Lambda (Choice B) over ECS.<br>https://prismatic.io/blog/why-we-moved-from-lambda-to-ecs/ - This is an interesting case study on the problems faced by Prismatic with Lambda and why they moved to ECS - which provide a perspective. However in our case Lambda will do the work.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491998,
          "date": "Thu 02 Dec 2021 00:14",
          "username": "AzureDP900",
          "content": "B,D is right",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 443342,
          "date": "Fri 05 Nov 2021 17:35",
          "username": "andylogan",
          "content": "It's B, D - minimum management overhead",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 438949,
          "date": "Fri 05 Nov 2021 07:39",
          "username": "DerekKey",
          "content": "B&D - we are using such solution in two environments",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436323,
          "date": "Thu 04 Nov 2021 14:42",
          "username": "tgv",
          "content": "BBB DDD<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 433601,
          "date": "Wed 03 Nov 2021 20:41",
          "username": "blackgamer",
          "content": "E is okay, but B is more suitable to minimize management overhead. I will go with B and D. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 415499,
          "date": "Tue 02 Nov 2021 17:34",
          "username": "jobe42",
          "content": "In fact that we can change the existing architecture:<br>A. ) Will not solve the scaling problem, more EC2 instances have somehow cooridinate the tasks, no SQS or DynamoDB here for processing information => NOK<br>B. ) S3 triggers a Lambda function for processing => OK<br>C. ) Recognition not suitable for \\\"processing\\\", just for analyzing. you can't change the pictures (scale, add watermark etc.) just find out if this is a dog or a copyrighted dog => NOK<br>D. ) Obvious.. => OK<br>E. ) Would work, but needs more to do than B => NOK<br><br>== B & D",
          "upvote_count": "8",
          "selected_answers": ""
        },
        {
          "id": 413312,
          "date": "Sun 31 Oct 2021 12:39",
          "username": "WhyIronMan",
          "content": "I'll go with B,D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 375008,
          "date": "Thu 21 Oct 2021 07:35",
          "username": "tvs",
          "content": "BD -Why not A - because you need to patch and other maintenance on EC2 instances.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 374572,
          "date": "Wed 20 Oct 2021 20:49",
          "username": "zolthar_z",
          "content": "The answer is B and D. . D is obvious. B the question give the answer (execute on process per image, if there is no new image no process should run, python and libraries) is lambda",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 356120,
          "date": "Wed 20 Oct 2021 16:23",
          "username": "Waiwengstudent22",
          "content": "it's A&Dimplement changes to it's existing architecture and reduce management complexityB,D<br>Lambda will reduce management overhead better. EC2 with ASG will still have some overhead for patching etc.",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 458988,
          "date": "Sat 06 Nov 2021 22:46",
          "username": "student22",
          "content": "B,D<br>Lambda will reduce management overhead better. EC2 with ASG will still have some overhead for patching etc.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 298043,
          "date": "Tue 19 Oct 2021 14:07",
          "username": "gpark",
          "content": "DE<br>===<br>The question asks about application tier, not processing tier..<br>So, AB is quite doubtful to select.",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#636",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has a web application that allows users to upload short videos. The videos are stored on Amazon EBS volumes and analyzed by custom recognition software for categorization.<br>The website contains static content that has variable traffic with peaks in certain months. The architecture consists of Amazon EC2 instances running in an Auto<br>Scaling group for the web application and EC2 instances running in an Auto Scaling group to process an Amazon SQS-queue. The company wants to re-architect the application to reduce operational overhead using AWS managed services where possible and remove dependencies on third-party software.<br>Which solution meets these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#636",
          "answers": [
            {
              "choice": "<p>A. Use Amazon ECS containers for the web application and Spot instances for the Scaling group that processes the SQS queue. Replace the custom software with Amazon Rekognition to categorize the videos.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Store the uploaded videos in Amazon EFS and mount the file system to the EC2 instances for the web application. Process the SQS queue with an AWS Lambda function that calls the Amazon Rekognition API to categorize the videos.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Host the web application in Amazon S3. Store the uploaded videos in Amazon S3. Use S3 event notification to publish events to the SQS queue. Process the SQS queue with an AWS Lambda function that call the Amazon Rekognition API to categorize the videos.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use AWS Elastic Beanstalk to launch EC2 instances in an Auto Scaling group for the application and launch a worker environment to process the SQS queue. Replace the custom software with Amazon Rekognition to categorize the videos.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 211806,
          "date": "Sun 26 Sep 2021 11:22",
          "username": "Gmail78",
          "content": "C is more realistic",
          "upvote_count": "14",
          "selected_answers": ""
        },
        {
          "id": 264448,
          "date": "Fri 15 Oct 2021 20:05",
          "username": "Ebi",
          "content": "I will go with C",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 638929,
          "date": "Fri 29 Jul 2022 02:34",
          "username": "hilft",
          "content": "C is full serverless",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 622808,
          "date": "Sun 26 Jun 2022 22:32",
          "username": "kangtamo",
          "content": "Agree with C: S3.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 571837,
          "date": "Sun 20 Mar 2022 20:59",
          "username": "Ni_yot",
          "content": "Yep. C is correct. they want to do away with 3rd party software and use AWS managed services",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 492002,
          "date": "Thu 02 Dec 2021 00:23",
          "username": "AzureDP900",
          "content": "c is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443343,
          "date": "Sat 06 Nov 2021 02:21",
          "username": "andylogan",
          "content": "It's C - reduce operational overhead.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436330,
          "date": "Wed 03 Nov 2021 21:00",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433603,
          "date": "Wed 03 Nov 2021 06:47",
          "username": "blackgamer",
          "content": "C for sure, managed services.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413314,
          "date": "Sun 31 Oct 2021 23:21",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 366523,
          "date": "Thu 28 Oct 2021 04:16",
          "username": "oscargeeChibuzo1devtest01",
          "content": "C? How can you host an app in S3? S3 is for static data.\\\"the website contains static content\\\" Answer is C buddy!!Question is not clearly. \\\"Contain\\\"not\\\"static website\\\"",
          "upvote_count": "222",
          "selected_answers": ""
        },
        {
          "id": 400414,
          "date": "Sat 30 Oct 2021 18:17",
          "username": "Chibuzo1devtest01",
          "content": "\\\"the website contains static content\\\" Answer is C buddy!!Question is not clearly. \\\"Contain\\\"not\\\"static website\\\"",
          "upvote_count": "22",
          "selected_answers": ""
        },
        {
          "id": 659638,
          "date": "Mon 05 Sep 2022 02:16",
          "username": "devtest01",
          "content": "Question is not clearly. \\\"Contain\\\"not\\\"static website\\\"",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 365226,
          "date": "Wed 27 Oct 2021 16:37",
          "username": "mustpassla",
          "content": "C, reduce operational overhead.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 356126,
          "date": "Tue 26 Oct 2021 04:34",
          "username": "Waiweng",
          "content": "it's C",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 296591,
          "date": "Fri 22 Oct 2021 13:24",
          "username": "kiev",
          "content": "Full House says C is the answer",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 293396,
          "date": "Fri 22 Oct 2021 10:26",
          "username": "Kian1",
          "content": "going with C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 292218,
          "date": "Thu 21 Oct 2021 06:09",
          "username": "LB",
          "content": "C for me",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 256015,
          "date": "Fri 15 Oct 2021 08:27",
          "username": "Bulti",
          "content": "C is the right answer",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#637",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A retail company processes point-of-sale data on application servers in its data center and writes outputs to an Amazon DynamoDB table. The data center is connected to the company's VPC with an AWS Direct Connect (DX) connection, and the application servers require a consistent network connection at speeds greater than 2 Gbps.<br>The company decides that the DynamoDB table needs to be highly available and fault tolerant. The company policy states that the data should be available across two regions.<br>What changes should the company make to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: A</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#637",
          "answers": [
            {
              "choice": "<p>A. Establish a second DX connection for redundancy. Use DynamoDB global tables to replicate data to a second Region. Modify the application to fail over to the second Region.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use an AWS managed VPN as a backup to DX. Create an identical DynamoDB table in a second Region. Modify the application to replicate data to both Regions.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Establish a second DX connection for redundancy. Create an identical DynamoDB table in a second Region. Enable DynamoDB auto scaling to manage throughput capacity. Modify the application to write to the second Region.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use AWS managed VPN as a backup to DX. Create an identical DynamoDB table in a second Region. Enable DynamoDB streams to capture changes to the table. Use AWS Lambda to replicate changes to the second Region.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 211811,
          "date": "Mon 20 Sep 2021 16:18",
          "username": "Gmail78",
          "content": "A - https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GlobalTables.html",
          "upvote_count": "15",
          "selected_answers": ""
        },
        {
          "id": 365229,
          "date": "Sun 31 Oct 2021 23:30",
          "username": "mustpassla",
          "content": "A, speeds greater than 2 Gbps.",
          "upvote_count": "8",
          "selected_answers": ""
        },
        {
          "id": 635827,
          "date": "Sun 24 Jul 2022 02:47",
          "username": "hilft",
          "content": "A.  two region - > \\\"global\\\"",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 553363,
          "date": "Tue 22 Feb 2022 02:09",
          "username": "jyrajan69",
          "content": "Only A gives you the Global Table option for Dynamo so definitely the answer",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 496410,
          "date": "Wed 08 Dec 2021 01:10",
          "username": "AzureDP900",
          "content": "A is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492001,
          "date": "Thu 02 Dec 2021 00:22",
          "username": "AzureDP900",
          "content": "A for sure",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443346,
          "date": "Sun 07 Nov 2021 12:24",
          "username": "andylogan",
          "content": "It's A - Managed VPN max throughput 1.25Gbps",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436331,
          "date": "Fri 05 Nov 2021 18:20",
          "username": "tgv",
          "content": "AAA<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413315,
          "date": "Fri 05 Nov 2021 09:45",
          "username": "WhyIronMan",
          "content": "I'll go with A",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 356130,
          "date": "Thu 28 Oct 2021 08:25",
          "username": "Waiweng",
          "content": "it;s A",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 331489,
          "date": "Wed 27 Oct 2021 02:59",
          "username": "PredaOvde",
          "content": "A say \\\"modify the application to fail over...\\\" . That makes no sense.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 321735,
          "date": "Wed 20 Oct 2021 17:10",
          "username": "alisyech",
          "content": "A for sure",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 317673,
          "date": "Tue 19 Oct 2021 22:38",
          "username": "bulapapa",
          "content": "A is correct <br>VPN doesn't meet the bandwidth. The maximum bandwidth of VPN is 1.25Gbps.<br>https://docs.aws.amazon.com/vpn/latest/s2svpn/vpn-limits.html",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 293405,
          "date": "Tue 19 Oct 2021 18:01",
          "username": "Kian1",
          "content": "going with A",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 292221,
          "date": "Sat 16 Oct 2021 06:45",
          "username": "LB",
          "content": "A - Dynamo DB global tables and redundant Direct connection",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 273449,
          "date": "Thu 14 Oct 2021 16:03",
          "username": "kopper2019",
          "content": "A, VPN cannot be used since they required stable and consistent speed and DynamoDB global tables",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 264445,
          "date": "Thu 14 Oct 2021 13:47",
          "username": "Ebi",
          "content": "Answer is A",
          "upvote_count": "4",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#638",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is using AWS CloudFormation as its deployment tool for all application. It stages all application binaries and templates within Amazon S3 bucket with versioning enabled. Developers have access to an Amazon EC2 instance that hosts the integrated development (IDE). The Developers download the application binaries from Amazon S3 to the EC2 instance, make changes, and upload the binaries to an S3 bucket after running the unit tests locally. The developers want to improve the existing deployment mechanism and implement CI/CD using AWS CodePipeline.<br>The developers have the following requirements:<br>✑ Use AWS CodeCommit for source control.<br>✑ Automate unit testing and security scanning.<br>✑ Alert the Developers when unit tests fail.<br>✑ Turn application features on and off, and customize deployment dynamically as part of CI/CD. <br>✑ Have the lead Developer provide approval before deploying an application.<br>Which solution will meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: A</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#638",
          "answers": [
            {
              "choice": "<p>A. Use AWS CodeBuild to run tests and security scans. Use an Amazon EventBridge rule to send Amazon SNS alerts to the Developers when unit tests fail. Write AWS Cloud Developer kit (AWS CDK) constructs for different solution features, and use a manifest file to turn features on and off in the AWS CDK application. Use a manual approval stage in the pipeline to allow the lead Developer to approve applications.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use AWS Lambda to run unit tests and security scans. Use Lambda in a subsequent stage in the pipeline to send Amazon SNS alerts to the developers when unit tests fail. Write AWS Amplify plugins for different solution features and utilize user prompts to turn features on and off. Use Amazon SES in the pipeline to allow the lead developer to approve applications.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use Jenkins to run unit tests and security scans. Use an Amazon EventBridge rule in the pipeline to send Amazon SES alerts to the developers when unit tests fail. Use AWS CloudFormation nested stacks for different solution features and parameters to turn features on and off. Use AWS Lambda in the pipeline to allow the lead developer to approve applications.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use AWS CodeDeploy to run unit tests and security scans. Use an Amazon CloudWatch alarm in the pipeline to send Amazon SNS alerts to the developers when unit tests fail. Use Docker images for different solution features and the AWS CLI to turn features on and off. Use a manual approval stage in the pipeline to allow the lead developer to approve applications.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 211824,
          "date": "Mon 20 Sep 2021 01:45",
          "username": "Gmail78certainly",
          "content": "UI testing (AWS Lambda and AWS CodeBuild). Not sure B is correct, Jenkins is an alternative of AWS Pipeline.A seems the more close one.A for sure. B is incorrect. 1. Lambda limit of 15 min make it a poor candidate for running unit tests and security scans. AWS Amplify is used for onboarding, ml, rt-collaboration, doesn't seem to be good fit here",
          "upvote_count": "165",
          "selected_answers": ""
        },
        {
          "id": 304517,
          "date": "Mon 25 Oct 2021 04:14",
          "username": "certainly",
          "content": "A for sure. B is incorrect. 1. Lambda limit of 15 min make it a poor candidate for running unit tests and security scans. AWS Amplify is used for onboarding, ml, rt-collaboration, doesn't seem to be good fit here",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 284570,
          "date": "Fri 15 Oct 2021 00:16",
          "username": "Ebi",
          "content": "I go with A",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 701024,
          "date": "Fri 21 Oct 2022 17:23",
          "username": "nsvijay04b1",
          "content": "A. <br>->eventbridge handling codebuild state change and trigger SNShttps://docs.aws.amazon.com/codebuild/latest/userguide/sample-build-notifications.html<br>-> manual approval stage in pipeline",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 639766,
          "date": "Sat 30 Jul 2022 19:42",
          "username": "xinhui",
          "content": "I will also go with A , AWS CodeBuild is a fully managed continuous integration service that compiles source code, runs tests, and produces software packages that are ready to deploy.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 636910,
          "date": "Mon 25 Jul 2022 20:44",
          "username": "hilft",
          "content": "A.  Codebuild is the only option here",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 596141,
          "date": "Mon 02 May 2022 19:23",
          "username": "tartarus23",
          "content": "A.  CodeBuild is the AWS managed service for unit tests and scans. I highly doubt AWS will promote third party services such as Jenkins, instead of their own AWS services.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 568030,
          "date": "Tue 15 Mar 2022 01:34",
          "username": "Hari008",
          "content": "Why on the earth AWS promote Jenkins instead of their own product",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 551581,
          "date": "Sun 20 Feb 2022 07:11",
          "username": "mousedolly2002",
          "content": "Should be A",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492003,
          "date": "Thu 02 Dec 2021 00:25",
          "username": "AzureDP900",
          "content": "A code build and lead approval is key!",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443347,
          "date": "Sat 06 Nov 2021 01:31",
          "username": "andylogan",
          "content": "It's A with CDK as integrated development (IDE)",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436332,
          "date": "Wed 03 Nov 2021 17:17",
          "username": "tgv",
          "content": "AAA<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433617,
          "date": "Wed 03 Nov 2021 09:01",
          "username": "blackgamer",
          "content": "Clearly A. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413317,
          "date": "Sun 31 Oct 2021 05:44",
          "username": "WhyIronMan",
          "content": "I'll go with A",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 365237,
          "date": "Sun 31 Oct 2021 04:21",
          "username": "mustpassla",
          "content": "A, major function of CodeBuild.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 362548,
          "date": "Wed 27 Oct 2021 02:56",
          "username": "victordun",
          "content": "A - Code build for testing",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 356167,
          "date": "Mon 25 Oct 2021 20:00",
          "username": "Waiweng",
          "content": "it's A",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 321736,
          "date": "Mon 25 Oct 2021 15:29",
          "username": "alisyech",
          "content": "i go with A",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#639",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>An IoT company has rolled out a fleet of sensors for monitoring temperatures in remote locations. Each device connects to AWS IoT Core and sends a message<br>30 seconds, updating an Amazon DynamoDB table. A System Administrator users AWS IoT to verify the devices are still sending messages to AWS IoT Core: the database is not updating.<br>What should a Solutions Architect check to determine why the database is not being updated?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#639",
          "answers": [
            {
              "choice": "<p>A. Verify the AWS IoT Device Shadow service is subscribed to the appropriate topic and is executing the AWS Lambda function.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Verify that AWS IoT monitoring shows that the appropriate AWS IoT rules are being executed, and that the AWS IoT rules are enabled with the correct rule actions.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Check the AWS IoT Fleet indexing service and verify that the thing group has the appropriate IAM role to update DynamoDB. <br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Verify that AWS IoT things are using MQTT instead of MQTT over WebSocket, then check that the provisioning has the appropriate policy attached.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 214960,
          "date": "Tue 21 Sep 2021 06:37",
          "username": "keosbeso",
          "content": "B, https://docs.aws.amazon.com/iot/latest/developerguide/iot-rules.htmlhttps://docs.aws.amazon.com/iot/latest/developerguide/monitoring_overview.html",
          "upvote_count": "183",
          "selected_answers": ""
        },
        {
          "id": 220325,
          "date": "Wed 29 Sep 2021 06:47",
          "username": "beso",
          "content": "https://docs.aws.amazon.com/iot/latest/developerguide/monitoring_overview.html",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 636262,
          "date": "Mon 25 Jul 2022 00:21",
          "username": "hilft",
          "content": "I thought it was C.  Forum goes for the B.  I guess the keyword here is \\\"IoT rules\\\".",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 626413,
          "date": "Sun 03 Jul 2022 06:58",
          "username": "aandc",
          "content": "keyword :IoT rules",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 492005,
          "date": "Thu 02 Dec 2021 00:31",
          "username": "AzureDP900",
          "content": "B perfect !",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443348,
          "date": "Sat 06 Nov 2021 23:23",
          "username": "andylogan",
          "content": "It's B - appropriate actions on the rule to write to DDB. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 434872,
          "date": "Wed 03 Nov 2021 22:17",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433626,
          "date": "Sat 30 Oct 2021 23:43",
          "username": "blackgamer",
          "content": "B is the answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413321,
          "date": "Fri 29 Oct 2021 06:30",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 407057,
          "date": "Sun 24 Oct 2021 19:32",
          "username": "Kopa",
          "content": "B, All others no reason to change in unexcpected way.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 365241,
          "date": "Sun 24 Oct 2021 19:20",
          "username": "mustpassla",
          "content": "Guess B. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 356321,
          "date": "Thu 21 Oct 2021 09:53",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 293416,
          "date": "Fri 08 Oct 2021 23:29",
          "username": "Kian1",
          "content": "going for B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 259115,
          "date": "Wed 06 Oct 2021 14:06",
          "username": "Ebi",
          "content": "Answer is B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 256023,
          "date": "Wed 06 Oct 2021 12:06",
          "username": "Bulti",
          "content": "Answer is B. . Not C because Fleet Group index is for querying thing group not updating.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 255799,
          "date": "Sun 03 Oct 2021 20:01",
          "username": "petebear55",
          "content": "KNOWING HOW SLIPPERY AWS CAN BE AND HOW THEY LIKE TO THROW A OBVIOUS ANSWER IN THERE SOMETIMES .. WHEN WERE PROGRAMMED TO LOOK HARDER... IT MAY BE SIMPLY C !! ... Given experience of similar questions i may actually choose C for this.However in all honesty any of the answers could be the right 1. So C for me",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 244965,
          "date": "Fri 01 Oct 2021 13:53",
          "username": "T14102020",
          "content": "Correct is B.  appropriate actions",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 232626,
          "date": "Thu 30 Sep 2021 13:50",
          "username": "cloudgc",
          "content": "B - choose the appropriate actions on the rule. in this case write to DDB. <br>https://docs.aws.amazon.com/iot/latest/developerguide/iot-rule-actions.html",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#640",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>An enterprise company is using a multi-account AWS strategy. There are separate accounts for development staging and production workloads. To control costs and improve governance the following requirements have been defined:<br>✑ The company must be able to calculate the AWS costs for each project.<br>✑ The company must be able to calculate the AWS costs for each environment development staging and production.<br>✑ Commonly deployed IT services must be centrally managed.<br>✑ Business units can deploy pre-approved IT services only.<br>✑ Usage of AWS resources in the development account must be limited.<br>Which combination of actions should be taken to meet these requirements? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: ADF</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#640",
          "answers": [
            {
              "choice": "<p>A. Apply environment, cost center, and application name tags to all taggable resources.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Configure custom budgets and define thresholds using Cost Explorer.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Configure AWS Trusted Advisor to obtain weekly emails with cost-saving estimates.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a portfolio for each business unit and add products to the portfolios using AWS CloudFormation in AWS Service Catalog.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Configure a billing alarm in Amazon CloudWatch.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>F. Configure SCPs in AWS Organizations to allow services available using AWS.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 217415,
          "date": "Thu 23 Sep 2021 14:27",
          "username": "AK2020Kelvin1477",
          "content": "A - Tagging & Costing<br>D -Preapproved and Control<br>F- Limited servicethis options make more sense",
          "upvote_count": "342",
          "selected_answers": ""
        },
        {
          "id": 225558,
          "date": "Sun 26 Sep 2021 19:04",
          "username": "Kelvin1477",
          "content": "this options make more sense",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 256107,
          "date": "Mon 04 Oct 2021 01:46",
          "username": "vipgcp",
          "content": "A, D, F<br>A - TAGS for cost management - ok<br>B - There is no requirement of budgeting<br>C - no requirement on cost saving or alerts<br>D - controlled provisioining - ok<br>E - no requirement of alarm<br>F - central - ok",
          "upvote_count": "13",
          "selected_answers": ""
        },
        {
          "id": 637021,
          "date": "Tue 26 Jul 2022 02:38",
          "username": "hilftwassb",
          "content": "A,B,F<br>?Cost Explorer is not for setting thresholds.",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 693769,
          "date": "Thu 13 Oct 2022 11:25",
          "username": "wassb",
          "content": "Cost Explorer is not for setting thresholds.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 626460,
          "date": "Sun 03 Jul 2022 09:16",
          "username": "aandcaandc",
          "content": "vote ADFchange to ABF",
          "upvote_count": "11",
          "selected_answers": "Selected Answer: ADF"
        },
        {
          "id": 629078,
          "date": "Sat 09 Jul 2022 10:14",
          "username": "aandc",
          "content": "change to ABF",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 588255,
          "date": "Tue 19 Apr 2022 17:18",
          "username": "Alexey79Alexey79",
          "content": "A:<br>Tagging to have a clear segregation between staging and production workloads and each project.<br><br>B:<br>Visualize, understand, and manage your AWS costs based on Tags created in A:.<br><br>F:<br><br>Why NOT D:<br>AWS CloudFormation will not prevent usage of unauthorized AWS Services. SCP is used for that.A:<br>Tagging to have a clear segregation between staging and production workloads and each project.<br><br>B:<br>Visualize, understand, and manage your AWS costs based on Tags created in A:.<br>Having only tagging is not enough.<br><br>F:<br>Use SCP to limit AWS Resources deployment only to “pre-approved IT services only”.<br><br>Why NOT D:<br>AWS CloudFormation will not prevent usage of unauthorized AWS Services as per requirement “Business units can deploy pre-approved IT services only”. SCP is used for that. CloudFormation is good for deployment of approved AWS Resources, not AWS Services.",
          "upvote_count": "11",
          "selected_answers": "Selected Answer: ABF"
        },
        {
          "id": 588257,
          "date": "Tue 19 Apr 2022 17:22",
          "username": "Alexey79",
          "content": "A:<br>Tagging to have a clear segregation between staging and production workloads and each project.<br><br>B:<br>Visualize, understand, and manage your AWS costs based on Tags created in A:.<br>Having only tagging is not enough.<br><br>F:<br>Use SCP to limit AWS Resources deployment only to “pre-approved IT services only”.<br><br>Why NOT D:<br>AWS CloudFormation will not prevent usage of unauthorized AWS Services as per requirement “Business units can deploy pre-approved IT services only”. SCP is used for that. CloudFormation is good for deployment of approved AWS Resources, not AWS Services.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 580861,
          "date": "Mon 04 Apr 2022 19:28",
          "username": "roka_ua",
          "content": "Vote ADF",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: ADF"
        },
        {
          "id": 492009,
          "date": "Thu 02 Dec 2021 00:34",
          "username": "AzureDP900",
          "content": "I will go with ADF, It is most appropriate for given scenario.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443351,
          "date": "Sat 06 Nov 2021 00:09",
          "username": "andylogan",
          "content": "It's A D F - tag, limit access with SCP",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 434873,
          "date": "Fri 05 Nov 2021 07:42",
          "username": "tgv",
          "content": "AAA DDD FFF <br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433634,
          "date": "Wed 03 Nov 2021 06:40",
          "username": "blackgamer",
          "content": "Agree with ADF. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413325,
          "date": "Wed 27 Oct 2021 22:39",
          "username": "WhyIronMan",
          "content": "I'll go with A,D,F",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 392016,
          "date": "Sun 24 Oct 2021 09:18",
          "username": "daisyli",
          "content": "I think where B is wrong is the 'Cost Explorer'. If using 'AWS Budgets', B may be one of the right answer.<br>B.  Configure custom budgets and define thresholds using Cost Explorer.<br>Cost Explorer:<br>https://aws.amazon.com/aws-cost-management/aws-cost-explorer/?nc1=h_ls<br>AWS Budgets:<br>https://aws.amazon.com/aws-cost-management/aws-budgets/?nc1=h_ls",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 365245,
          "date": "Fri 22 Oct 2021 14:29",
          "username": "mustpassla",
          "content": "ADF for sure.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 358944,
          "date": "Fri 22 Oct 2021 11:00",
          "username": "digimaniac",
          "content": "what does \\\" Usage of AWS resources in the development account must be limited\\\" means? meaning don't create crazy expensive EC2 or don't use EC2 at all?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 356327,
          "date": "Wed 20 Oct 2021 13:18",
          "username": "Waiweng",
          "content": "it's A,D,F",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 293422,
          "date": "Wed 13 Oct 2021 18:57",
          "username": "Kian1",
          "content": "will go with ADF",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 259116,
          "date": "Sat 09 Oct 2021 21:54",
          "username": "Ebi",
          "content": "I will go with ADF",
          "upvote_count": "4",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#641",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is planning to migrate an existing high performance computing (HPC) solution to the AWS Cloud. The existing solution consists of a 12-node cluster running Linux with high speed interconnectivity developed on a single rack. A solutions architect needs to optimize the performance of the HPC cluster.<br>Which combination of steps will meet these requirements? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BC</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#641",
          "answers": [
            {
              "choice": "<p>A. Deploy instances across at least three Availability Zones.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Deploy Amazon EC2 instances in a placement group.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use Amazon EC2 instances that support Elastic Fabric Adapter (EFA).<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use Amazon EC2 instances that support burstable performance.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>E. Enable CPU hyperthreading.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 212409,
          "date": "Fri 24 Sep 2021 02:49",
          "username": "asldavidGmail78Kelvin1477",
          "content": "B andCB - C https://www.iucc.ac.il/en/blog/best-practices-for-running-hpc-on-aws/agree.. B&C",
          "upvote_count": "2031",
          "selected_answers": ""
        },
        {
          "id": 215078,
          "date": "Fri 24 Sep 2021 15:14",
          "username": "Gmail78",
          "content": "B - C https://www.iucc.ac.il/en/blog/best-practices-for-running-hpc-on-aws/",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 225588,
          "date": "Wed 29 Sep 2021 09:01",
          "username": "Kelvin1477",
          "content": "agree.. B&C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 322643,
          "date": "Fri 08 Oct 2021 23:57",
          "username": "KevinZhongSonujunko",
          "content": "BC<br>----------------<br>A: HA is not the case<br>B: placement group is good for HPC, refer to https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html<br>C: EFA is good for HPC, refer to https://aws.amazon.com/hpc/efa/<br>D: burstable is not the case<br>E: we need to Disable hyper-threading, refer to https://www.iucc.ac.il/en/blog/best-practices-for-running-hpc-on-aws/https://aws.amazon.com/blogs/compute/disabling-intel-hyper-threading-technology-on-amazon-linux/",
          "upvote_count": "91",
          "selected_answers": ""
        },
        {
          "id": 557070,
          "date": "Sun 27 Feb 2022 00:17",
          "username": "Sonujunko",
          "content": "https://aws.amazon.com/blogs/compute/disabling-intel-hyper-threading-technology-on-amazon-linux/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 540641,
          "date": "Fri 04 Feb 2022 21:36",
          "username": "AMKazi",
          "content": "B and C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 514377,
          "date": "Sat 01 Jan 2022 06:15",
          "username": "cldy",
          "content": "B and C. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 499256,
          "date": "Sat 11 Dec 2021 10:20",
          "username": "cldy",
          "content": "B.  Deploy Amazon EC2 instances in a placement group.<br>C.  Use Amazon EC2 instances that support Elastic Fabric Adapter (EFA).",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 497955,
          "date": "Thu 09 Dec 2021 19:19",
          "username": "Rho_Ohm",
          "content": "B and C",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BC"
        },
        {
          "id": 496412,
          "date": "Wed 08 Dec 2021 01:14",
          "username": "AzureDP900",
          "content": "I'll go with B,C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492010,
          "date": "Thu 02 Dec 2021 00:35",
          "username": "AzureDP900",
          "content": "B and C is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443354,
          "date": "Sat 06 Nov 2021 15:59",
          "username": "andylogan",
          "content": "It's B C, placement group and Elastic Fabric Adapter (EFA).",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436339,
          "date": "Sat 06 Nov 2021 01:03",
          "username": "tgv",
          "content": "BBB CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433636,
          "date": "Fri 05 Nov 2021 04:56",
          "username": "blackgamer",
          "content": "B and C. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413330,
          "date": "Thu 04 Nov 2021 14:50",
          "username": "WhyIronMan",
          "content": "I'll go with B,C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 407627,
          "date": "Fri 22 Oct 2021 08:56",
          "username": "Kopa",
          "content": "b,C for sure",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 356329,
          "date": "Sun 17 Oct 2021 06:47",
          "username": "Waiweng",
          "content": "it's B&C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 331371,
          "date": "Wed 13 Oct 2021 21:47",
          "username": "PredaOvde",
          "content": "B say \\\"in a placement group\\\". It does not say cluster partition group, which would improve performance. A placement group could also be spread, which would decrease performance.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 306617,
          "date": "Fri 08 Oct 2021 19:03",
          "username": "Taku",
          "content": "will go with B &C .....<br><br>https://aws.amazon.com/hpc/efa/<br><br>Elastic Fabric Adapter (EFA) is a network interface for Amazon EC2 instances that enables customers to run applications requiring high levels of inter-node communications at scale on AWS. Its custom-built operating system (OS) bypass hardware interface enhances the performance of inter-instance communications, which is critical to scaling these applications. With EFA, High Performance Computing (HPC) applications using the Message Passing Interface (MPI) and Machine Learning (ML) applications using NVIDIA Collective Communications Library (NCCL) can scale to thousands of CPUs or GPUs. As a result, you get the application performance of on-premises HPC clusters with the on-demand elasticity and flexibility of th...",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 293426,
          "date": "Thu 07 Oct 2021 07:50",
          "username": "Kian1",
          "content": "going with BC",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#642",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company hosts a game player-matching service on a public facing, physical, on-premises instance that all users are able to access over the internet. All traffic to the instance uses UDP. The company wants to migrate the service to AWS and provide a high level of security. A solutions architect needs to design a solution for the player-matching service using AWS.<br>Which combination of steps should the solutions architect take to meet these requirements? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: ADF</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#642",
          "answers": [
            {
              "choice": "<p>A. Use a Network Load Balancer (NLB) in front of the player-matching instance. Use a friendly DNS entry in Amazon Route 53 pointing to the NLB's Elastic IP address.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use an Application Load Balancer (ALB) in front of the player-matching instance. Use a friendly DNS entry in Amazon Route 53 pointing to the ALB's internet- facing fully qualified domain name (FQDN).<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Define an AWS WAF rule to explicitly drop non-UDP traffic, and associate the rule with the load balancer.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Configure a network ACL rule to block all non-UDP traffic. Associate the network ACL with the subnets that hold the load balancer instances.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Use Amazon CloudFront with an Elastic Load Balancer as an origin.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>F. Enable AWS Shield Advanced on all public-facing resources.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 217554,
          "date": "Mon 27 Sep 2021 15:06",
          "username": "smartassX",
          "content": "ADF \\\"If your application is used only for TCP traffic, you can create a rule to deny all UDP traffic, or vice versa\\\" https://docs.aws.amazon.com/whitepapers/latest/aws-best-practices-ddos-resiliency/security-groups-and-network-access-control-lists-nacls-bp5.html",
          "upvote_count": "24",
          "selected_answers": ""
        },
        {
          "id": 622812,
          "date": "Sun 26 Jun 2022 22:39",
          "username": "kangtamo",
          "content": "Agree with ADF. ",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: ADF"
        },
        {
          "id": 532365,
          "date": "Tue 25 Jan 2022 20:36",
          "username": "Ni_yot",
          "content": "ADF. NLB supports UDP",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492012,
          "date": "Thu 02 Dec 2021 00:40",
          "username": "AzureDP900",
          "content": "A,D,F is perfect answer<br>The Network Load Balancer (NLB) supports the UDP protocol and can be placed in front of the application instance.<br>This configuration may add some security if the instance is running in a private subnet.<br>An NLB can be configured with an Elastic IP in each subnet in which it has nodes. In this case it only has a single<br>subnet (one instance) and so there will be 1 EIP.<br>Route 53 can be configured to resolve directly to the EIP rather than the DNS name of the NLB as there is only one IP<br>address to return. To filter traffic the network ACL for the subnet can be configured to block all non-UDP traffic.<br>This solution meets all the stated requirements.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443369,
          "date": "Fri 05 Nov 2021 22:54",
          "username": "andylogan",
          "content": "It's A D F,NLB + NACL + AWS Shield Advanced",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 442267,
          "date": "Fri 05 Nov 2021 07:23",
          "username": "student22",
          "content": "ADF<br>NLB + NACL + AWS Shield Advanced",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436340,
          "date": "Fri 05 Nov 2021 05:57",
          "username": "tgv",
          "content": "AAA DDD FFF<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433644,
          "date": "Thu 04 Nov 2021 08:00",
          "username": "blackgamer",
          "content": "A over B because the application needs UDP port. NLB is the answer here. D and F are Okay.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 431539,
          "date": "Tue 02 Nov 2021 04:30",
          "username": "dencccdenccc",
          "content": "I would think BDF? Not sure if the order of answers changed? WAF for ALB. Oh yes, UDP... my bad",
          "upvote_count": "12",
          "selected_answers": ""
        },
        {
          "id": 431541,
          "date": "Tue 02 Nov 2021 13:05",
          "username": "denccc",
          "content": "Oh yes, UDP... my bad",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 413332,
          "date": "Sun 31 Oct 2021 04:47",
          "username": "WhyIronMan",
          "content": "I'll go with A,D,F",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 365292,
          "date": "Sun 31 Oct 2021 04:41",
          "username": "mustpassla",
          "content": "ADF for sure. keyword: UDP and security.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 356339,
          "date": "Sat 30 Oct 2021 16:21",
          "username": "Waiweng",
          "content": "it's A,D,F",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 293434,
          "date": "Thu 21 Oct 2021 11:02",
          "username": "Kian1",
          "content": "going with ADF",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 267858,
          "date": "Sat 16 Oct 2021 06:35",
          "username": "Justurasti",
          "content": "I would go ACF, WAF is better solution to defend your load balancer than NACL.C is wrong. WAF is only for ALB, not for NLB. <br>ADF is correct",
          "upvote_count": "211",
          "selected_answers": ""
        },
        {
          "id": 273013,
          "date": "Wed 20 Oct 2021 16:06",
          "username": "rasti",
          "content": "C is wrong. WAF is only for ALB, not for NLB. <br>ADF is correct",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 264333,
          "date": "Thu 07 Oct 2021 17:17",
          "username": "nqobza",
          "content": "The correct answer is AEF.  I think people are getting caught up with trying to block UDP traffic. There is no need for that as on the Network load balancer we would only add a UDP listener so anything outside of UDP would be rejected anyway.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 259125,
          "date": "Thu 07 Oct 2021 14:20",
          "username": "EbiEbicertainlyheyheyhei",
          "content": "I will go with ADE,<br>I don't see any reason to enable expensive Advanced Shield when there is no specific requirement in the questionChanged my answer to ADF:<br>https://aws.amazon.com/blogs/networking-and-content-delivery/accelerate-protect-games-with-amazon-cloudfront-aws-shield-aws-waf/why not E.  CloudFront is also recommended in referenced aws blog. also, https://docs.aws.amazon.com/whitepapers/latest/aws-best-practices-ddos-resiliency/protecting-your-origin-bp1-bp5.htmlCloudFront does not support UDP. Instead, Global Accelerator can be used for UDP gaming",
          "upvote_count": "3528",
          "selected_answers": ""
        },
        {
          "id": 284575,
          "date": "Wed 20 Oct 2021 17:40",
          "username": "Ebicertainlyheyheyhei",
          "content": "Changed my answer to ADF:<br>https://aws.amazon.com/blogs/networking-and-content-delivery/accelerate-protect-games-with-amazon-cloudfront-aws-shield-aws-waf/why not E.  CloudFront is also recommended in referenced aws blog. also, https://docs.aws.amazon.com/whitepapers/latest/aws-best-practices-ddos-resiliency/protecting-your-origin-bp1-bp5.htmlCloudFront does not support UDP. Instead, Global Accelerator can be used for UDP gaming",
          "upvote_count": "528",
          "selected_answers": ""
        },
        {
          "id": 304529,
          "date": "Wed 27 Oct 2021 15:52",
          "username": "certainlyheyheyhei",
          "content": "why not E.  CloudFront is also recommended in referenced aws blog. also, https://docs.aws.amazon.com/whitepapers/latest/aws-best-practices-ddos-resiliency/protecting-your-origin-bp1-bp5.htmlCloudFront does not support UDP. Instead, Global Accelerator can be used for UDP gaming",
          "upvote_count": "28",
          "selected_answers": ""
        },
        {
          "id": 312507,
          "date": "Thu 28 Oct 2021 01:08",
          "username": "heyheyhei",
          "content": "CloudFront does not support UDP. Instead, Global Accelerator can be used for UDP gaming",
          "upvote_count": "8",
          "selected_answers": ""
        },
        {
          "id": 256046,
          "date": "Sat 02 Oct 2021 04:41",
          "username": "Bulti",
          "content": "ADF.  Not B because this is a traffic using layer 4 Protocol (UDP) andNLB is a better fit to handle this traffic than ALB.  Not C because WAF protects ALB and is meant to protect web application traffic mainly HTTP and HTTPS.",
          "upvote_count": "4",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#643",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has multiple AWS accounts and manages these accounts which AWS Organizations. A developer was given IAM user credentials to access AWS resources. The developer should have read-only access to all Amazon S3 buckets in the account. However, when the developer tries to access the S3 buckets from the console, they receive an access denied error message with no bucket listed.<br>A solution architect reviews the permissions and finds that the developer's IAM user is listed as having read-only access to all S3 buckets in the account.<br>Which additional steps should the solutions architect take to troubleshoot the issue? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: CD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#643",
          "answers": [
            {
              "choice": "<p>A. Check the bucket policies for all S3 buckets.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Check the ACLs for all S3 buckets.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Check the SCPs set at the organizational units (OUs).<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Check for the permissions boundaries set for the IAM user.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Check if an appropriate IAM role is attached to the IAM user.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 226643,
          "date": "Sat 09 Oct 2021 09:24",
          "username": "XRiddlerX",
          "content": "Answer C and D<br> - My two cents:<br>A is INCORRECT even though a bucket policy IS a resource based policy and will be evaluated AFTER Organizations SCPs, if a DENY is set in the policy you will list see it listed.You will see the word \\\"ERROR\\\" in the Access column.<br><br>B is INCORRECT because even though ACLs are resource-based policies you use ACLs to grant basic read/write permissions on the objects in the bucket.You'll still be able to ListBuckets if there is an ACL on the bucket.<br><br>C is CORRECT because after the Deny Evaluation a Organization SCPs are evaluated and take affect/merged. (See Link Below)<br><br>D is CORRECT because a DENY on the permission boundary will not allow the developer to ListBuckets<br><br>E is INCORRECT because this is a IAM Permission and applied AFTER DENY, ORG SCP, and RESOURCE-based policy evaluation.In addition the Solution Architect checked the developers IAM User and it was listed as readonly.<br><br>https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_evaluation-logic.html#policy-eval-denyallow",
          "upvote_count": "33",
          "selected_answers": ""
        },
        {
          "id": 213001,
          "date": "Mon 27 Sep 2021 08:57",
          "username": "liono",
          "content": "c,d seems correct",
          "upvote_count": "17",
          "selected_answers": ""
        },
        {
          "id": 708716,
          "date": "Mon 31 Oct 2022 21:41",
          "username": "Cal88",
          "content": "The answer is CD<br><br>A.  Check the bucket policies for all S3 buckets.<br>Not relevant , the user is facing an issue to list all buckets.<br>If the question is about access denied when trying to read or write from some bucket then this might be the cause<br><br>B.  Check the ACLs for all S3 buckets.<br>Same as A <br><br>C.  Check the SCPs set at the organizational units (OUs).<br>Correct , even if a user has IAM permission to access a service if the SCP for his OU denies it he cant access<br>D.  Check for the permissions boundaries set for the IAM user.<br>This is correct , the issue could be because of the permission set for the IAM user<br><br>E.  Check if an appropriate IAM role is attached to the IAM user.<br>Not relevant , the permission to access S3 in the question is defined on the user and there is no mention that the user is a assuming a role or that an ec2 instance with that role is having the problem",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 627301,
          "date": "Tue 05 Jul 2022 08:56",
          "username": "Enigmaaaaaa",
          "content": "CD for me.<br>Since we cannot list any bucket at all - A& B are excluded.<br>E - we already have this kind of access - not relevant.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 622566,
          "date": "Sun 26 Jun 2022 15:16",
          "username": "kangtamo",
          "content": "Agree with CD. ",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: CD"
        },
        {
          "id": 572532,
          "date": "Mon 21 Mar 2022 22:55",
          "username": "HellGate",
          "content": "There are several ways to control access S3 bucket.<br>- IAM user policy<br>- bucket policy<br>- ACLs<br>- S3 block public access<br>If setting related with IAM is right, we should check their bucket policies and ACLs.So answer is A and B. ",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: AB"
        },
        {
          "id": 492013,
          "date": "Thu 02 Dec 2021 00:44",
          "username": "AzureDP900",
          "content": "C, D is correct<br>A service control policy (SCP) may have been implemented that limits the API actions that are available for Amazon<br>S3. This will apply to all users in the account regardless of the permissions they have assigned to their user account.<br>Another potential cause of the issue is that the permissions boundary for the user limits the S3 API actions available<br>to the user. A permissions boundary is an advanced feature for using a managed policy to set the maximum<br>permissions that an identity-based policy can grant to an IAM entity. An entity’s permissions boundary allows it to<br>perform only the actions that are allowed by both its identity-based policies and its permissions boundaries",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443374,
          "date": "Sat 06 Nov 2021 13:58",
          "username": "andylogan",
          "content": "It's C D with evaluating Identity-based policies with boundaries",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 438969,
          "date": "Mon 01 Nov 2021 00:25",
          "username": "DerekKey",
          "content": "C&D correct<br>https://aws.amazon.com/premiumsupport/knowledge-center/s3-troubleshoot-403/",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 436341,
          "date": "Sat 30 Oct 2021 08:18",
          "username": "tgv",
          "content": "CCC DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433657,
          "date": "Thu 28 Oct 2021 12:32",
          "username": "blackgamer",
          "content": "CD is the answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413335,
          "date": "Thu 28 Oct 2021 11:14",
          "username": "WhyIronMan",
          "content": "I'll go with C,D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 356345,
          "date": "Wed 27 Oct 2021 10:48",
          "username": "Waiweng",
          "content": "it's C,D",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 343846,
          "date": "Wed 27 Oct 2021 02:18",
          "username": "Amitv2706",
          "content": "C and D. <br><br>If I go with IAM Policy Evaluation Logic mentioned here :<br>https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_evaluation-logic.html#policy-eval-denyallow<br>Deny Evaluation : There is no explicit deny mentioned<br>Organizations SCPs : C (not checked as per question)<br>Resource based policies : Not given as a option or mentioned in question<br>IAM permission boundaries : D (not checked as per question)<br>Session Policies : Not given as a option or mentioned in question<br>Identity Based Policy : Based on question user(or its group which is implicit) is already having read-only access to all S3 buckets <br>Errors :Not given as a option or mentioned in question",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 321729,
          "date": "Sun 24 Oct 2021 07:10",
          "username": "alisyech",
          "content": "i choose C & D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 313569,
          "date": "Sun 24 Oct 2021 03:06",
          "username": "nitinz",
          "content": "trick question C&D check the vein dig on https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.html and things will make sense.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 301273,
          "date": "Wed 20 Oct 2021 20:26",
          "username": "kiev",
          "content": "CD WOULD FOR ME AS WELL.",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#644",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is planning to migrate its business-critical applications from an on-premises data center to AWS. The company has an on-premises installation of a<br>Microsoft SQL Server Always On cluster. The company wants to migrate to an AWS managed database service. A solutions architect must design a heterogeneous database migration on AWS.<br>Which solution will meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#644",
          "answers": [
            {
              "choice": "<p>A. Migrate the SQL Server databases to Amazon RDS for MySQL by using backup and restore utilities.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use an AWS Snowball Edge Storage Optimized device to transfer data to Amazon S3. Set up Amazon RDS for MySQL. Use S3 integration with SQL Server features, such as BULK INSERT.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use the AWS Schema Conversion Tool to translate the database schema to Amazon RDS for MeSQL. Then use AWS Database Migration Service (AWS DMS) to migrate the data from on-premises databases to Amazon RDS.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use AWS DataSync to migrate data over the network between on-premises storage and Amazon S3. Set up Amazon RDS for MySQL. Use S3 integration with SQL Server features, such as BULK INSERT.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 529375,
          "date": "Fri 21 Jan 2022 21:54",
          "username": "Ni_yot",
          "content": "c of cause",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 513159,
          "date": "Thu 30 Dec 2021 09:46",
          "username": "wpinfo",
          "content": "answer should be C.  The AWS Schema Conversion Tool (AWS SCT) makes heterogeneous database migrations. https://aws.amazon.com/dms/schema-conversion-tool/",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 512901,
          "date": "Thu 30 Dec 2021 02:07",
          "username": "notabot2",
          "content": "I go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 512635,
          "date": "Wed 29 Dec 2021 20:26",
          "username": "RamCrk",
          "content": "C , preference ,because must design a heterogeneous<br>https://aws.amazon.com/dms/schema-conversion-tool/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 511928,
          "date": "Wed 29 Dec 2021 08:46",
          "username": "rootx",
          "content": "C seems to be the best fit",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        }
      ]
    },
    {
      "question_id": "#645",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has an application that generates reports and stores them in an Amazon bucket Amazon S3 bucket. When a user accesses their report, the application generates a signed URL to allow the user to download the report. The company's security team has discovered that the files are public and that anyone can download them without authentication. The company has suspended the generation of new reports until the problem is resolved.<br>Which set of action will immediately remediate the security issue without impacting the application's normal workflow?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: D</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#645",
          "answers": [
            {
              "choice": "<p>A. Create an AWS Lambda function that applies all policy for users who are not authenticated. Create a scheduled event to invoke the Lambda function.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Review the AWS Trusted advisor bucket permissions check and implement the recommend actions.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Run a script that puts a Private ACL on all of the object in the bucket.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use the Block Public Access feature in Amazon S3 to set the IgnorePublicAcis option to TRUE on the bucket.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 259133,
          "date": "Thu 21 Oct 2021 10:46",
          "username": "Ebi",
          "content": "I'll go with D",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 356352,
          "date": "Mon 01 Nov 2021 00:04",
          "username": "Waiwenguser0001",
          "content": "it's Dfrom documentation <br>Setting this option to TRUE causes Amazon S3 to ignore all public ACLs on a bucket and any objects that it contains. This setting enables you to safely block public access granted by ACLs while still allowing PUT Object calls that include a public ACL (as opposed to BlockPublicAcls, which rejects PUT Object calls that include a public ACL). Enabling this setting doesn't affect the persistence of any existing ACLs and doesn't prevent new public ACLs from being set.",
          "upvote_count": "61",
          "selected_answers": ""
        },
        {
          "id": 602995,
          "date": "Tue 17 May 2022 19:02",
          "username": "user0001",
          "content": "from documentation <br>Setting this option to TRUE causes Amazon S3 to ignore all public ACLs on a bucket and any objects that it contains. This setting enables you to safely block public access granted by ACLs while still allowing PUT Object calls that include a public ACL (as opposed to BlockPublicAcls, which rejects PUT Object calls that include a public ACL). Enabling this setting doesn't affect the persistence of any existing ACLs and doesn't prevent new public ACLs from being set.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 623524,
          "date": "Tue 28 Jun 2022 00:52",
          "username": "kangtamo",
          "content": "D sounds better.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 528947,
          "date": "Fri 21 Jan 2022 06:21",
          "username": "GeniusMikeLiu",
          "content": "\\\" The company's security staff determined that the files are accessible to the public and may be downloaded without authentication\\\"mean want public access right? why D? so confused",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 498315,
          "date": "Fri 10 Dec 2021 06:21",
          "username": "cldy",
          "content": "D.  Use the Block Public Access feature in Amazon S3 to set the IgnorePublicAcis option to TRUE on the bucket.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 492018,
          "date": "Thu 02 Dec 2021 00:50",
          "username": "AzureDP900",
          "content": "D is right. <br>The S3 bucket is allowing public access and this must be immediately disabled. Setting the IgnorePublicAcls option<br>to TRUE causes Amazon S3 to ignore all public ACLs on a bucket and any objects that it contains.<br>The other settings you can configure with the Block Public Access Feature are:<br>o BlockPublicAcls – PUT bucket ACL and PUT objects requests are blocked if granting public access.<br>o BlockPublicPolicy – Rejects requests to PUT a bucket policy if granting public access.<br>o RestrictPublicBuckets – Restricts access to principles in the bucket owners’ AWS account.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 443378,
          "date": "Sun 07 Nov 2021 07:12",
          "username": "andylogan",
          "content": "It's D - pre-signed URL is to allows unauthenticated users access to the bucket in private",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436344,
          "date": "Sat 06 Nov 2021 08:16",
          "username": "tgv",
          "content": "DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413340,
          "date": "Fri 05 Nov 2021 16:41",
          "username": "WhyIronMan",
          "content": "I'll go with D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 293454,
          "date": "Sun 31 Oct 2021 03:23",
          "username": "Kian1",
          "content": "going with D",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 256091,
          "date": "Tue 12 Oct 2021 18:44",
          "username": "Bulti",
          "content": "Answer is D.  Remember that the purpose of creating a pre-signed URL is to allows unauthenticated users access to the bucket or the objects in the bucket which are private. So if someone can still access the bucket then the buckets or the objects in the bucket have been granted a public ACL which needs to be blocked and the way to do that is by using the IgnorePublicAcls setting.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 255855,
          "date": "Sun 10 Oct 2021 15:18",
          "username": "petebear55shammous",
          "content": "Bcould be the answer .. however it would probably AWS Macie which does the needful. .. I will go for D in this case .. however i'm not hundred percent convinced and think the question is poorly writtenB won't \\\"immediately remediate the security issue\\\". D would.",
          "upvote_count": "12",
          "selected_answers": ""
        },
        {
          "id": 277886,
          "date": "Mon 25 Oct 2021 19:50",
          "username": "shammous",
          "content": "B won't \\\"immediately remediate the security issue\\\". D would.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 244969,
          "date": "Sat 09 Oct 2021 01:45",
          "username": "T14102020",
          "content": "Correct is D. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 232646,
          "date": "Wed 29 Sep 2021 22:28",
          "username": "jackdryan",
          "content": "I'll go with D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 217565,
          "date": "Mon 20 Sep 2021 13:12",
          "username": "smartassX",
          "content": "D--> \\\"IgnorePublicAcis\\\" --> \\\"Setting this option to TRUE causes Amazon S3 to ignore all public ACLs on a bucket and any objects that it contains. This setting enables you to safely block public access granted by ACLs while still allowing PUT Object calls that include a public ACL (as opposed to BlockPublicAcls, which rejects PUT Object calls that include a public ACL). Enabling this setting doesn't affect the persistence of any existing ACLs and doesn't prevent new public ACLs from being set.\\\"",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 212416,
          "date": "Mon 20 Sep 2021 03:02",
          "username": "asldavidGmail78avlandKelvin1477",
          "content": "D<br>https://aws.amazon.com/s3/features/block-public-access/what is IgnorePublicAcis? I would go with A insteadPretty sure there's a typo there. Should be IgnorePublicAcls.<br><br>Block public access to buckets and objects granted through any access control lists (ACLs)<br>S3 will ignore all ACLs that grant public access to buckets and objects.Support D too as mention pre-signed url that is shared to the user will not be block but the policy will block any other public access: <br>https://acloud.guru/forums/s3-masterclass/discussion/-LsBZBXjnnNdi4dT1Czi/block%20public%20access%20vs%20pre-signed%20URL%20access",
          "upvote_count": "3132",
          "selected_answers": ""
        },
        {
          "id": 218276,
          "date": "Thu 23 Sep 2021 18:52",
          "username": "Gmail78avland",
          "content": "what is IgnorePublicAcis? I would go with A insteadPretty sure there's a typo there. Should be IgnorePublicAcls.<br><br>Block public access to buckets and objects granted through any access control lists (ACLs)<br>S3 will ignore all ACLs that grant public access to buckets and objects.",
          "upvote_count": "13",
          "selected_answers": ""
        },
        {
          "id": 226771,
          "date": "Mon 27 Sep 2021 10:31",
          "username": "avland",
          "content": "Pretty sure there's a typo there. Should be IgnorePublicAcls.<br><br>Block public access to buckets and objects granted through any access control lists (ACLs)<br>S3 will ignore all ACLs that grant public access to buckets and objects.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 225641,
          "date": "Sun 26 Sep 2021 15:36",
          "username": "Kelvin1477",
          "content": "Support D too as mention pre-signed url that is shared to the user will not be block but the policy will block any other public access: <br>https://acloud.guru/forums/s3-masterclass/discussion/-LsBZBXjnnNdi4dT1Czi/block%20public%20access%20vs%20pre-signed%20URL%20access",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#646",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company hosts a legacy application that runs on an Amazon EC2 instance inside a VPC without internet access. Users access the application with a desktop program installed on their corporate laptops. Communication between the laptops and the VPC flows through AWS Direct Connect (DX). A new requirement states that all data in transit must be encrypted between users and the VPC. <br>Which strategy should a solutions architect use to maintain consistent network performance while meeting this new requirement?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#646",
          "answers": [
            {
              "choice": "<p>A. Create a client VPN endpoint and configure the laptops to use an AWS client VPN to connect to the VPC over the internet.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create a new public virtual interface for the existing DX connection, and create a new VPN that connects to the VPC over the DX public virtual interface.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create a new Site-to-Site VPN that connects to the VPC over the internet.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a new private virtual interface for the existing DX connection, and create a new VPN that connects to the VPC over the DX private virtual interface.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 213291,
          "date": "Tue 21 Sep 2021 03:53",
          "username": "lionouser0001ByrneyDashLhelpaws",
          "content": "B<br>https://aws.amazon.com/premiumsupport/knowledge-center/create-vpn-direct-connect/it is D, there is no requirement to access public services so no need for public VIPAWS S2S VPN is a public service, so a public VIF is requiredTo connect to a VPC, it is required to connect to a Private Virtual interface over Direct connect. I guess an AWS document will be more accurate than any blog post:<br>https://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-direct-connect-vpn.htmlPrivate VIFs do not provide encryption.. Public VIFs can via IPSEC.  you also cannot establish a VPN connection without a Public VIF. ",
          "upvote_count": "272145",
          "selected_answers": ""
        },
        {
          "id": 606280,
          "date": "Mon 23 May 2022 20:33",
          "username": "user0001Byrney",
          "content": "it is D, there is no requirement to access public services so no need for public VIPAWS S2S VPN is a public service, so a public VIF is required",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 713374,
          "date": "Tue 08 Nov 2022 01:42",
          "username": "Byrney",
          "content": "AWS S2S VPN is a public service, so a public VIF is required",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 396389,
          "date": "Mon 01 Nov 2021 09:34",
          "username": "DashL",
          "content": "To connect to a VPC, it is required to connect to a Private Virtual interface over Direct connect. I guess an AWS document will be more accurate than any blog post:<br>https://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-direct-connect-vpn.html",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 638933,
          "date": "Fri 29 Jul 2022 02:41",
          "username": "helpaws",
          "content": "Private VIFs do not provide encryption.. Public VIFs can via IPSEC.  you also cannot establish a VPN connection without a Public VIF. ",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 256104,
          "date": "Mon 18 Oct 2021 14:56",
          "username": "Bulti",
          "content": "Answer is B.  https://aws.amazon.com/premiumsupport/knowledge-center/create-vpn-direct-connect/. Remember that to connect to services such as EC2 using just Direct Connect you need to create a private VIF.  However if you want to encrypt the traffic flowing through DirectConnect, you will need to use the public VIF of DX to create a VPN connection that will allow access to AWS services such as S3, EC2 etc. The video describes this.",
          "upvote_count": "12",
          "selected_answers": ""
        },
        {
          "id": 698820,
          "date": "Wed 19 Oct 2022 10:27",
          "username": "JohnPi",
          "content": "you need public VIF. <br>To implement a Private IP VPN with AWS Direct Connect you need a transit virtual interface, DXG, transit gateway",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 640081,
          "date": "Sun 31 Jul 2022 13:15",
          "username": "Enigmaaaaaa",
          "content": "This is clearly stated in AWS documentation <br>https://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-direct-connect-vpn.html<br>The answer must B as IPSec tunnels are always public",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 638935,
          "date": "Fri 29 Jul 2022 02:48",
          "username": "hilft",
          "content": "got the DX. D > B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 625970,
          "date": "Sat 02 Jul 2022 07:57",
          "username": "aandc",
          "content": "B you need to use the public VIF of DX to create a VPN connection <br>https://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-direct-connect-vpn.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 624379,
          "date": "Wed 29 Jun 2022 04:49",
          "username": "TechXTechX",
          "content": "D for meJust ignore D, after asking my experienced senior SA.  It should be B, cause now he is also doing a same solution for a company has the same case in this question",
          "upvote_count": "12",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 624389,
          "date": "Wed 29 Jun 2022 05:02",
          "username": "TechX",
          "content": "Just ignore D, after asking my experienced senior SA.  It should be B, cause now he is also doing a same solution for a company has the same case in this question",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 621794,
          "date": "Fri 24 Jun 2022 19:33",
          "username": "Ddssssss",
          "content": "I don't understand why it cant be D?? Just because 90% of the time you would use the Public interface doesn't mean you cant use the private. Its a valid DX configuration option with IPSEC tunnel. <br>Private virtual interface: A private virtual interface should be used to access an Amazon VPC using private IP addresses.<br><br>https://docs.aws.amazon.com/directconnect/latest/UserGuide/WorkingWithVirtualInterfaces.html<br><br>It is also clearly explain in this blog which references all the details in any AWS doc. <br>https://jayendrapatil.com/tag/direct-connect/<br><br>This doc is also only 2 days old. but with the use of a transit GW you can use Private IP and IPSEC.  <br><br>https://aws.amazon.com/blogs/networking-and-content-delivery/introducing-aws-site-to-site-vpn-private-ip-vpns/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 596272,
          "date": "Tue 03 May 2022 03:33",
          "username": "Hasitha99",
          "content": "o connect to services such as EC2 using just Direct Connect you need to create a private VIF.  However if you want to encrypt the traffic flowing through DirectConnect, you will need to use the public VIF of DX to create a VPN connection that will allow access to AWS services such as S3, EC2.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 576414,
          "date": "Sun 27 Mar 2022 21:21",
          "username": "azure_kai",
          "content": "I would choose D.  There is no internet connection. And the traffic is between corporate network and VPC.  Most likely, it only involves private IP addresses, which only requires privhttps://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-professional/view/14/#ate virtual interface over DX.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 558647,
          "date": "Tue 01 Mar 2022 08:40",
          "username": "jyrajan69",
          "content": "There is no debate, link from liono clearly shows step by step solution. Answer is B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 546958,
          "date": "Mon 14 Feb 2022 08:33",
          "username": "lifebegins",
          "content": "Answer is D:<br>We shoud go over the <br>With AWS Direct Connect and AWS Site-to-Site VPN, you can combine one or more AWS Direct Connect dedicated network connections with the Amazon VPC VPN<br><br>https://docs.aws.amazon.com/directconnect/latest/UserGuide/encryption-in-transit.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 543146,
          "date": "Tue 08 Feb 2022 16:16",
          "username": "HellGatefuten0326Naj_64",
          "content": "My answer is D. <br><br>Why do we need public virtual interface for communication between laptop and VPC over DX? There are no requirements of accessing from internet.It should be PRIVATE virtual interface.Private VIFs do not provide encryption.. Public VIFs can via IPSEC.  you also cannot establish a VPN connection without a Public VIF. You can with a Transit VIF \\\"Private IP VPN is deployed on top of Transit VIFs\\\" -- https://aws.amazon.com/blogs/networking-and-content-delivery/introducing-aws-site-to-site-vpn-private-ip-vpns/ Answer is still B though.",
          "upvote_count": "121",
          "selected_answers": ""
        },
        {
          "id": 546420,
          "date": "Sun 13 Feb 2022 12:28",
          "username": "futen0326Naj_64",
          "content": "Private VIFs do not provide encryption.. Public VIFs can via IPSEC.  you also cannot establish a VPN connection without a Public VIF. You can with a Transit VIF \\\"Private IP VPN is deployed on top of Transit VIFs\\\" -- https://aws.amazon.com/blogs/networking-and-content-delivery/introducing-aws-site-to-site-vpn-private-ip-vpns/ Answer is still B though.",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 689639,
          "date": "Sat 08 Oct 2022 21:30",
          "username": "Naj_64",
          "content": "You can with a Transit VIF \\\"Private IP VPN is deployed on top of Transit VIFs\\\" -- https://aws.amazon.com/blogs/networking-and-content-delivery/introducing-aws-site-to-site-vpn-private-ip-vpns/ Answer is still B though.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 529413,
          "date": "Fri 21 Jan 2022 22:33",
          "username": "GV19",
          "content": "to establish VPN over DX, Public VIF is required, Only Option B has this detail;",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 495736,
          "date": "Tue 07 Dec 2021 08:37",
          "username": "KiraguJohn",
          "content": "VPC does not have internet connection.<br>Private virtual interface: used to access an VPC using private IP addresses.<br>Public virtual interface: can access all AWS public services using public IP addresses.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492019,
          "date": "Thu 02 Dec 2021 00:51",
          "username": "AzureDP900",
          "content": "B is right answer<br>Create a new public virtual interface for the existing DX connection, and create a new VPN that connects to the VPC over the DX public virtual interface.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 480738,
          "date": "Thu 18 Nov 2021 14:30",
          "username": "Ronon",
          "content": "Using PRIVATE virtual interface to connect to legacy application in an Amazon EC2. Answer D is correct.",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#647",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is creating a centralized logging service running on Amazon EC2 that will receive and analyze logs from hundreds of AWS accounts. AWS PrivateLink is being used to provide connectivity between the client services and the logging service.<br>In each AWS account with a client, an interface endpoint has been created for the logging service and is available. The logging service running on EC2 instances with a Network Load Balancer (NLB) are deployed in different subnets. The clients are unable to submit logs using the VPC endpoint.<br>Which combination of steps should a solutions architect take to resolve this issue? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#647",
          "answers": [
            {
              "choice": "<p>A. Check that the NACL is attached to the logging service subnet to allow communications to and from the NLB subnets. Check that the NACL is attached to the NLB subnet to allow communications to and from the logging service subnets running on EC2 instances.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Check that the NACL is attached to the logging service subnets to allow communications to and from the interface endpoint subnets. Check that the NACL is attached to the interface endpoint subnet to allow communications to and from the logging service subnets running on EC2 instances.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Check the security group for the logging service running on the EC2 instances to ensure it allows ingress from the NLB subnets.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Check the security group for the logging service running on the EC2 instances to ensure it allows ingress from the clients.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Check the security group for the NLB to ensure it allows ingress from the interface endpoint subnets.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 233622,
          "date": "Sat 09 Oct 2021 08:54",
          "username": "cloudgc",
          "content": "A&C are correct.<br>NLB will see traffic from interface endpoint subnet and logging service subnet.<br>Logging service SG will see traffic only from NLB IP.",
          "upvote_count": "37",
          "selected_answers": ""
        },
        {
          "id": 256110,
          "date": "Wed 13 Oct 2021 01:49",
          "username": "Bultirchernitinz",
          "content": "A&C.  The client of the Logging service running on EC2 is NLB and not the interface endpoint. the flow is Client->VPCE(PrivateLink)->NLB->Logging service. So the answer is A & C 100%.Agreed, and i implemented this architecture for my work.<br><br>NLB sits in front of the Logging Services, so the NACL and Sec groups for the corresponding logging instances (and its subnet) need to check for the NLB ingress. A/C for meyou got it right.",
          "upvote_count": "1221",
          "selected_answers": ""
        },
        {
          "id": 277447,
          "date": "Sun 17 Oct 2021 16:41",
          "username": "rcher",
          "content": "Agreed, and i implemented this architecture for my work.<br><br>NLB sits in front of the Logging Services, so the NACL and Sec groups for the corresponding logging instances (and its subnet) need to check for the NLB ingress. A/C for me",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 313655,
          "date": "Wed 20 Oct 2021 05:11",
          "username": "nitinz",
          "content": "you got it right.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 689503,
          "date": "Sat 08 Oct 2022 18:21",
          "username": "JohnPi",
          "content": "B +D is corect",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 637735,
          "date": "Wed 27 Jul 2022 03:47",
          "username": "foureye2004",
          "content": "I think A&D and include C. <br><br>With NLB, for security group attached to target EC2 instance (front by NLB) need to allow not only IP of NLB but also IP from client (If target type is an instance), assume that we use EC2 only, so target type instance is fitted.<br><br>https://aws.amazon.com/premiumsupport/knowledge-center/security-group-load-balancer/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 623521,
          "date": "Tue 28 Jun 2022 00:38",
          "username": "kangtamo",
          "content": "Agree with AC: NLB",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: AC"
        },
        {
          "id": 604939,
          "date": "Sat 21 May 2022 17:41",
          "username": "bobsmith2000Ddssssss",
          "content": "A is not correct.<br>The Q states \\\"The logging service is deployed in many SUBNETS\\\", A states \\\"Check that the NACL is attached to the logging service SUBNET\\\"the singulars and plurals in A are off. First it says subnets, then subnet, then subnets, then subnet. I think A is correct, just bad grammar.",
          "upvote_count": "12",
          "selected_answers": ""
        },
        {
          "id": 617005,
          "date": "Thu 16 Jun 2022 01:55",
          "username": "Ddssssss",
          "content": "the singulars and plurals in A are off. First it says subnets, then subnet, then subnets, then subnet. I think A is correct, just bad grammar.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 497787,
          "date": "Thu 09 Dec 2021 15:22",
          "username": "cldy",
          "content": "A.  Check that the NACL is attached to the logging service subnet to allow communications to and from the NLB subnets. Check that the NACL is attached to the NLB subnet to allow communications to and from the logging service subnets running on EC2 instances.<br>C.  Check the security group for the logging service running on the EC2 instances to ensure it allows ingress from the NLB subnets.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 492022,
          "date": "Thu 02 Dec 2021 01:06",
          "username": "AzureDP900",
          "content": "It seems B & D for me. I need to revisit this question again !",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 483611,
          "date": "Sun 21 Nov 2021 20:40",
          "username": "nsei",
          "content": "From this resource https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-target-groups.html#client-ip-preservation:<br>\\\"Client IP preservation has no effect on AWS PrivateLink traffic. The source IP of the AWS PrivateLink traffic is always the private IP address of the Network Load Balancer.\\\" ... hence the answer is A&C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 443428,
          "date": "Thu 04 Nov 2021 08:49",
          "username": "andylogan",
          "content": "It's A C since the client of the Logging service running on EC2 is NLB",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 441629,
          "date": "Wed 03 Nov 2021 14:55",
          "username": "wakamewakame",
          "content": "Hi guys,<br>NLB does not do Source NAT unlike ALB, but is the correct answer still A & C?I found out that there are the following specifications, so I solved it.<br> https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-target-groups.html#client-ip-preservation<br>In the case of using PrivateLink, NLB has a specification that It transrates Source IP to NLB Private IP.",
          "upvote_count": "13",
          "selected_answers": ""
        },
        {
          "id": 441638,
          "date": "Thu 04 Nov 2021 00:24",
          "username": "wakame",
          "content": "I found out that there are the following specifications, so I solved it.<br> https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-target-groups.html#client-ip-preservation<br>In the case of using PrivateLink, NLB has a specification that It transrates Source IP to NLB Private IP.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 434880,
          "date": "Tue 02 Nov 2021 19:08",
          "username": "tgv",
          "content": "AAA CCC<br>---<br>I don't understand what NLB not having security group has to do with A/C.  <br>I'm thinking that the clients are sending traffic to the NLB (not some kind of round robin directly on the EC2 instances). <br>The communication between NLB and EC2 instances still has to be configured. It doesn't work out of the box",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433723,
          "date": "Tue 02 Nov 2021 11:09",
          "username": "blackgamer",
          "content": "A and C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 413344,
          "date": "Mon 01 Nov 2021 11:35",
          "username": "WhyIronMan",
          "content": "I'll go with B,D",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 403181,
          "date": "Mon 01 Nov 2021 10:05",
          "username": "nopenope111",
          "content": "B&D. <br>NLB is not like ALB.  it just passes the traffic to EC2. EC2 needs to allow ingress from outside.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 383616,
          "date": "Sun 31 Oct 2021 06:42",
          "username": "kpcert",
          "content": "I think the answer is B and D.  NACL and Security group of EC2 logging service to allow traffic from client subnets,It is NLB in front of EC2 , NLB will preserve the client IPs and pass on the client details and source IPs of client to EC2, so the Network ACL and Security group of logging service should have the allow rule for the ip range of client subnets subnets.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 356365,
          "date": "Sun 24 Oct 2021 14:06",
          "username": "Waiweng",
          "content": "it's A&C",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#648",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is refactoring an existing web service that provides read and write access to structured data. The service must respond to short but significant spikes in the system load. The service must be fault tolerant across multiple AWS Regions.<br>Which actions should be taken to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#648",
          "answers": [
            {
              "choice": "<p>A. Store the data in Amazon DocumentDB.  Create a single global Amazon CloudFront distribution with a custom origin built on edge-optimized Amazon API Gateway and AWS Lambda. Assign the company's domain as an alternate domain for the distribution, and configure Amazon Route 53 with an alias to the CloudFront distribution.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Store the data in replicated Amazon S3 buckets in two Regions. Create an Amazon CloudFront distribution in each Region, with custom origins built on Amazon API Gateway and AWS Lambda launched in each Region. Assign the company's domain as an alternate domain for both distributions, and configure Amazon Route 53 with a failover routing policy between them.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Store the data in an Amazon DynamoDB global table in two Regions using on-demand capacity mode. In both Regions, run the web service as Amazon ECS Fargate tasks in an Auto Scaling ECS service behind an Application Load Balancer (ALB). In Amazon Route 53, configure an alias record in the company's domain and a Route 53 latency-based routing policy with health checks to distribute traffic between the two ALBs.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Store the data in Amazon Aurora global databases. Add Auto Scaling replicas to both Regions. Run the web service on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer in each Region. Configure the instances to download the web service code in the user data. In Amazon Route 53, configure an alias record for the company's domain and a multi-value routing policy<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 256375,
          "date": "Wed 29 Sep 2021 01:01",
          "username": "Bultiaws_arn_namejoe16tekkarttekkartacloudguru",
          "content": "Its between B and C.  I think A and D are out. A is out because of DocumentDB and D is out because of multi value. Between B and C, I think C is a better because S3 is usually used as a static web site and not for writing dynamic data (in this case structured data). Option C is a standard way of designing an application using a middle tier and a data tier where the middle tier is load balanced and is in an auto scaling group. Moreover DynamoDb can be used for both structured and semi-structured data. The latency routing policy with health checks will result in routing the traffic to the region with low latency in case the ALB endpoint is considered healthy or else it will be routed to the other region. So I will go with C. \\\"short but significant spikes\\\" , i think Lambda is better with this than ASG so answer should be BIn S3 CRR is not immediate(AWS Docs - \\\"Most objects replicate within 15 minutes, but sometimes replication can take a couple hours or more\\\"). So B is not an option as solution. <br>DDB Global tables have sync latency of less than a sec - \\\"In a global table, a newly written item is usually propagated to all replica tables within a second.\\\"<br>I will go with CD can work fine also<br>- Aurora for structured value<br>- Fault Tolerant because Route 53 with MVA policy allows health checks like it would w/ Failover policy : https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-values-multivalue.html<br>- ASG for spikes<br>- 1 ALB, simpler architecture than C where there are 2 ALB (one internal and one external)Because of the word 'refactoring' it's right may be ECS in answer C where ASG and ALB are also available<br><br>For A and B, I don't see how CloudFront can have API Gateway as origin... A and B would be ruled out because CloudFront can have : Web server, S3 bucket, or Elemental Media PAckage/Store for VOD as origins.Cloudfront can support API gateway and lambda.https://aws.amazon.com/tw/cloudfront/?nc=sn&loc=0",
          "upvote_count": "2621311",
          "selected_answers": ""
        },
        {
          "id": 367733,
          "date": "Sun 24 Oct 2021 00:06",
          "username": "aws_arn_name",
          "content": "\\\"short but significant spikes\\\" , i think Lambda is better with this than ASG so answer should be B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 456652,
          "date": "Fri 05 Nov 2021 22:23",
          "username": "joe16",
          "content": "In S3 CRR is not immediate(AWS Docs - \\\"Most objects replicate within 15 minutes, but sometimes replication can take a couple hours or more\\\"). So B is not an option as solution. <br>DDB Global tables have sync latency of less than a sec - \\\"In a global table, a newly written item is usually propagated to all replica tables within a second.\\\"<br>I will go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 424691,
          "date": "Fri 29 Oct 2021 00:34",
          "username": "tekkarttekkartacloudguru",
          "content": "D can work fine also<br>- Aurora for structured value<br>- Fault Tolerant because Route 53 with MVA policy allows health checks like it would w/ Failover policy : https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-values-multivalue.html<br>- ASG for spikes<br>- 1 ALB, simpler architecture than C where there are 2 ALB (one internal and one external)Because of the word 'refactoring' it's right may be ECS in answer C where ASG and ALB are also available<br><br>For A and B, I don't see how CloudFront can have API Gateway as origin... A and B would be ruled out because CloudFront can have : Web server, S3 bucket, or Elemental Media PAckage/Store for VOD as origins.Cloudfront can support API gateway and lambda.https://aws.amazon.com/tw/cloudfront/?nc=sn&loc=0",
          "upvote_count": "311",
          "selected_answers": ""
        },
        {
          "id": 424696,
          "date": "Fri 29 Oct 2021 11:19",
          "username": "tekkartacloudguru",
          "content": "Because of the word 'refactoring' it's right may be ECS in answer C where ASG and ALB are also available<br><br>For A and B, I don't see how CloudFront can have API Gateway as origin... A and B would be ruled out because CloudFront can have : Web server, S3 bucket, or Elemental Media PAckage/Store for VOD as origins.Cloudfront can support API gateway and lambda.https://aws.amazon.com/tw/cloudfront/?nc=sn&loc=0",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 484052,
          "date": "Mon 22 Nov 2021 10:36",
          "username": "acloudguru",
          "content": "Cloudfront can support API gateway and lambda.https://aws.amazon.com/tw/cloudfront/?nc=sn&loc=0",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 258986,
          "date": "Thu 30 Sep 2021 20:49",
          "username": "EbinqobzaEbigparkdart93MrCarterLiongeek",
          "content": "Answer is C. <br>D is not the right answer, although Aurora is better choice for structured data, but Aurora Global database supports one master only, so other regions do not support write.You're overthinking it. We only need to write to the primary.With multi value routing in route 53 you should be able to write in each region, otherwise you need manage failover if primary fails which has not been mentioned in this answer, I still go with CThis is another good point.aurora does support multi master: https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-multi-master.html<br>'In a multi-master cluster, all DB instances can perform write operations.'MULTI MASTER IS A REGIONAL SERVICE NOT MULTI REGION!!\\\"Currently, all DB instances in a multi-master cluster must be in the same AWS Region.\\\"",
          "upvote_count": "18331381",
          "selected_answers": ""
        },
        {
          "id": 264338,
          "date": "Fri 01 Oct 2021 23:45",
          "username": "nqobzaEbi",
          "content": "You're overthinking it. We only need to write to the primary.With multi value routing in route 53 you should be able to write in each region, otherwise you need manage failover if primary fails which has not been mentioned in this answer, I still go with C",
          "upvote_count": "33",
          "selected_answers": ""
        },
        {
          "id": 284555,
          "date": "Sat 09 Oct 2021 12:52",
          "username": "Ebi",
          "content": "With multi value routing in route 53 you should be able to write in each region, otherwise you need manage failover if primary fails which has not been mentioned in this answer, I still go with C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 298181,
          "date": "Wed 13 Oct 2021 07:39",
          "username": "gpark",
          "content": "This is another good point.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 334673,
          "date": "Sun 17 Oct 2021 20:02",
          "username": "dart93MrCarterLiongeek",
          "content": "aurora does support multi master: https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-multi-master.html<br>'In a multi-master cluster, all DB instances can perform write operations.'MULTI MASTER IS A REGIONAL SERVICE NOT MULTI REGION!!\\\"Currently, all DB instances in a multi-master cluster must be in the same AWS Region.\\\"",
          "upvote_count": "381",
          "selected_answers": ""
        },
        {
          "id": 395936,
          "date": "Tue 26 Oct 2021 20:11",
          "username": "MrCarter",
          "content": "MULTI MASTER IS A REGIONAL SERVICE NOT MULTI REGION!!",
          "upvote_count": "8",
          "selected_answers": ""
        },
        {
          "id": 449824,
          "date": "Fri 05 Nov 2021 19:06",
          "username": "Liongeek",
          "content": "\\\"Currently, all DB instances in a multi-master cluster must be in the same AWS Region.\\\"",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 686651,
          "date": "Wed 05 Oct 2022 08:36",
          "username": "tomosabc1",
          "content": "The answer is C<br><br>A(wrong):Single Point of Failure, can't support fault tolerant across multiple regions.<br><br>B(wrong):S3 CRR is not fast enough. AWS Docs - \\\"Most objects replicate within 15 minutes, but sometimes replication can take a couple hours or more\\\". By comparison, DynamoDB Global tables has sync latency of less than a sec - \\\"In a global table, a newly written item is usually propagated to all replica tables within a second.\\\".<br><br>D(wrong):Unlike DynamoDB, Aurora Global database has only one master(only one writable node) in the case of multiple region deployment.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 671166,
          "date": "Sat 17 Sep 2022 02:28",
          "username": "linuxmaster007",
          "content": "Answer is C ( as per tutorial dojo)",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 653122,
          "date": "Sun 28 Aug 2022 21:24",
          "username": "ASC1",
          "content": "dynamo db can store both Structured and Semi Structured data. So C is correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 635729,
          "date": "Sat 23 Jul 2022 21:51",
          "username": "CloudHandsOn",
          "content": "D.  - 'STRUCTURED' data. No other option is fully structured. I believe because of this, its the only viable option.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 602609,
          "date": "Mon 16 May 2022 15:43",
          "username": "bobsmith2000",
          "content": "The Q states \\\"structured data\\\". So neither NoSQL nor S3 (file storage) fits the bill.<br>The only answer which complies to this situation is D.  Multi-answer is not a problem for a web app.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 601564,
          "date": "Sat 14 May 2022 14:37",
          "username": "user0001",
          "content": "C: this is because The service must be able to react quickly to brief but large surges in system demand. Across many AWS Regions, the service must be fault resilient<br>D can not scale fast <br>A is notfault resilient across regions",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 546459,
          "date": "Sun 13 Feb 2022 14:14",
          "username": "RVivek",
          "content": "Answer isC ;The soloution should be able to quickly scale Fargate and fault resilientthenboth region should be active .Dynamodb glbal table and Route53 latency based rcords with health check",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 497306,
          "date": "Thu 09 Dec 2021 04:52",
          "username": "cldy",
          "content": "C.  Store the data in an Amazon DynamoDB global table in two Regions using on-demand capacity mode. In both Regions, run the web service as Amazon ECS Fargate tasks in an Auto Scaling ECS service behind an Application Load Balancer (ALB). In Amazon Route 53, configure an alias record in the companyג€™s domain and a Route 53 latency-based routing policy with health checks to distribute traffic between the two ALBs.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492025,
          "date": "Thu 02 Dec 2021 01:09",
          "username": "AzureDP900",
          "content": "Answer is C. <br>see Ebi explanation, I am good to with it.<br>D is not the right answer, although Aurora is better choice for structured data, but Aurora Global database supports one master only, so other regions do not support",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 484508,
          "date": "Mon 22 Nov 2021 20:33",
          "username": "nerembo",
          "content": "I think it shoud be D. <br>The question says: \\\"Across many AWS Regions, the service must be fault resilient\\\". There is nothing about that in both regions database should be writable.<br>https://aws.amazon.com/rds/aurora/faqs/ :<br>Amazon Aurora Global Database is a feature that allows a single Amazon Aurora database to span multiple AWS regions. It replicates your data with no impact on database performance, enables fast local reads in each region with typical latency of less than a second, and provides disaster recovery from region-wide outages. In the unlikely event of a regional degradation or outage, a secondary region can be promoted to full read/write capabilities in less than 1 minute.<br>https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html<br>Aurora Auto Scaling enables your Aurora DB cluster to handle sudden increases in connectivity or workload.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 462797,
          "date": "Sun 07 Nov 2021 12:24",
          "username": "kirrim",
          "content": "This was clearly C in the past due to the lack of multi-region support in DocumentDB. But in 2021, AWS implemented support for DocumentDB global clusters to support automatic replication across up to 5 regions.So now A and C are both valid candidates.<br><br>I would still lean towards C, even so, because one DocumentDB region must be primary, and the failover process to a secondary region is not seamless by any means.You have to stop application writes in the primary (failed) region, and then promote the secondary region to its own standalone master.Then you have to repoint your app to the secondary region.Not ideal.<br><br>https://aws.amazon.com/documentdb/global-clusters/<br><br>https://aws.amazon.com/blogs/database/introducing-amazon-documentdb-with-mongodb-compatibility-global-clusters/",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 443430,
          "date": "Fri 05 Nov 2021 16:59",
          "username": "andylogan",
          "content": "It's C for Dynamo",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435960,
          "date": "Mon 01 Nov 2021 11:58",
          "username": "blackgamer",
          "content": "C for me",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 434885,
          "date": "Fri 29 Oct 2021 21:29",
          "username": "tgv",
          "content": "CCC<br>---<br>A: it doesn't cover the fault-tolerant across multiple regions requirement<br>B: CloudFront is a global service<br>D: Creating multivalue answer alias records is not supported.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 421118,
          "date": "Thu 28 Oct 2021 02:13",
          "username": "TomPaschenda",
          "content": "C for me:<br>A - out because DocumentDB has no cross-region failover<br>B - out because S3 would not support writes in both regions (replication only goes one way)<br>C - only possible solution<br>D - out because EC2 ASG is not great for \\\"short but significant spikes\\\". Also \\\"download web service code in user data\\\" - why? And as pointed out, read replica would require promotion for failover",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#649",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company plans to migrate to AWS. A solutions architect uses AWS Application Discovery Service over the fleet and discovers that there is an Oracle data warehouse and several PostgreSQL databases.<br>Which combination of migration patterns will reduce licensing costs and operational overhead? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#649",
          "answers": [
            {
              "choice": "<p>A. Lift and shift the Oracle data warehouse to Amazon EC2 using AWS DMS.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Migrate the Oracle data warehouse to Amazon Redshift using AWS SCT and AWS DMS<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Lift and shift the PostgreSQL databases to Amazon EC2 using AWS DMS.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Migrate the PostgreSQL databases to Amazon RDS for PostgreSQL using AWS DMS.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Migrate the Oracle data warehouse to an Amazon EMR managed cluster using AWS DMS.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 212836,
          "date": "Mon 20 Sep 2021 07:49",
          "username": "asldavid",
          "content": "B & D <br>https://aws.amazon.com/getting-started/hands-on/migrate-oracle-to-amazon-redshift/",
          "upvote_count": "18",
          "selected_answers": ""
        },
        {
          "id": 258987,
          "date": "Wed 06 Oct 2021 00:47",
          "username": "Ebi",
          "content": "Answer is BD",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 525113,
          "date": "Sun 16 Jan 2022 18:45",
          "username": "pititcu667",
          "content": "i vote b and d",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 492026,
          "date": "Thu 02 Dec 2021 01:12",
          "username": "AzureDP900",
          "content": "B and D correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488519,
          "date": "Sat 27 Nov 2021 22:41",
          "username": "AzureDP900",
          "content": "B & D is correct answer, looks like they intentionally updating wrong answers. Read the question and understand why it is wrong vs right.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 443434,
          "date": "Fri 05 Nov 2021 21:41",
          "username": "andylogan",
          "content": "It's B D - Redshift and RDS PostgreSQL",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 442275,
          "date": "Tue 02 Nov 2021 13:39",
          "username": "student22",
          "content": "B,D<br>---<br>Oracle Dara Warehouse --> Redshift<br>PostgreSQL --> RDS PostgreSQL",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 434886,
          "date": "Wed 27 Oct 2021 03:18",
          "username": "tgv",
          "content": "BBB DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433732,
          "date": "Sun 24 Oct 2021 11:45",
          "username": "blackgamer",
          "content": "B and D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413349,
          "date": "Thu 21 Oct 2021 05:09",
          "username": "WhyIronMan",
          "content": "I'll go with B,D",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 365385,
          "date": "Tue 19 Oct 2021 22:33",
          "username": "mustpassla",
          "content": "BD, SAA level.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 356385,
          "date": "Tue 12 Oct 2021 10:55",
          "username": "Waiweng",
          "content": "it's B&D",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 293819,
          "date": "Fri 08 Oct 2021 14:57",
          "username": "Kian1",
          "content": "going with BD",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 271704,
          "date": "Thu 07 Oct 2021 14:20",
          "username": "kopper2019",
          "content": "B and D for sure",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 256386,
          "date": "Sat 02 Oct 2021 01:05",
          "username": "Bulti",
          "content": "B & D is the answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 244972,
          "date": "Fri 01 Oct 2021 16:55",
          "username": "rscloud",
          "content": "B,D for sure",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 240975,
          "date": "Tue 28 Sep 2021 17:59",
          "username": "T14102020",
          "content": "For sure B & D",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#650",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A solutions architect needs to define a reference architecture for a solution for three-tier applications with web, application, and NoSQL data layers. The reference architecture must meet the following requirements:<br>✑ High availability within an AWS Region<br>✑ Able to fail over in 1 minute to another AWS Region for disaster recovery<br>✑ Provide the most efficient solution while minimizing the impact on the user experience<br>Which combination of steps will meet these requirements? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BCE</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#650",
          "answers": [
            {
              "choice": "<p>A. Use an Amazon Route 53 weighted routing policy set to 100/0 across the two selected Regions. Set Time to Live (TTL) to 1 hour.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use an Amazon Route 53 failover routing policy for failover from the primary Region to the disaster recovery Region. Set Time to Live (TTL) to 30 seconds.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use a global table within Amazon DynamoDB so data can be accessed in the two selected Regions.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Back up data from an Amazon DynamoDB table in the primary Region every 60 minutes and then write the data to Amazon S3. Use S3 cross-Region replication to copy the data from the primary Region to the disaster recovery Region. Have a script import the data into DynamoDB in a disaster recovery scenario.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>E. Implement a hot standby model using Auto Scaling groups for the web and application layers across multiple Availability Zones in the Regions. Use zonal Reserved Instances for the minimum number of servers and On-Demand Instances for any additional resources.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>F. Use Auto Scaling groups for the web and application layers across multiple Availability Zones in the Regions. Use Spot Instances for the required resources.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 308495,
          "date": "Tue 21 Sep 2021 10:17",
          "username": "kalyan_krishna742020",
          "content": "Ans: BCE",
          "upvote_count": "22",
          "selected_answers": ""
        },
        {
          "id": 625069,
          "date": "Thu 30 Jun 2022 08:28",
          "username": "TechX",
          "content": "No-brain, it's BCE",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BCE"
        },
        {
          "id": 577673,
          "date": "Tue 29 Mar 2022 16:27",
          "username": "jj22222",
          "content": "bce - look right",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BCE"
        },
        {
          "id": 532311,
          "date": "Tue 25 Jan 2022 18:54",
          "username": "shotty1",
          "content": "it is BCE",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BCE"
        },
        {
          "id": 521510,
          "date": "Tue 11 Jan 2022 12:56",
          "username": "pititcu667",
          "content": "A will only move the dns after 1 hour so ..",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BCE"
        },
        {
          "id": 492029,
          "date": "Thu 02 Dec 2021 01:15",
          "username": "AzureDP900",
          "content": "B,C,E is perfect answer.<br>The requirements can be achieved by using an Amazon DynamoDB database with a global table. DynamoDB is a<br>NoSQL database so it fits the requirements. A global table also allows both reads and writes to occur in both Regions.<br>For the web and application tiers Auto Scaling groups should be configured. Due to the 1-minute RTO these must be<br>configured in an active/passive state. The best pricing model to lower price but ensure resources are available when<br>needed is to use a combination of zonal reserved instances and on-demand instances.<br>To failover between the Regions, a Route 53 failover routing policy can be configured with a TTL configured on the<br>record of 30 seconds. This will mean clients must resolve against Route 53 every 30 seconds to get the latest record.<br>In a failover scenario the clients would be redirected to the secondary site if the primary site is unhealthy.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 469986,
          "date": "Sat 06 Nov 2021 10:53",
          "username": "andypham",
          "content": "Yes, BBB CCC EEE",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 443444,
          "date": "Thu 28 Oct 2021 19:54",
          "username": "andylogan",
          "content": "It's B C E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436373,
          "date": "Mon 18 Oct 2021 04:12",
          "username": "tgv",
          "content": "BBB CCC EEE<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433738,
          "date": "Sun 17 Oct 2021 05:35",
          "username": "blackgamer",
          "content": "BCE is the answer",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 418377,
          "date": "Tue 12 Oct 2021 10:01",
          "username": "DanShone",
          "content": "Agree B,C,E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413350,
          "date": "Fri 08 Oct 2021 07:38",
          "username": "WhyIronMan",
          "content": "I'll go with B,C,E",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 407716,
          "date": "Thu 07 Oct 2021 21:35",
          "username": "Kopa",
          "content": "B,C,E for sure",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 362577,
          "date": "Wed 06 Oct 2021 00:06",
          "username": "victordun",
          "content": "BCE should be most optimal choices that meets requirements",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 356388,
          "date": "Sun 26 Sep 2021 06:13",
          "username": "Waiweng",
          "content": "BCE is correct",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 334794,
          "date": "Sat 25 Sep 2021 07:53",
          "username": "CarisB",
          "content": "Yes, BCE",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 313903,
          "date": "Thu 23 Sep 2021 21:46",
          "username": "wasabidev",
          "content": "BCE for me",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#651",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has a Microsoft SQL Server database in its data center and plans to migrate data to Amazon Aurora MySQL. The company has already used the AWS<br>Schema Conversion Tool to migrate triggers, stored procedures and other schema objects to Aurora MySQL. The database contains 1 TB of data and grows less than 1 MB per day. The company's data center is connected to AWS through a dedicated 1Gbps AWS Direct Connect connection.<br>The company would like to migrate data to Aurora MySQL and perform reconfigurations with minimal downtime to the applications.<br>Which solution meets the company's requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#651",
          "answers": [
            {
              "choice": "<p>A. Shut down applications over the weekend. Create an AWS DMS replication instance and task to migrate existing data from SQL Server to Aurora MySQL. Perform application testing and migrate the data to the new database endpoint.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an AWS DMS replication instance and task to migrate existing data and ongoing replication from SQL Server to Aurora MySQL. Perform application testing and migrate the data to the new database endpoint.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create a database snapshot of SQL Server on Amazon S3. Restore the database snapshot from Amazon S3 to Aurora MySQL. Create an AWS DMS replication instance and task for ongoing replication from SQL Server to Aurora MySQL. Perform application testing and migrate the data to the new database endpoint.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a SQL Server native backup file on Amazon S3. Create an AWS DMS replication instance and task to restore the SQL Server backup file to Aurora MySQL. Create another AWS DMS task for ongoing replication from SQL Server to Aurora MySQL. Perform application testing and migrate the data to the new database endpoint.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 218475,
          "date": "Wed 29 Sep 2021 07:07",
          "username": "XRiddlerXjackdryanGopiSivanathanStelSen",
          "content": "Answer is B<br>A is incorrect because shutting down the application over the weekend will cause downtime to the application.<br>C is incorrect because you can't restore a SQL Server snapshot to Aurora MySQL.They are two very different DBS engines<br>D is incorrect cause you can restore a native MSSQL backup to a Aurora MySQL because they are two different DBS engines and I'm not aware of restoring backup file functionality in DMS.<br><br>B is correct because since your have used the AWS SCT all you need to do for this migration is migrate the existing data and keep replication going until cutover.https://docs.aws.amazon.com/dms/latest/sbs/CHAP_SQLServer2Aurora.Steps.htmlTo transfer 1TB data over 1 Gbps ; it will take only 2 and 26 mins, is that not acceptable as this statement in the question? <br>The company would like to migrate data to Aurora MySQL and perform reconfigurations with minimal downtime to the applications.Read this in Option-B -> \\\"migrate existing data and ONGOING Replication....\\\". So, initially it will take 2.5 hrs and afterwards it will be almost realtime sync. So, literally no downtime or may be 5 mins to just to finish last replication.",
          "upvote_count": "35312",
          "selected_answers": ""
        },
        {
          "id": 237800,
          "date": "Tue 05 Oct 2021 23:52",
          "username": "jackdryan",
          "content": "https://docs.aws.amazon.com/dms/latest/sbs/CHAP_SQLServer2Aurora.Steps.html",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 244321,
          "date": "Wed 06 Oct 2021 10:20",
          "username": "GopiSivanathanStelSen",
          "content": "To transfer 1TB data over 1 Gbps ; it will take only 2 and 26 mins, is that not acceptable as this statement in the question? <br>The company would like to migrate data to Aurora MySQL and perform reconfigurations with minimal downtime to the applications.Read this in Option-B -> \\\"migrate existing data and ONGOING Replication....\\\". So, initially it will take 2.5 hrs and afterwards it will be almost realtime sync. So, literally no downtime or may be 5 mins to just to finish last replication.",
          "upvote_count": "12",
          "selected_answers": ""
        },
        {
          "id": 458683,
          "date": "Sun 07 Nov 2021 05:35",
          "username": "StelSen",
          "content": "Read this in Option-B -> \\\"migrate existing data and ONGOING Replication....\\\". So, initially it will take 2.5 hrs and afterwards it will be almost realtime sync. So, literally no downtime or may be 5 mins to just to finish last replication.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 495829,
          "date": "Tue 07 Dec 2021 10:30",
          "username": "cldy",
          "content": "B.  Create an AWS DMS replication instance and task to migrate existing data and ongoing replication from SQL Server to Aurora MySQL. Perform application testing and migrate the data to the new database endpoint.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492030,
          "date": "Thu 02 Dec 2021 01:19",
          "username": "AzureDP900",
          "content": "B is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 444012,
          "date": "Thu 04 Nov 2021 17:14",
          "username": "andylogan",
          "content": "It's B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435880,
          "date": "Mon 01 Nov 2021 17:09",
          "username": "Suresh108",
          "content": "BBBBBBBBBBBB<br><br>https://docs.aws.amazon.com/dms/latest/sbs/chap-sqlserver2aurora.steps.html",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 434888,
          "date": "Sat 30 Oct 2021 10:15",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413363,
          "date": "Wed 27 Oct 2021 15:23",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 356854,
          "date": "Mon 25 Oct 2021 21:53",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 321718,
          "date": "Wed 20 Oct 2021 19:49",
          "username": "alisyech",
          "content": "should be B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 293834,
          "date": "Wed 20 Oct 2021 14:37",
          "username": "Kian1",
          "content": "going with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 283589,
          "date": "Mon 18 Oct 2021 17:51",
          "username": "Trap_D0_r",
          "content": "B<br>LOL you can do B with 1-2 hours of total outage time MAX (if things go very VERY poorly), and schedule that time during extremely low usage periods or scheduled outage (if you have an uptime requirement it won't affect your SLA). \\\"A\\\" requires a full weekend of downtime. Terrible, terrible solution. See XRiddlerX's answer for why the other two options are garbage.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 272694,
          "date": "Mon 18 Oct 2021 13:27",
          "username": "Superomam",
          "content": "I've changed my idea to B.  A is not wrongbecause it's doable but reading carefully this article https://docs.aws.amazon.com/dms/latest/sbs/CHAP_SQLServer2Aurora.Steps.htm, it seems that B should be the right answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 263762,
          "date": "Mon 11 Oct 2021 02:24",
          "username": "Superomamsarah_tpablobairat",
          "content": "A.  I'm currently working into the \\\"migration arena\\\" and every time a DB must be migrated, you've to stop the application to avoid writing to the DB. you can use DMS for ongoing replication until you cut overYour company is lucky for having you ;) It is B",
          "upvote_count": "113",
          "selected_answers": ""
        },
        {
          "id": 334463,
          "date": "Fri 22 Oct 2021 14:20",
          "username": "sarah_t",
          "content": "you can use DMS for ongoing replication until you cut over",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 427632,
          "date": "Wed 27 Oct 2021 20:59",
          "username": "pablobairat",
          "content": "Your company is lucky for having you ;) It is B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 258990,
          "date": "Fri 08 Oct 2021 16:36",
          "username": "Ebi",
          "content": "B for sure,",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 256400,
          "date": "Fri 08 Oct 2021 10:58",
          "username": "Bulti",
          "content": "B is the right answer. Not C because you cannot use DMS to import a SQL Server snapshot into the Aurora SQL DB. ",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 255902,
          "date": "Thu 07 Oct 2021 02:32",
          "username": "petebear55",
          "content": "Ive seen these questions before and the answer is always A. .. don't think the question is written very well.if it mentions the app needs to run 24/7 then of course i would not choose A. but given experience with similar ? i will choose A",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 241085,
          "date": "Wed 06 Oct 2021 04:06",
          "username": "T14102020",
          "content": "For sure B",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#652",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company runs an application on a fleet of Amazon EC2 instances. The application requires low latency and random access to 100 GB of data. The application must be able to access the data at up to 3.000 IOPS. A Development team has configured the EC2 launch template to provision a 100-GB Provisioned IOPS<br>(PIOPS) Amazon EBS volume with 3 000 IOPS provisioned. A Solutions Architect is tasked with lowering costs without impacting performance and durability.<br>Which action should be taken?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#652",
          "answers": [
            {
              "choice": "<p>A. Create an Amazon EFS file system with the performance mode set to Max I/O. Configure the EC2 operating system to mount the EFS file system.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an Amazon EFS file system with the throughput mode set to Provisioned. Configure the EC2 operating system to mount the EFS file system.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Update the EC2 launch template to allocate a new 1-TB EBS General Purpose SSO (gp2) volume.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Update the EC2 launch template to exclude the PIOPS volume. Configure the application to use local instance storage.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 215489,
          "date": "Mon 20 Sep 2021 10:15",
          "username": "Gmail78AppukkKelvin1477Kelvin1477user0001",
          "content": "Definitely C https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.htmlAnswer is B as per tutorialdojoBut need to consider also ec2 fleet instances, 1 ec2 can tied to only 1 ebs volumeLooks like it:100 GiB gp2 volume has a baseline performance of 300 IOPS.agree it is C",
          "upvote_count": "162511",
          "selected_answers": ""
        },
        {
          "id": 700105,
          "date": "Thu 20 Oct 2022 18:10",
          "username": "Appukk",
          "content": "Answer is B as per tutorialdojo",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 225436,
          "date": "Wed 29 Sep 2021 08:33",
          "username": "Kelvin1477",
          "content": "But need to consider also ec2 fleet instances, 1 ec2 can tied to only 1 ebs volume",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 225428,
          "date": "Sat 25 Sep 2021 17:08",
          "username": "Kelvin1477",
          "content": "Looks like it:100 GiB gp2 volume has a baseline performance of 300 IOPS.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 606793,
          "date": "Tue 24 May 2022 17:56",
          "username": "user0001",
          "content": "agree it is C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 215603,
          "date": "Wed 22 Sep 2021 18:41",
          "username": "keoskeos",
          "content": "B likelyshould be C, cheaper than provisioned<br><br>A,B is misleading",
          "upvote_count": "154",
          "selected_answers": ""
        },
        {
          "id": 224937,
          "date": "Fri 24 Sep 2021 16:04",
          "username": "keos",
          "content": "should be C, cheaper than provisioned<br><br>A,B is misleading",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 730978,
          "date": "Wed 30 Nov 2022 02:17",
          "username": "SureNot",
          "content": "C the cheapest",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 727076,
          "date": "Fri 25 Nov 2022 21:53",
          "username": "timmysixstrings",
          "content": "Launch templates are immutable, so C and D are out. Question never mentions throughput, so B is out. The remaining answer is A.  <br><br>The question also never mentions if the storage can be shared or not. I chose A because I eliminated the other answers but overall I think this question is poorly written.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 715174,
          "date": "Thu 10 Nov 2022 12:20",
          "username": "Heer",
          "content": "gp2 is designed to offer single-digit millisecond latency, deliver a consistent baseline performance of 3 IOPS/GB (minimum 100 IOPS) to a maximum of 16,000 IOPS, and provide up to 250 MB/s of throughput per volume. gp2 volumes smaller than 1 TB can also burst up to 3,000 IOPS.<br><br>The right ans is C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 640098,
          "date": "Sun 31 Jul 2022 14:08",
          "username": "Enigmaaaaaa",
          "content": "Lets say there are 1000 EC2 instances and we want to save cost.<br>The choice is between B and C:<br>1000instances with 1TB of GP2 data is: 10K a month<br>1000instances with 100GB of io1 with 3000 iopsis: 20.7K a month<br>So C is valid.<br>Now regarding EFS its not clear by the question if the data can be shared between the instances or its unique per instance - if it can be shared 100 GB of EFS is cheaper<br>if we need 100gb*1000 = 100tb C is cheaper.<br>Since the questions does not state that data can be shared between instance i will have to choose C",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 612993,
          "date": "Wed 08 Jun 2022 02:50",
          "username": "kangtamo",
          "content": "Go with C. ",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 492031,
          "date": "Thu 02 Dec 2021 01:22",
          "username": "AzureDP900",
          "content": "General Purpose SSD, It is typo in question. I will go with C. ",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 463257,
          "date": "Fri 05 Nov 2021 14:48",
          "username": "kirrim",
          "content": "The key consideration here is that the company is paying for individual disks for every EC2 instance in their fleet.The question translates to: Is it cheaper to provision that on an individual disk basis for every EC2 instance in the fleet using a different disk approach, or is it cheaper to provision a shared EFS volume and mount it on every instance in the fleet?<br><br>Ultimately this question comes down to:<br>- how much EFS data throughput is your app going to need (which you would need to multiply by the number of servers accessing the EFS filesystem)<br>- how many servers are in your fleet?<br><br>And we are not told how many servers are in the fleet, nor the throughput needed based on the application's average block size per operation.Both are critical factors in making this decision.I'm not a fan of this question due to that missing info.<br><br>Without that crucial info, I'm just going to default to keeping things the way they're doing today with individual disks on each instance, and save on cost by going with gp2, but that's really answering the question at all.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 444024,
          "date": "Thu 04 Nov 2021 09:39",
          "username": "andylogan",
          "content": "It's C - 1-TB EBS General Purpose SSO (gp2)",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 434894,
          "date": "Thu 04 Nov 2021 01:31",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 433740,
          "date": "Sun 31 Oct 2021 06:32",
          "username": "blackgamer",
          "content": "B is the answer. It can’t be A because of the unnecessary cost for max io.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 422929,
          "date": "Sat 30 Oct 2021 11:06",
          "username": "saggarwal4114",
          "content": "It is B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 414500,
          "date": "Wed 27 Oct 2021 00:24",
          "username": "mericovtkanmani76",
          "content": "\\\"Launch templates are immutable. To modify a launch template, you must create a new version of the launch template.\\\" - there is no option to update the launch templates (C&D). Provisioned for EFS is referring to the throughput (MiB/s), for which we do not have any info. The remaining option is A - MaxIOAgree on the launch templates - C and D are incorrect. The below passage sounds A is not the right choice. <br>Some latency-sensitive workloads require the higher I/O levels provided by Max I/O performance mode and the lower latency provided by General Purpose performance mode. For this type of workload, we recommend creating multiple General Purpose performance mode file systems. <br>https://docs.aws.amazon.com/efs/latest/ug/performance.html<br>Hence going with B. ",
          "upvote_count": "42",
          "selected_answers": ""
        },
        {
          "id": 508913,
          "date": "Sat 25 Dec 2021 01:37",
          "username": "tkanmani76",
          "content": "Agree on the launch templates - C and D are incorrect. The below passage sounds A is not the right choice. <br>Some latency-sensitive workloads require the higher I/O levels provided by Max I/O performance mode and the lower latency provided by General Purpose performance mode. For this type of workload, we recommend creating multiple General Purpose performance mode file systems. <br>https://docs.aws.amazon.com/efs/latest/ug/performance.html<br>Hence going with B. ",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 413365,
          "date": "Tue 26 Oct 2021 21:12",
          "username": "WhyIronManAWSum1somebodyelse",
          "content": "I'll go with C<br><br>Guys, please READ the question!!!!!<br><br>The questions never said that's a single volume mounted/shared across instances!!!!<br><br>So, instead of having<br>-1 x 100 Gb 3000 PIOPs PER INSTANCE is cheaper to have<br>-1 x 1000 Gb (1000 x 3 iops) PER INSTANCE<br><br>If you guys don't read the question at least twice it'll be difficult to go well in the examC- because of this exact reasonhttps://aws.amazon.com/ebs/general-purpose/<br>I think GP might do the required 3000 iops",
          "upvote_count": "923",
          "selected_answers": ""
        },
        {
          "id": 470863,
          "date": "Sat 06 Nov 2021 09:32",
          "username": "AWSum1",
          "content": "C- because of this exact reason",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 434518,
          "date": "Tue 02 Nov 2021 05:37",
          "username": "somebodyelse",
          "content": "https://aws.amazon.com/ebs/general-purpose/<br>I think GP might do the required 3000 iops",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 402332,
          "date": "Sat 23 Oct 2021 09:14",
          "username": "qurren",
          "content": "It is C<br><br>EFS is not correct for this random access requirement, so rule out A/B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 380635,
          "date": "Fri 22 Oct 2021 14:49",
          "username": "XAvenger",
          "content": "There are concerns related to the EBS volume attached to multiple EC2 instances (how are they going to use single volume for multiple EC2 instances??) If they are going to user multiple EBS volumes then EFS looks cheaper.<br>BUT I tried to find any information related to EFS IOPS. About EFS throughput - there is much information, but not about EFS IOPS.<br><br>I would choose C despite the fact the option is weird.",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#653",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company recently transformed its legacy infrastructure provisioning scripts to AWS CloudFormation templates. The newly developed templates are hosted in the company's private GitHub repository. Since adopting CloudFormation, the company has encountered several issues with updates to the CloudFormation templates, causing execution or creating environment. Management is concerned by the increase in errors and has asked a Solutions Architect to design the automated testing of CloudFormation template updates.<br>What should the Solution Architect do to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#653",
          "answers": [
            {
              "choice": "<p>A. Use AWS CodePipeline to create a change set from the CloudFormation templates stored in the private GitHub repository. Execute the change set using AWS CodeDeploy. Include a CodePipeline action to test the deployment with testing scripts run by AWS CodeBuild.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Mirror the GitHub repository to AWS CodeCommit using AWS Lambda. Use AWS CodeDeploy to create a change set from the CloudFormation templates and execute it. Have CodeDeploy test the deployment with testing scripts run by AWS CodeBuild.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use AWS CodePipeline to create and execute a change set from the CloudFormation templates stored in the GitHub repository. Configure a CodePipeline action to be deployment with testing scripts run by AWS CodeBuild.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Mirror the GitHub repository to AWS CodeCommit using AWS Lambda. Use AWS CodeBuild to create a change set from the CloudFormation templates and execute it. Have CodeBuild test the deployment with testing scripts.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 284565,
          "date": "Tue 19 Oct 2021 22:20",
          "username": "Ebi",
          "content": "C is my answer",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 256441,
          "date": "Wed 13 Oct 2021 12:17",
          "username": "Bulti",
          "content": "Answer is C.  Not A because CodeDeploy is not required to execute the changeset. CodePiepline action can do that.",
          "upvote_count": "8",
          "selected_answers": ""
        },
        {
          "id": 622747,
          "date": "Sun 26 Jun 2022 20:35",
          "username": "kangtamo",
          "content": "Agree with C. ",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 499071,
          "date": "Sat 11 Dec 2021 04:39",
          "username": "challenger1",
          "content": "My Answer: C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492033,
          "date": "Thu 02 Dec 2021 01:24",
          "username": "AzureDP900",
          "content": "C is perfect",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 444288,
          "date": "Fri 05 Nov 2021 23:45",
          "username": "andylogan",
          "content": "It's C - CodePipeline create and execute change set",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436382,
          "date": "Fri 05 Nov 2021 13:09",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433741,
          "date": "Fri 05 Nov 2021 03:04",
          "username": "blackgamer",
          "content": "Crun test during build",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 414512,
          "date": "Wed 03 Nov 2021 13:48",
          "username": "mericovkirrim",
          "content": "C: - https://aws.amazon.com/blogs/devops/building-a-ci-cd-pipeline-to-update-an-aws-cloudformation-stacksets/Agree, that architecture exactly matches C (except it uses CodeCommit instead of GitHub as in the question, but minor difference)",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 463264,
          "date": "Sat 06 Nov 2021 06:26",
          "username": "kirrim",
          "content": "Agree, that architecture exactly matches C (except it uses CodeCommit instead of GitHub as in the question, but minor difference)",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413366,
          "date": "Wed 03 Nov 2021 10:16",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 365962,
          "date": "Fri 29 Oct 2021 09:25",
          "username": "mustpassla",
          "content": "It is B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 356887,
          "date": "Tue 26 Oct 2021 02:08",
          "username": "Waiweng",
          "content": "it's C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 321721,
          "date": "Fri 22 Oct 2021 03:14",
          "username": "alisyech",
          "content": "C seems correct",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 293886,
          "date": "Tue 19 Oct 2021 23:18",
          "username": "Kian1",
          "content": "going with C",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 283596,
          "date": "Sat 16 Oct 2021 20:21",
          "username": "Trap_D0_r",
          "content": "I want to vote for A since C is actual gibberish and there's a lot of reading between the lines to make it coherent...",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 252464,
          "date": "Mon 11 Oct 2021 05:45",
          "username": "RLai",
          "content": "C is the answer.<br>https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/use-third-party-git-source-repositories-in-aws-codepipeline.html",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 244985,
          "date": "Mon 11 Oct 2021 02:24",
          "username": "rscloud",
          "content": "I will go with C",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#654",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has several Amazon EC2 instances to both public and private subnets within a VPC that is not connected to the corporate network. A security group associated with the EC2 instances allows the company to use the Windows remote desktop protocol (RDP) over the internet to access the instances. The security team has noticed connection attempts from unknown sources. The company wants to implement a more secure solution to access the EC2 instances.<br>Which strategy should a solutions architect implement?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#654",
          "answers": [
            {
              "choice": "<p>A. Deploy a Linux bastion host on the corporate network that has access to all instances in the VPC. <br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Deploy AWS Systems Manager Agent on the EC2 instances. Access the EC2 instances using Session Manager restricting access to users with permission.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Deploy a Linux bastion host with an Elastic IP address in the public subnet. Allow access to the bastion host from 0.0.0.0/0.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Establish a Site-to-Site VPN connecting the corporate network to the VPC.  Update the security groups to allow access from the corporate network only.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 259008,
          "date": "Mon 04 Oct 2021 00:27",
          "username": "Ebi",
          "content": "Answer is B, with Systems Manager agent you can manage EC2 instances without the need to open inbound ports.",
          "upvote_count": "23",
          "selected_answers": ""
        },
        {
          "id": 225485,
          "date": "Wed 22 Sep 2021 14:57",
          "username": "Kelvin1477",
          "content": "I still prefer B or SSM Session Manager, as the other option is using Linux bastion where the question here is talking about Windows RDP which i believe the target instance is Windows Server",
          "upvote_count": "13",
          "selected_answers": ""
        },
        {
          "id": 671364,
          "date": "Sat 17 Sep 2022 10:51",
          "username": "joancarles",
          "content": "It would be necessary to add a role to the EC2 computers for SSM access, installing only the agent is not enough. On the other hand, users would have to change the use of RDP to open the session through the Fleet Manager, since from the connect tab, they would only get a power shell. For me, the most balanced answer would be D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 532314,
          "date": "Tue 25 Jan 2022 18:56",
          "username": "shotty1",
          "content": "it is B",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 521512,
          "date": "Tue 11 Jan 2022 12:58",
          "username": "pititcu667",
          "content": "It a windows / ssm based question. it' trying to assert if you know about the remove login option of ssm",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 494801,
          "date": "Mon 06 Dec 2021 02:50",
          "username": "vbal",
          "content": "https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/connecting_to_windows_instance.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491574,
          "date": "Wed 01 Dec 2021 12:14",
          "username": "AzureDP900",
          "content": "B is right. Systems manager manages EC2 instances",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491573,
          "date": "Wed 01 Dec 2021 12:13",
          "username": "AzureDP900",
          "content": "D is right. Systems manager manages EC2 instances",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 449845,
          "date": "Sat 06 Nov 2021 08:31",
          "username": "LiongeekViper57Liongeek",
          "content": "I totally agree with all those who say it's B.  I'd mark B too. I'm just a bit concern by \\\"Windows remote desktop protocol\\\" which can't be used with session manager.RDP isn't required if you use session manager as it can be accessed through the console. You can created a RDP tunnel through session manager if its completely necessary. <br><br>https://awscloudsecvirtualevent.com/workshops/module1/rdp/I switch to B thanks to this lab, we can use SSM to RDP an EC2 Windows instance",
          "upvote_count": "121",
          "selected_answers": ""
        },
        {
          "id": 457893,
          "date": "Sat 06 Nov 2021 09:55",
          "username": "Viper57Liongeek",
          "content": "RDP isn't required if you use session manager as it can be accessed through the console. You can created a RDP tunnel through session manager if its completely necessary. <br><br>https://awscloudsecvirtualevent.com/workshops/module1/rdp/I switch to B thanks to this lab, we can use SSM to RDP an EC2 Windows instance",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 476640,
          "date": "Fri 12 Nov 2021 03:55",
          "username": "Liongeek",
          "content": "I switch to B thanks to this lab, we can use SSM to RDP an EC2 Windows instance",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 444520,
          "date": "Sat 06 Nov 2021 02:02",
          "username": "andylogan",
          "content": "It's B - Systems Manager agent can manage EC2 instances with RDP",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 442613,
          "date": "Fri 05 Nov 2021 17:46",
          "username": "Goram113",
          "content": "https://aws.amazon.com/blogs/mt/manage-aws-managed-microsoft-ad-resources-with-session-manager-port-forwarding/<br><br>it is B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436384,
          "date": "Thu 04 Nov 2021 13:27",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433743,
          "date": "Wed 03 Nov 2021 14:30",
          "username": "blackgamer",
          "content": "B for sure",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413368,
          "date": "Wed 20 Oct 2021 16:50",
          "username": "WhyIronManjobe42TomPaschenda",
          "content": "I'll go with B<br><br>Guys, with Systems Manager agent you can manage EC2 instances without the need to leave open ports to the world.<br><br>Also, you can control which user's can access Systems Manager, giving one more security controlAfter Reading:https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/connecting_to_windows_instance.html#session-manager\\\" After the session is started, you can run Powershell commands as you would through any other connection type. \\\" , so no RDP, just PS => DYou can use Port Forwarding with SSM to still access via Remote Desktop: https://aws.amazon.com/about-aws/whats-new/2019/08/now-forward-traffic-between-a-local-and-remote-port-using-session-manager/<br>B is correct",
          "upvote_count": "212",
          "selected_answers": ""
        },
        {
          "id": 416266,
          "date": "Tue 02 Nov 2021 09:45",
          "username": "jobe42TomPaschenda",
          "content": "After Reading:https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/connecting_to_windows_instance.html#session-manager\\\" After the session is started, you can run Powershell commands as you would through any other connection type. \\\" , so no RDP, just PS => DYou can use Port Forwarding with SSM to still access via Remote Desktop: https://aws.amazon.com/about-aws/whats-new/2019/08/now-forward-traffic-between-a-local-and-remote-port-using-session-manager/<br>B is correct",
          "upvote_count": "12",
          "selected_answers": ""
        },
        {
          "id": 421501,
          "date": "Tue 02 Nov 2021 13:46",
          "username": "TomPaschenda",
          "content": "You can use Port Forwarding with SSM to still access via Remote Desktop: https://aws.amazon.com/about-aws/whats-new/2019/08/now-forward-traffic-between-a-local-and-remote-port-using-session-manager/<br>B is correct",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 404886,
          "date": "Wed 20 Oct 2021 10:25",
          "username": "Tony_WWhyIronMan",
          "content": "The security team has noticed connection attempts. The ONLY way to stop this it seems is a site-to-site VPN. A and C won't work with Windows so they are auto out. Seems to me a VPN secures the connection, stops the outside attempts, and would allow RDP without any other config changes.You're wrong. SSM Sessions manager works for windows and you don't need to leave the ports open to the world.<br>https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/connecting_to_windows_instance.html#session-manager",
          "upvote_count": "12",
          "selected_answers": ""
        },
        {
          "id": 413370,
          "date": "Fri 22 Oct 2021 05:33",
          "username": "WhyIronMan",
          "content": "You're wrong. SSM Sessions manager works for windows and you don't need to leave the ports open to the world.<br>https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/connecting_to_windows_instance.html#session-manager",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 400223,
          "date": "Tue 19 Oct 2021 22:25",
          "username": "zapper1234DerekKeyWhyIronMan",
          "content": "It has to be \\\"D\\\". All other answer still leave the EC2 open to the word.You are wrong. Session Manager allows for connection without any change to your VPC/Security configurationYou're wrong. SSM Sessions manager works for windows and you don't need to leave the ports open to the world.<br><br>https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/connecting_to_windows_instance.html#session-manager",
          "upvote_count": "311",
          "selected_answers": ""
        },
        {
          "id": 439018,
          "date": "Fri 05 Nov 2021 14:05",
          "username": "DerekKey",
          "content": "You are wrong. Session Manager allows for connection without any change to your VPC/Security configuration",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413371,
          "date": "Fri 22 Oct 2021 16:22",
          "username": "WhyIronMan",
          "content": "You're wrong. SSM Sessions manager works for windows and you don't need to leave the ports open to the world.<br><br>https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/connecting_to_windows_instance.html#session-manager",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 396191,
          "date": "Tue 19 Oct 2021 21:04",
          "username": "zapper1234WhyIronMan",
          "content": "It has to be D.  B would still allow (but deny) connection attempts from outside. Whereas, D would not.You're wrong. SSM Sessions manager works for windows and you don't need to leave the ports open to the world.<br>https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/connecting_to_windows_instance.html#session-manager",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 413373,
          "date": "Sun 24 Oct 2021 03:12",
          "username": "WhyIronMan",
          "content": "You're wrong. SSM Sessions manager works for windows and you don't need to leave the ports open to the world.<br>https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/connecting_to_windows_instance.html#session-manager",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#655",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A retail company has a custom .NET web application running on AWS that uses Microsoft SQL Server for the database. The application servers maintain a user's session locally.<br>Which combination of architecture changes are needed to ensure all tiers of the solution are highly available? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: ACE</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#655",
          "answers": [
            {
              "choice": "<p>A. Refactor the application to store the user's session in Amazon ElastiCache. Use Application Load Balancers to distribute the load between application instances.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Set up the database to generate hourly snapshots using Amazon EBS. Configure an Amazon CloudWatch Events rule to launch a new database instance if the primary one fails.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Migrate the database to Amazon RDS for SQL Server. Configure the RDS instance to use a Multi-AZ deployment.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Move the .NET content to an Amazon S3 bucket. Configure the bucket for static website hosting.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>E. Put the application instances in an Auto Scaling group. Configure the Auto Scaling group to create new instances if an instance becomes unhealthy.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>F. Deploy Amazon CloudFront in front of the application tier. Configure CloudFront to serve content from healthy application instances only.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 213419,
          "date": "Wed 22 Sep 2021 02:08",
          "username": "lionoMarkDillon1075cpdWhyIronManXRiddlerX",
          "content": "A, C, E are correctC,D,E. The question asks for a highly available solution for all tiers. A - gives load balancing, not high availability.\\\"Move the .NET content to an Amazon S3 bucket\\\" does NOT make sense.yeah? hey genius,how you will handle session management ? you need AAnswer is A,C,E<br>D is incorrect because S3 doesn't support server-side scripting like \\\"ASP.NET, PHP, or JSP\\\".In addition, high availability is one of the features of ELB. <br>ELB Features - https://aws.amazon.com/elasticloadbalancing/features/#:~:text=High%20availability,response%20to%20incoming%20application%20traffic.<br><br>S3 static web site hosting - https://docs.amazonaws.cn/en_us/AmazonS3/latest/user-guide/static-website-hosting.html<br>\\\"You can host a static website on Amazon S3. On a static website, individual webpages include static content. A static website might also contain client-side scripts. By contrast, a dynamic website relies on server-side processing, including server-side scripts such as PHP, JSP, or ASP.NET. Amazon S3 does not support server-side scripting.\\\"",
          "upvote_count": "301438",
          "selected_answers": ""
        },
        {
          "id": 216819,
          "date": "Thu 23 Sep 2021 23:53",
          "username": "MarkDillon1075cpdWhyIronManXRiddlerX",
          "content": "C,D,E. The question asks for a highly available solution for all tiers. A - gives load balancing, not high availability.\\\"Move the .NET content to an Amazon S3 bucket\\\" does NOT make sense.yeah? hey genius,how you will handle session management ? you need AAnswer is A,C,E<br>D is incorrect because S3 doesn't support server-side scripting like \\\"ASP.NET, PHP, or JSP\\\".In addition, high availability is one of the features of ELB. <br>ELB Features - https://aws.amazon.com/elasticloadbalancing/features/#:~:text=High%20availability,response%20to%20incoming%20application%20traffic.<br><br>S3 static web site hosting - https://docs.amazonaws.cn/en_us/AmazonS3/latest/user-guide/static-website-hosting.html<br>\\\"You can host a static website on Amazon S3. On a static website, individual webpages include static content. A static website might also contain client-side scripts. By contrast, a dynamic website relies on server-side processing, including server-side scripts such as PHP, JSP, or ASP.NET. Amazon S3 does not support server-side scripting.\\\"",
          "upvote_count": "1438",
          "selected_answers": ""
        },
        {
          "id": 218928,
          "date": "Wed 29 Sep 2021 01:27",
          "username": "cpd",
          "content": "\\\"Move the .NET content to an Amazon S3 bucket\\\" does NOT make sense.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 413388,
          "date": "Mon 18 Oct 2021 17:18",
          "username": "WhyIronMan",
          "content": "yeah? hey genius,how you will handle session management ? you need A",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 218494,
          "date": "Mon 27 Sep 2021 21:52",
          "username": "XRiddlerX",
          "content": "Answer is A,C,E<br>D is incorrect because S3 doesn't support server-side scripting like \\\"ASP.NET, PHP, or JSP\\\".In addition, high availability is one of the features of ELB. <br>ELB Features - https://aws.amazon.com/elasticloadbalancing/features/#:~:text=High%20availability,response%20to%20incoming%20application%20traffic.<br><br>S3 static web site hosting - https://docs.amazonaws.cn/en_us/AmazonS3/latest/user-guide/static-website-hosting.html<br>\\\"You can host a static website on Amazon S3. On a static website, individual webpages include static content. A static website might also contain client-side scripts. By contrast, a dynamic website relies on server-side processing, including server-side scripts such as PHP, JSP, or ASP.NET. Amazon S3 does not support server-side scripting.\\\"",
          "upvote_count": "8",
          "selected_answers": ""
        },
        {
          "id": 259019,
          "date": "Sat 09 Oct 2021 22:12",
          "username": "Ebi",
          "content": "Answer is ACE",
          "upvote_count": "10",
          "selected_answers": ""
        },
        {
          "id": 498423,
          "date": "Fri 10 Dec 2021 09:39",
          "username": "cldy",
          "content": "A.  Refactor the application to store the userג€™s session in Amazon ElastiCache. Use Application Load Balancers to distribute the load between application instances.<br>C.  Migrate the database to Amazon RDS for SQL Server. Configure the RDS instance to use a Multi-AZ deployment.<br>E.  Put the application instances in an Auto Scaling group. Configure the Auto Scaling group to create new instances if an instance becomes unhealthy.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492038,
          "date": "Thu 02 Dec 2021 01:29",
          "username": "AzureDP900",
          "content": "A,C, E is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488675,
          "date": "Sun 28 Nov 2021 02:31",
          "username": "acloudguru",
          "content": "hope I can have it in my exam as difficile ones",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488673,
          "date": "Sun 28 Nov 2021 02:31",
          "username": "acloudguru",
          "content": "D is incorrect because S3 doesn't support server-side scripting like \\\"ASP.NET, PHP, or JSP\\\". In addition, high availability is one of the features of ELB. <br>ELB Features - https://aws.amazon.com/elasticloadbalancing/features/#:~:text=High%20availability,response%20to%20incoming%20application%20traffic.<br><br>S3 static web site hosting - https://docs.amazonaws.cn/en_us/AmazonS3/latest/user-guide/static-website-hosting.html<br>\\\"You can host a static website on Amazon S3. On a static website, individual webpages include static content. A static website might also contain client-side scripts. By contrast, a dynamic website relies on server-side processing, including server-side scripts such as PHP, JSP, or ASP.NET. Amazon S3 does not support server-side scripting.\\\"",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ACE"
        },
        {
          "id": 444525,
          "date": "Sat 06 Nov 2021 14:27",
          "username": "andylogan",
          "content": "It's A C E - ElasticCache, RDS Multi AZ, Auto Scaling group",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 439383,
          "date": "Fri 05 Nov 2021 17:28",
          "username": "student22",
          "content": "A,C,E<br>A - Session management<br>C - HA DB<br>E - HA Application",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436390,
          "date": "Sat 30 Oct 2021 09:36",
          "username": "tgv",
          "content": "AAA CCC EEE<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433744,
          "date": "Mon 25 Oct 2021 23:29",
          "username": "blackgamer",
          "content": "ACE is correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413389,
          "date": "Fri 22 Oct 2021 07:06",
          "username": "WhyIronMan",
          "content": "I'll go with A,C,E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 356908,
          "date": "Sat 16 Oct 2021 04:00",
          "username": "Waiweng",
          "content": "it;s A,C,E",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 341987,
          "date": "Wed 13 Oct 2021 01:27",
          "username": "nil3112",
          "content": "can AWS RDS supports SQL server or we have to put it on EC2 ?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 321723,
          "date": "Tue 12 Oct 2021 18:13",
          "username": "alisyech",
          "content": "A C E for sure",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 301311,
          "date": "Tue 12 Oct 2021 16:53",
          "username": "kiev",
          "content": "ACE is the correct answer. S3 don't use NET applications as they are dynamic and that also rules out cloudfront.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 294155,
          "date": "Sun 10 Oct 2021 17:22",
          "username": "Kian1",
          "content": "going with ACE",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 269226,
          "date": "Sun 10 Oct 2021 06:41",
          "username": "kopper2019",
          "content": "A,C,E without thinking twice about it",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#656",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is using an existing orchestration tool to manage thousands of Amazon EC2 instances. A recent penetration test found a vulnerability in the company's software stack. This vulnerability has prompted the company to perform a full evaluation of its current production environment. The analysis determined that the following vulnerabilities exist within the environment:<br>✑ Operating systems with outdated libraries and known vulnerabilities are being used in production.<br>✑ Relational databases hosted and managed by the company are running unsupported versions with known vulnerabilities.<br>✑ Data stored in databases is not encrypted.<br>The solutions architect intends to use AWS Config to continuously audit and assess the compliance of the company's AWS resource configurations with the company's policies and guidelines.<br>What additional steps will enable the company to secure its environments and track resources while adhering to best practices?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: D</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#656",
          "answers": [
            {
              "choice": "<p>A. Use AWS Application Discovery Service to evaluate all running EC2 instances Use the AWS CLI to modify each instance, and use EC2 user data to install the AWS Systems Manager Agent during boot. Schedule patching to run as a Systems Manager Maintenance Windows task. Migrate all relational databases to Amazon RDS and enable AWS KMS encryption.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an AWS CloudFormation template for the EC2 instances. Use EC2 user data in the CloudFormation template to install the AWS Systems Manager Agent, and enable AWS KMS encryption on all Amazon EBS volumes. Have CloudFormation replace all running instances. Use Systems Manager Patch Manager to establish a patch baseline and deploy a Systems Manager Maintenance Windows task to execute AWS-RunPatchBaseline using the patch baseline.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Install the AWS Systems Manager Agent on all existing instances using the company's current orchestration tool. Use the Systems Manager Run Command to execute a list of commands to upgrade software on each instance using operating system-specific tools. Enable AWS KMS encryption on all Amazon EBS volumes.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Install the AWS Systems Manager Agent on all existing instances using the company's current orchestration tool. Migrate all relational databases to Amazon RDS and enable AWS KMS encryption. Use Systems Manager Patch Manager to establish a patch baseline and deploy a Systems Manager Maintenance Windows task to execute AWS-RunPatchBaseline using the patch baseline.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 213422,
          "date": "Wed 22 Sep 2021 09:20",
          "username": "liono",
          "content": "D looks correct",
          "upvote_count": "15",
          "selected_answers": ""
        },
        {
          "id": 259022,
          "date": "Sat 09 Oct 2021 17:02",
          "username": "Ebi",
          "content": "D for sure",
          "upvote_count": "10",
          "selected_answers": ""
        },
        {
          "id": 492039,
          "date": "Thu 02 Dec 2021 01:30",
          "username": "AzureDP900",
          "content": "D is correct answer !",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 437066,
          "date": "Sat 30 Oct 2021 10:41",
          "username": "Kopa",
          "content": "D correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436392,
          "date": "Wed 27 Oct 2021 08:17",
          "username": "tgv",
          "content": "DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433264,
          "date": "Mon 25 Oct 2021 18:06",
          "username": "Suresh108",
          "content": "B, C -eliminated, no mention of RDS<br>A - AWS Application Discovery Service involved with on premise migration , elimiate it. <br><br>choosing DDDDDD",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 413392,
          "date": "Tue 19 Oct 2021 22:29",
          "username": "WhyIronMan",
          "content": "I'll go with D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 356913,
          "date": "Tue 19 Oct 2021 09:54",
          "username": "Waiweng",
          "content": "it;s D",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 294159,
          "date": "Tue 12 Oct 2021 00:08",
          "username": "Kian1",
          "content": "going with D",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 256469,
          "date": "Sun 03 Oct 2021 04:16",
          "username": "Bulti",
          "content": "D is correct. You do not want to go with B because it's a lot of work to replace the current orchestration toll with cloud formation templates",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 241189,
          "date": "Mon 27 Sep 2021 18:59",
          "username": "T14102020",
          "content": "D is correct",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 233227,
          "date": "Sat 25 Sep 2021 04:55",
          "username": "jackdryan",
          "content": "I'll go with D",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 213505,
          "date": "Fri 24 Sep 2021 12:49",
          "username": "liono",
          "content": "You need to encrypt DB during creation.",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#657",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company wants to improve cost awareness for its Amazon EMR platform. The company has allocated budgets for each team's Amazon EMR usage. When a budgetary threshold is reached, a notification should be sent by email to the budget office's distribution list. Teams should be able to view their EMR cluster expenses to date. A solutions architect needs to create a solution that ensures the policy is proactively and centrally enforced in a multi-account environment.<br>Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: AD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#657",
          "answers": [
            {
              "choice": "<p>A. Update the AWS CloudFormation template to include the AWS::Budgets::Budget::resource with the NotificationsWithSubscribers property.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Implement Amazon CloudWatch dashboards for Amazon EMR usage.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create an EMR bootstrap action that runs at startup that calls the Cost Explorer API to set the budget on the cluster with the GetCostForecast and NotificationsWithSubscribers actions.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create an AWS Service Catalog portfolio for each team. Add each team's Amazon EMR cluster as an AWS CloudFormation template to their Service Catalog portfolio as a Product.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Create an Amazon CloudWatch metric for billing. Create a custom alert when costs exceed the budgetary threshold.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 213636,
          "date": "Thu 23 Sep 2021 21:36",
          "username": "lionoarulrajjayarajoscargeeWaiweng",
          "content": "A & D<br>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-budgets-budget.htmlWhy not DE - custom alert when costs exceed the budgetary thresholdIt's AWS::Budgets::Budget not AWS::Budgets::Budget::resource. Please read the html you posted more carefully. A is wrong!there's typo in the answer as it should be AWS::Bugests::Budget. the content of the answer is complete. The questions want centrally managing the requirement to which A&D should satisfy",
          "upvote_count": "18112",
          "selected_answers": ""
        },
        {
          "id": 231298,
          "date": "Sat 25 Sep 2021 05:00",
          "username": "arulrajjayaraj",
          "content": "Why not DE - custom alert when costs exceed the budgetary threshold",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 368082,
          "date": "Wed 27 Oct 2021 11:40",
          "username": "oscargeeWaiweng",
          "content": "It's AWS::Budgets::Budget not AWS::Budgets::Budget::resource. Please read the html you posted more carefully. A is wrong!there's typo in the answer as it should be AWS::Bugests::Budget. the content of the answer is complete. The questions want centrally managing the requirement to which A&D should satisfy",
          "upvote_count": "12",
          "selected_answers": ""
        },
        {
          "id": 383065,
          "date": "Wed 27 Oct 2021 13:15",
          "username": "Waiweng",
          "content": "there's typo in the answer as it should be AWS::Bugests::Budget. the content of the answer is complete. The questions want centrally managing the requirement to which A&D should satisfy",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 613599,
          "date": "Thu 09 Jun 2022 04:49",
          "username": "AnhddAnhdd",
          "content": "why not BE?sorry, typo. I mean why not DE?",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 613600,
          "date": "Thu 09 Jun 2022 04:50",
          "username": "Anhdd",
          "content": "sorry, typo. I mean why not DE?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 582738,
          "date": "Fri 08 Apr 2022 09:28",
          "username": "Netaji",
          "content": "A:Update the AWS CloudFormation template to include the AWS::Budgets::Budget::resource with the NotificationsWithSubscribers property.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 558565,
          "date": "Tue 01 Mar 2022 05:41",
          "username": "itznotme",
          "content": "https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-budgets-budget.html",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: AD"
        },
        {
          "id": 513949,
          "date": "Fri 31 Dec 2021 09:33",
          "username": "cldy",
          "content": "A and D. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492045,
          "date": "Thu 02 Dec 2021 01:32",
          "username": "AzureDP900",
          "content": "I will go with A & D <br><br>You can use AWS Budgets to track your service costs and usage within AWS Service Catalog. You can associate<br>budgets with AWS Service Catalog products and portfolios.<br>AWS Budgets gives you the ability to set custom budgets that alert you when your costs or usage exceed (or are<br>forecasted to exceed) your budgeted amount.<br>If a budget is associated to a product, you can view information about the budget on the Products and Product<br>details page. If a budget is associated to a portfolio, you can view information about the budget on<br>the Portfolios and Portfolio details page.<br>When you click on a product or portfolio, you are taken to a detail page. These Portfolio detail and Product<br>detail pages have a section with detailed information about the associated budget. You can see the budgeted<br>amount, current spend, and forecasted spend. You also have the option to view budget details and edit the budget.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 445598,
          "date": "Sun 07 Nov 2021 02:23",
          "username": "andylogan",
          "content": "It's A D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435235,
          "date": "Wed 03 Nov 2021 14:03",
          "username": "tgv",
          "content": "AAA DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433754,
          "date": "Sat 30 Oct 2021 12:30",
          "username": "blackgamerblackgamer",
          "content": "Yes, A & D. https://docs.aws.amazon.com/servicecatalog/latest/adminguide/catalogs_budgets.html#budgets-view<br><br>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-budgets-budget.html",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 433755,
          "date": "Mon 01 Nov 2021 23:19",
          "username": "blackgamer",
          "content": "https://docs.aws.amazon.com/servicecatalog/latest/adminguide/catalogs_budgets.html#budgets-view<br><br>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-budgets-budget.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413393,
          "date": "Wed 27 Oct 2021 15:50",
          "username": "WhyIronMan",
          "content": "Changing to A,D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 356915,
          "date": "Sun 24 Oct 2021 03:50",
          "username": "Waiweng",
          "content": "it's A&D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 344099,
          "date": "Fri 22 Oct 2021 06:01",
          "username": "Amitv2706",
          "content": "Option E's language is not clear. It seems they want to create an alert manually when limit cross.<br><br>Any ways CF option is better in terms of centrally managing this requirement through script for each account.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 321724,
          "date": "Wed 20 Oct 2021 17:11",
          "username": "alisyech",
          "content": "i think A & D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 294160,
          "date": "Sat 16 Oct 2021 22:19",
          "username": "Kian1",
          "content": "going with AD",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 284567,
          "date": "Sat 16 Oct 2021 15:45",
          "username": "Ebi",
          "content": "AD is answer",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 256474,
          "date": "Thu 07 Oct 2021 05:20",
          "username": "Bulti",
          "content": "A &D are the combination of steps required to meet the requirements",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 245690,
          "date": "Sat 02 Oct 2021 20:32",
          "username": "rscloudelf78",
          "content": "A,D<br>D- Create Budget in AWS Budget associate it with AWS service catalog product. <br>https://docs.aws.amazon.com/servicecatalog/latest/adminguide/catalogs_budgets.html+1 for the link.",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 274250,
          "date": "Fri 15 Oct 2021 04:28",
          "username": "elf78",
          "content": "+1 for the link.",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#658",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is migrating its on-premises systems to AWS. The user environment consists of the following systems:<br>✑ Windows and Linux virtual machines running on VMware.<br>Physical servers running Red Hat Enterprise Linux.<br><img src=\"https://www.examtopics.com/https://examtopics.com/assets/media/exam-media/04241/0043300002.png\" class=\"in-exam-image\"><br>The company wants to be able to perform the following steps before migrating to AWS:<br>✑ Identify dependencies between on-premises systems.<br>✑ Group systems together into applications to build migration plans.<br>✑ Review performance data using Amazon Athena to ensure that Amazon EC2 instances are right-sized.<br>How can these requirements be met?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: D</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#658",
          "answers": [
            {
              "choice": "<p>A. Populate the AWS Application Discovery Service import template with information from an on-premises configuration management database (CMDB). Upload the completed import template to Amazon S3, then import the data into Application Discovery Service.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Install the AWS Application Discovery Service Discovery Agent on each of the on-premises systems. Allow the Discovery Agent to collect data for a period of time.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Install the AWS Application Discovery Service Discovery Connector on each of the on-premises systems and in VMware vCenter. Allow the Discovery Connector to collect data for one week.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Install the AWS Application Discovery Service Discovery Agent on the physical on-premises servers. Install the AWS Application Discovery Service Discovery Connector in VMware vCenter. Allow the Discovery Agent to collect data for a period of time.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 591824,
          "date": "Mon 25 Apr 2022 18:07",
          "username": "snakecharmer2",
          "content": "The service discovery agentless connector can oly work with VMware, you still need the agent for the physicall server.<br>\\\"AWS Application Discovery Service supports agent-based and agentless modes of operation. With the agentless discovery, VMware customers collect VM configuration and performance profiles without deploying the AWS Application Discovery Agent on each host, which accelerates data collection. Customers in a non-VMware environment or that need additional information, like network dependencies and information about running processes, may install the Application Discovery Agent on servers and virtual machines (VMs) to collect data\\\" (taken from the Application Discovery FAQ)",
          "upvote_count": "6",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 595028,
          "date": "Sat 30 Apr 2022 15:17",
          "username": "pankajrawat",
          "content": "D is the correct ans for me",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 716347,
          "date": "Sat 12 Nov 2022 00:05",
          "username": "shyamexamprep",
          "content": "The same questions is appeared in neal's and dojo practice exam set.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 701457,
          "date": "Sat 22 Oct 2022 12:02",
          "username": "wassb",
          "content": "I think it's B since we need the agent to evaluate dependencies between on premise system.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        }
      ]
    },
    {
      "question_id": "#659",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company hosts a web application on AWS in the us-east-1 Region. The application servers are distributed across three Availability Zones behind an Application<br>Load Balancer. The database is hosted in MySQL database on an Amazon EC2 instance. A solutions architect needs to design a cross-Region data recovery solution using AWS services with an RTO of less than 5 minutes and an RPO of less than 1 minute. The solutions architect is deploying application servers in us- west-2, and has configured Amazon Route 53 health checks and DNS failover to us-west-2.<br>Which additional step should the solutions architect take?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#659",
          "answers": [
            {
              "choice": "<p>A. Migrate the database to an Amazon RDS for MySQL instance with a cross-Region read replica in us-west-2.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Migrate the database to an Amazon Aurora global database with the primary in us-east-1 and the secondary in us-west-2.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Migrate the database to an Amazon RDS for MySQL instance with a Multi-AZ deployment.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a MySQL standby database on an Amazon EC2 instance in us-west-2.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 213646,
          "date": "Mon 20 Sep 2021 11:59",
          "username": "liono",
          "content": "B<br>https://aws.amazon.com/rds/aurora/global-database/",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 284501,
          "date": "Mon 18 Oct 2021 02:06",
          "username": "Ebi",
          "content": "B is my choice",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 502979,
          "date": "Thu 16 Dec 2021 15:26",
          "username": "AkaAka4pixepeTokyoboyAkaAka4",
          "content": "Why not C though? :/Because Multi-AZ provides reliability w.r.t Availability Zone (AZ) where as question mentions reliability w.r.t Regions (AWS regions)I think Not C becuse the application is deployed in two AZ. Multi-AZ RDS works in primary-stanby instance fashion. There will not be efficient for the application as it is deployed in 2 AZ.Thank you @pixepe and @Tokyoboy!",
          "upvote_count": "1331",
          "selected_answers": ""
        },
        {
          "id": 652593,
          "date": "Sat 27 Aug 2022 16:02",
          "username": "pixepe",
          "content": "Because Multi-AZ provides reliability w.r.t Availability Zone (AZ) where as question mentions reliability w.r.t Regions (AWS regions)",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 519523,
          "date": "Sat 08 Jan 2022 13:58",
          "username": "TokyoboyAkaAka4",
          "content": "I think Not C becuse the application is deployed in two AZ. Multi-AZ RDS works in primary-stanby instance fashion. There will not be efficient for the application as it is deployed in 2 AZ.Thank you @pixepe and @Tokyoboy!",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 714574,
          "date": "Wed 09 Nov 2022 13:55",
          "username": "AkaAka4",
          "content": "Thank you @pixepe and @Tokyoboy!",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492051,
          "date": "Thu 02 Dec 2021 01:39",
          "username": "AzureDP900",
          "content": "B <br>Amazon Aurora Global Database is designed for globally distributed applications, allowing a single Amazon Aurora<br>database to span multiple AWS regions. It replicates your data with no impact on database performance, enables fast<br>local reads with low latency in each region, and provides disaster recovery from region-wide outages",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 445612,
          "date": "Fri 05 Nov 2021 16:33",
          "username": "andylogan",
          "content": "It's B -RTO is 1 mins, and RPO is 1 second.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436394,
          "date": "Fri 05 Nov 2021 11:01",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 421631,
          "date": "Fri 05 Nov 2021 05:31",
          "username": "CloudFan",
          "content": "Aurora is must for RTO of 1 min.here RTO is 5 mins. you can easily promote a RDS read replica in 5 mins. RPO of 1 min is met by both. Why not A ?",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 413400,
          "date": "Tue 02 Nov 2021 11:03",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 356927,
          "date": "Fri 29 Oct 2021 02:56",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 321726,
          "date": "Wed 27 Oct 2021 19:18",
          "username": "alisyech",
          "content": "should be B, https://aws.amazon.com/rds/aurora/global-database/",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 294167,
          "date": "Sun 24 Oct 2021 20:18",
          "username": "Kian1",
          "content": "going with B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 262270,
          "date": "Thu 14 Oct 2021 11:02",
          "username": "MichaelHuang01037",
          "content": "Is A an option? For B, RTO is 1 mins, and RPO is 1 second.Unlike an Amazon RDS Multi-AZ configuration, failover to a Read Replica is not an automated process, I don't think A is an option.",
          "upvote_count": "16",
          "selected_answers": ""
        },
        {
          "id": 271215,
          "date": "Fri 15 Oct 2021 18:26",
          "username": "01037",
          "content": "Unlike an Amazon RDS Multi-AZ configuration, failover to a Read Replica is not an automated process, I don't think A is an option.",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 256644,
          "date": "Wed 13 Oct 2021 07:57",
          "username": "Bulti",
          "content": "Answer is B. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 256328,
          "date": "Tue 12 Oct 2021 12:14",
          "username": "petebear55",
          "content": "Could also be A ...",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 241217,
          "date": "Fri 01 Oct 2021 14:24",
          "username": "T14102020",
          "content": "Its only Aurora for RTO of 1 min. Answer is B. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 233252,
          "date": "Sun 26 Sep 2021 13:43",
          "username": "jackdryan",
          "content": "I'll go with B",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 219538,
          "date": "Sat 25 Sep 2021 16:04",
          "username": "gookseangKelvin1477",
          "content": "B for sureAgree esp with RTO of 1 min",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 225368,
          "date": "Sat 25 Sep 2021 18:41",
          "username": "Kelvin1477",
          "content": "Agree esp with RTO of 1 min",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#660",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company wants to migrate its on-premises data center to the AWS Cloud. This includes thousands of virtualized Linux and Microsoft Windows servers, SAN storage, Java and PHP applications with MYSQL, and Oracle databases. There are many dependent services hosted either in the same data center or externally.<br>The technical documentation is incomplete and outdated. A solutions architect needs to understand the current environment and estimate the cloud resource costs after the migration.<br>Which tools or services should solutions architect use to plan the cloud migration? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: ADF</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#660",
          "answers": [
            {
              "choice": "<p>A. AWS Application Discovery Service<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. AWS SMS<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. AWS x-Ray<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. AWS Cloud Adoption Readiness Tool (CART)<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Amazon Inspector<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>F. AWS Migration Hub<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 215818,
          "date": "Mon 27 Sep 2021 01:33",
          "username": "keossmartassX",
          "content": "ADF, as for planningF is for visibility/ current status during migration. --> \\\"AWS Migration Hub provides a single place to monitor migrations in any AWS region where your migration tools are available. There is no additional charge\\\"",
          "upvote_count": "124",
          "selected_answers": ""
        },
        {
          "id": 217581,
          "date": "Mon 27 Sep 2021 11:31",
          "username": "smartassX",
          "content": "F is for visibility/ current status during migration. --> \\\"AWS Migration Hub provides a single place to monitor migrations in any AWS region where your migration tools are available. There is no additional charge\\\"",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 328321,
          "date": "Thu 21 Oct 2021 22:13",
          "username": "ExtHo",
          "content": "ADF<br>- Use AWS Application Discovery Service to gather information about the running virtual machines and running applications inside the servers.<br><br>- Use the AWS Cloud Adoption Readiness Tool (CART) to generate a migration assessment report to identify gaps in organizational skills and processes.<br><br>- Use AWS Migration Hub to discover and track the status of the application migration across AWS and partner solutions.",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 636326,
          "date": "Mon 25 Jul 2022 04:24",
          "username": "hilft",
          "content": "ADF. <br>Directly from Job Bonso's exam",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 626423,
          "date": "Sun 03 Jul 2022 07:26",
          "username": "aandc",
          "content": "keyword:planning",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: ADF"
        },
        {
          "id": 586283,
          "date": "Fri 15 Apr 2022 12:44",
          "username": "tartarus23",
          "content": "A.  AWS Application Discovery Service<br>D.  AWS Cloud Adoption Readness Tool (CART)<br>F.  AWS Migration Hub<br><br>These AWS tools and questionnaires are very helpful for assessment and planning before doing the migration activity.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ADF"
        },
        {
          "id": 522059,
          "date": "Wed 12 Jan 2022 11:58",
          "username": "pititcu667",
          "content": "B is more for implementation the question talk about planning.",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: ADF"
        },
        {
          "id": 505702,
          "date": "Mon 20 Dec 2021 23:15",
          "username": "edgarrodriguez2303",
          "content": "The best option",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ADF"
        },
        {
          "id": 492052,
          "date": "Thu 02 Dec 2021 01:40",
          "username": "AzureDP900",
          "content": "A,D, F iscorrect",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 486794,
          "date": "Thu 25 Nov 2021 17:22",
          "username": "pcops",
          "content": "A D and F",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 445645,
          "date": "Tue 02 Nov 2021 07:03",
          "username": "andylogan",
          "content": "It's A D F - refer ExtHo",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 437083,
          "date": "Sat 30 Oct 2021 12:46",
          "username": "Kopa",
          "content": "Also for A,D,F",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435243,
          "date": "Fri 29 Oct 2021 22:51",
          "username": "tgv",
          "content": "AAA DDD FFF<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 433759,
          "date": "Fri 29 Oct 2021 06:43",
          "username": "blackgamer",
          "content": "A , D and F",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413403,
          "date": "Thu 28 Oct 2021 21:08",
          "username": "WhyIronMan",
          "content": "I'll go with A,D,F",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 356929,
          "date": "Fri 22 Oct 2021 15:55",
          "username": "Waiweng",
          "content": "it's A,D,F",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 321728,
          "date": "Wed 20 Oct 2021 19:23",
          "username": "alisyech",
          "content": "im going with A, D & F",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 294168,
          "date": "Mon 18 Oct 2021 18:53",
          "username": "Kian1",
          "content": "going with ADF",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#661",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company decided to purchase Amazon EC2 Reserved Instances. A solutions architect is tasked with implementing a solution where only the master account in<br>AWS Organizations is able to purchase the Reserved Instances. Current and future member accounts should be blocked from purchasing Reserved Instances.<br>Which solution will meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: A</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#661",
          "answers": [
            {
              "choice": "<p>A. Create an SCP with the Deny effect on the ec2:PurchaseReservedInstancesOffering action. Attach the SCP to the root of the organization.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create a new organizational unit (OU) Move all current member accounts to the new OU. Create an SCP with the Deny effect on the ec2:PurchaseReservedInstancesOffering action. Attach the SCP to the new OU.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create an AWS Config rule event that triggers automation that will terminate any Reserved Instances launched by member accounts.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create two new organizational units (OUs): OU1 and OU2. Move all member accounts to OU2 and the master account to OU1. Create an SCP with the Allow effect on the ec2:PurchaseReservedInstancesOffering action. Attach the SCP to OU1.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 218535,
          "date": "Mon 27 Sep 2021 04:11",
          "username": "XRiddlerXblackgamerblackgamerstudent2020cpdstudent22",
          "content": "Answer is A<br>B is INCORRECT because this doesn't satisfy the requirement for future accounts possibility inOTHER OU's that might be created.The SCP in this answer would only affect the OU the SCP is applied too.<br>C is INCORRECT because this allows accounts to continue to purchase RIs and the requirement is to BLOCK from purchasing<br>D is INCORRECT because the \\\"master account (a.k.a management account) is the root account of the org and should not and can not be in an OU.See the following diagram here (https://docs.aws.amazon.com/organizations/latest/userguide/orgs_getting-started_concepts.html)<br><br>A is CORRECT because applying the explicit deny on the API and attaching it to the root org allows for current and future account in ANY OU to not be able to purchase RI's.Answer is D.  It is incorrect that \\\"master account can not be in an OU\\\". It is tested and it is allowed. A is incorrect because it will block everyone from purchasing reserved instances including the management account if you attach to root.Sorry , after having more research, A is correct because \\\"SCPs don't affect users or roles in the management account. They affect only the member accounts in your organization.\\\"Just a correction, you can move a management account into an OU, I just tested it.I was about to go with B but after reading above, A makes sense to ensure any future accounts to also not buy RI's. With A.  member accounts cannot purchase RI but, master account can still purchase RI, \\\"SCPs cannot restrict the Master account of the Organization. This is a primary reason why it is best practice not to use the Organization Master account for anything other than Organization activities.\\\"A is correct.<br>SCPs don't affect users or roles in the management account. They affect only the member accounts in your organization. <br>https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html",
          "upvote_count": "2727262",
          "selected_answers": ""
        },
        {
          "id": 433849,
          "date": "Wed 03 Nov 2021 02:37",
          "username": "blackgamerblackgamer",
          "content": "Answer is D.  It is incorrect that \\\"master account can not be in an OU\\\". It is tested and it is allowed. A is incorrect because it will block everyone from purchasing reserved instances including the management account if you attach to root.Sorry , after having more research, A is correct because \\\"SCPs don't affect users or roles in the management account. They affect only the member accounts in your organization.\\\"",
          "upvote_count": "27",
          "selected_answers": ""
        },
        {
          "id": 433851,
          "date": "Fri 05 Nov 2021 17:38",
          "username": "blackgamer",
          "content": "Sorry , after having more research, A is correct because \\\"SCPs don't affect users or roles in the management account. They affect only the member accounts in your organization.\\\"",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 411072,
          "date": "Sat 30 Oct 2021 15:22",
          "username": "student2020",
          "content": "Just a correction, you can move a management account into an OU, I just tested it.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 219316,
          "date": "Fri 01 Oct 2021 02:11",
          "username": "cpd",
          "content": "I was about to go with B but after reading above, A makes sense to ensure any future accounts to also not buy RI's. With A.  member accounts cannot purchase RI but, master account can still purchase RI, \\\"SCPs cannot restrict the Master account of the Organization. This is a primary reason why it is best practice not to use the Organization Master account for anything other than Organization activities.\\\"",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 439399,
          "date": "Sat 06 Nov 2021 08:57",
          "username": "student22",
          "content": "A is correct.<br>SCPs don't affect users or roles in the management account. They affect only the member accounts in your organization. <br>https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 241236,
          "date": "Tue 05 Oct 2021 13:26",
          "username": "T1410202001037",
          "content": "https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html<br>SCPs don't affect users or roles in the management (master) account. They affect only the member accounts in your organization.<br><br>So correct answer is A. Good point.",
          "upvote_count": "161",
          "selected_answers": ""
        },
        {
          "id": 271308,
          "date": "Mon 11 Oct 2021 17:13",
          "username": "01037",
          "content": "Good point.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496030,
          "date": "Tue 07 Dec 2021 14:10",
          "username": "cldy",
          "content": "A.  Create an SCP with the Deny effect on the ec2:PurchaseReservedInstancesOffering action. Attach the SCP to the root of the organization.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492054,
          "date": "Thu 02 Dec 2021 01:42",
          "username": "AzureDP900",
          "content": "A is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 483126,
          "date": "Sun 21 Nov 2021 09:54",
          "username": "acloudguru",
          "content": "https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 445654,
          "date": "Sun 07 Nov 2021 09:38",
          "username": "andylogan",
          "content": "It's A - The master account of the organization is not affected by any SCPs that are attached either to it or to any root or OU the master account might be in.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435244,
          "date": "Sat 06 Nov 2021 01:43",
          "username": "tgv",
          "content": "AAA<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 430914,
          "date": "Mon 01 Nov 2021 01:00",
          "username": "denccc",
          "content": "go with A",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 424793,
          "date": "Sun 31 Oct 2021 18:09",
          "username": "tekkart",
          "content": "The answer should be D<br>- Rights work as intersection between Root, OU SCP and IAM Policy<br>- Explicit Deny > Explicit Allow > Implicit Deny > Implicit Allow<br><br>A : Explicit Deny. Blocks everybody, none can purchase instances<br>B : Same<br>C : As XRiddlerX states, ruled out<br>D : Explicit Allow in OU1 SCP for master account,and Implicit Deny in OU2 SCP - as long as no Explicit Allow on OU2 SCP, works fine.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413405,
          "date": "Sun 31 Oct 2021 05:13",
          "username": "WhyIronMan",
          "content": "I'll go with A",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 407368,
          "date": "Thu 28 Oct 2021 13:37",
          "username": "Akhil254",
          "content": "A Correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 398241,
          "date": "Thu 28 Oct 2021 01:24",
          "username": "Pb55",
          "content": "If you assign SCP to root, how does the master account buy reserved instances? It will be blocked as well. Has to be B. ",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 395760,
          "date": "Mon 25 Oct 2021 20:25",
          "username": "OAS1",
          "content": "SCPs affect only member accounts in the organization hence applying it on root will not impact master account. Answer is 𝗔.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 385529,
          "date": "Fri 22 Oct 2021 03:27",
          "username": "hk436",
          "content": "I don't think it's A!<br>AWS strongly recommends that you don't attach SCPs to the root of your organization without thoroughly testing the impact that the policy has on accounts. Instead, create an OU that you can move your accounts into one at a time, or at least in small numbers, to ensure that you don't inadvertently lock users out of key services.<br><br>https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 356947,
          "date": "Wed 20 Oct 2021 14:43",
          "username": "Waiweng",
          "content": "it's A",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 354319,
          "date": "Wed 20 Oct 2021 08:53",
          "username": "tvs",
          "content": "AWS strongly recommends that you don't attach SCPs to the root of your organization without thoroughly testing the impact that the policy has on accounts. Instead, create an OU that you can move your accounts into one at a time, or at least in small numbers, to ensure that you don't inadvertently lock users out of key services. https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html<br>However we dont know how many OU currently exist whether all current belongs to one OU , or what are existingSCP applied old OU's.So I will go with A",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 344681,
          "date": "Wed 20 Oct 2021 03:02",
          "username": "victornj",
          "content": "Putting deny on root account does not make sense, it means you have to add explicit allow to other services. Therefore A cannot be the answer. C& D are incorrect .. therfore it seems B is the right answer",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#662",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is using multiple AWS accounts. The DNS records are stored in a private hosted zone for Amazon Route 53 in Account A.  The company's applications and databases are running in Account B. <br>A solutions architect will deploy a two-tier application in a new VPC.  To simplify the configuration, the db.example.com CNAME record set for the Amazon RDS endpoint was created in a private hosted zone for Amazon Route 53.<br>During deployment, the application failed to start. Troubleshooting revealed that db.example.com is not resolvable on the Amazon EC2 instance. The solutions architect confirmed that the record set was created correctly in Route 53.<br>Which combination of steps should the solutions architect take to resolve this issue? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: CE</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#662",
          "answers": [
            {
              "choice": "<p>A. Deploy the database on a separate EC2 instance in the new VPC.  Create a record set for the instance's private IP in the private hosted zone.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use SSH to connect to the application tier EC2 instance. Add an RDS endpoint IP address to the /etc/resolv.conf file.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create an authorization to associate the private hosted zone in Account A with the new VPC in Account B. <br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a private hosted zone for the example com domain in Account B.  Configure Route 53 replication between AWS accounts.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>E. Associate a new VPC in Account B with a hosted zone in Account A.  Delete the association authorization in Account A. <br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 213070,
          "date": "Mon 20 Sep 2021 21:57",
          "username": "ali98student22cloudgc",
          "content": "C & E <br>https://aws.amazon.com/premiumsupport/knowledge-center/private-hosted-zone-different-account/C,E<br>Authorize --> Associate --> Remove Authorization<br>As in the ali98's link.Perfect!",
          "upvote_count": "3734",
          "selected_answers": ""
        },
        {
          "id": 439402,
          "date": "Thu 04 Nov 2021 11:35",
          "username": "student22",
          "content": "C,E<br>Authorize --> Associate --> Remove Authorization<br>As in the ali98's link.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 233772,
          "date": "Sun 03 Oct 2021 01:43",
          "username": "cloudgc",
          "content": "Perfect!",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 569415,
          "date": "Thu 17 Mar 2022 02:33",
          "username": "RVD",
          "content": "Ans: C & E",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: CE"
        },
        {
          "id": 492057,
          "date": "Thu 02 Dec 2021 01:43",
          "username": "AzureDP900",
          "content": "C, E is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 445663,
          "date": "Thu 04 Nov 2021 20:10",
          "username": "andylogan",
          "content": "It's C E <br>A Authorize B --> B Associate A --> A Remove Authorization",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436397,
          "date": "Wed 03 Nov 2021 00:25",
          "username": "tgv",
          "content": "CCC EEE<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433854,
          "date": "Mon 01 Nov 2021 02:56",
          "username": "blackgamer",
          "content": "C & E for me.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413408,
          "date": "Wed 20 Oct 2021 05:55",
          "username": "WhyIronMan",
          "content": "I'll go with C,E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 382750,
          "date": "Mon 18 Oct 2021 06:54",
          "username": "ibrahimsow",
          "content": "For sure, the correct answers are C & E.  https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zone-private-associate-vpcs-different-accounts.html",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 356956,
          "date": "Sun 17 Oct 2021 15:44",
          "username": "Waiweng",
          "content": "it's C,E",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 294180,
          "date": "Sat 16 Oct 2021 20:08",
          "username": "Kian1",
          "content": "going for CE",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 284534,
          "date": "Sat 16 Oct 2021 02:22",
          "username": "Ebi",
          "content": "CE for sure",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 263574,
          "date": "Thu 14 Oct 2021 02:00",
          "username": "Bulti",
          "content": "C&E is the right answer",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 245831,
          "date": "Sat 09 Oct 2021 21:04",
          "username": "rscloud",
          "content": "CE for sure",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 241239,
          "date": "Fri 08 Oct 2021 00:59",
          "username": "T14102020",
          "content": "For sure CE",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 233270,
          "date": "Sat 02 Oct 2021 23:06",
          "username": "jackdryan",
          "content": "I'll go with C,E<br>Thanks to ali98 for providing the right on link",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#663",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A solutions architect needs to advise a company on how to migrate its on-premises data processing application to the AWS Cloud. Currently, users upload input files through a web portal. The web server then stores the uploaded files on NAS and messages the processing server over a message queue. Each media file can take up to 1 hour to process. The company has determined that the number of media files awaiting processing is significantly higher during business hours, with the number of files rapidly declining after business hours.<br>What is the MOST cost-effective migration recommendation?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: D</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#663",
          "answers": [
            {
              "choice": "<p>A. Create a queue using Amazon SQS. Configure the existing web server to publish to the new queue. When there are messages in the queue, invoke an AWS Lambda function to pull requests from the queue and process the files. Store the processed files in an Amazon S3 bucket.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create a queue using Amazon MQ. Configure the existing web server to publish to the new queue. When there are messages in the queue, create a new Amazon EC2 instance to pull requests from the queue and process the files. Store the processed files in Amazon EFS. Shut down the EC2 instance after the task is complete.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create a queue using Amazon MQ. Configure the existing web server to publish to the new queue. When there are messages in the queue, invoke an AWS Lambda function to pull requests from the queue and process the files. Store the processed files in Amazon EFS.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a queue using Amazon SQS. Configure the existing web server to publish to the new queue. Use Amazon EC2 instances in an EC2 Auto Seating group to pull requests from the queue and process the files. Scale the EC2 instances based on the SQS queue length. Store the processed files in an Amazon S3 bucket.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 214505,
          "date": "Mon 20 Sep 2021 06:08",
          "username": "liono",
          "content": "As the length of processing the files take 1 hour, Lambda seems to be out of question, then we are left with EC2 option, D seems to be correct as we are auto-scaling EC2",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 284536,
          "date": "Sat 23 Oct 2021 05:08",
          "username": "Ebi",
          "content": "Answer is D",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 637711,
          "date": "Wed 27 Jul 2022 02:59",
          "username": "hilft",
          "content": "keyword here is sqs length + asg",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 607131,
          "date": "Wed 25 May 2022 11:02",
          "username": "bobsmith2000",
          "content": "Right by the book",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 568233,
          "date": "Tue 15 Mar 2022 10:08",
          "username": "tyrk",
          "content": "DDDDDDDDDDDD",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 542637,
          "date": "Mon 07 Feb 2022 20:40",
          "username": "jj22222",
          "content": "D looks right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 532069,
          "date": "Tue 25 Jan 2022 12:29",
          "username": "kaush4u",
          "content": "https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-1/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 525998,
          "date": "Mon 17 Jan 2022 19:32",
          "username": "lulz111",
          "content": "D is correct even though there is a typo (auto seating group) its obvious when you look at the other answers. The Lambda execution limit is 15 minutes which instantly rules out two. The remaining answer that suggests creating a new EC2 instance when something goes in the queue is not a good solution (slow).",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 513356,
          "date": "Thu 30 Dec 2021 13:39",
          "username": "cldy",
          "content": "D is correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 499315,
          "date": "Sat 11 Dec 2021 11:15",
          "username": "cldy",
          "content": "D.  Create a queue using Amazon SQS. Configure the existing web server to publish to the new queue. Use Amazon EC2 instances in an EC2 Auto Seating group to pull requests from the queue and process the files. Scale the EC2 instances based on the SQS queue length. Store the processed files in an Amazon S3 bucket.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492317,
          "date": "Thu 02 Dec 2021 10:15",
          "username": "KiraguJohn",
          "content": "I would have chosen Lambda until i saw the processing time. Therefore i will also go with D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492124,
          "date": "Thu 02 Dec 2021 04:59",
          "username": "AzureDP900",
          "content": "D is correct, initially i thought A but it is not scalable.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 490395,
          "date": "Tue 30 Nov 2021 04:43",
          "username": "acloudguru",
          "content": "this is really a easy one, hope I can have it as complex one in my exam",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 445671,
          "date": "Sun 07 Nov 2021 12:42",
          "username": "andylogan",
          "content": "It's D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436398,
          "date": "Fri 05 Nov 2021 19:05",
          "username": "tgv",
          "content": "DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433286,
          "date": "Mon 01 Nov 2021 04:55",
          "username": "Suresh108",
          "content": "going for DDDDD<br><br>eliminate A & C for lambda (15 mins timeout)<br>eliminate B - solution is incomplete, it creates EC2 processes and shutdown, what triggers up new EC2??<br><br>D - is correct",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 413411,
          "date": "Thu 28 Oct 2021 11:44",
          "username": "WhyIronMan",
          "content": "MOST cost-effective",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#664",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has a media catalog with metadata for each item in the catalog. Different types of metadata are extracted from the media items by an application running on AWS Lambda. Metadata is extracted according to a number of rules with the output stored in an Amazon ElastiCache for Redis cluster. The extraction process is done in batches and takes around 40 minutes to complete.<br>The update process is triggered manually whenever the metadata extraction rules change.<br>The company wants to reduce the amount of time it takes to extract metadata from its media catalog. To achieve this, a solutions architect has split the single metadata extraction Lambda function into a Lambda function for each type of metadata.<br>Which additional steps should the solutions architect take to meet the requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: A</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#664",
          "answers": [
            {
              "choice": "<p>A. Create an AWS Step Functions workflow to run the Lambda functions in parallel. Create another Step Functions workflow that retrieves a list of media items and executes a metadata extraction workflow for each one.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an AWS Batch compute environment for each Lambda function. Configure an AWS Batch job queue for the compute environment. Create a Lambda function to retrieve a list of media items and write each item to the job queue.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create an AWS Step Functions workflow to run the Lambda functions in parallel. Create a Lambda function to retrieve a list of media items and write each item to an Amazon SQS queue. Configure the SQS queue as an input to the Step Functions workflow.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a Lambda function to retrieve a list of media items and write each item to an Amazon SQS queue. Subscribe the metadata extraction Lambda functions to the SQS queue with a large batch size.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 226206,
          "date": "Sun 26 Sep 2021 19:27",
          "username": "avlanddmscounteraalexmena1981MrCartergbrnqMrCarter",
          "content": "A. <br><br>B is nearly nonsensical with how it uses Batch.<br>C wouldn't work since Step Functions operate with JSON inputs/outputs. SQS wouldn't work as an input quite like that.<br>D wouldn't work because the metadata extraction Lambda functions are non-identical workers, so one function will pull a message containing the media item and process it, but then the other functions won't see that item and process their part of the metadata for it. For something like that to work, you'd actually want a separate SQS queue for each type of metadata function, and use an SNS topic to publish each item to each queue.https://docs.aws.amazon.com/step-functions/latest/dg/concepts-invoke-sfn.html<br>Points to AYou are incorrect,check https://www.youtube.com/watch?v=tPYa1r_cZ2E , Ans. CAns AAAAAAAAThat video shows how to trigger SQS from SF. . so it’s not relevant. Ans ANo, you are incorrect, SQS cannot be the input of an AWS Step Functions workflow.",
          "upvote_count": "1811134",
          "selected_answers": ""
        },
        {
          "id": 699993,
          "date": "Thu 20 Oct 2022 15:54",
          "username": "dmscountera",
          "content": "https://docs.aws.amazon.com/step-functions/latest/dg/concepts-invoke-sfn.html<br>Points to A",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 235281,
          "date": "Tue 28 Sep 2021 09:30",
          "username": "alexmena1981MrCartergbrnqMrCarter",
          "content": "You are incorrect,check https://www.youtube.com/watch?v=tPYa1r_cZ2E , Ans. CAns AAAAAAAAThat video shows how to trigger SQS from SF. . so it’s not relevant. Ans ANo, you are incorrect, SQS cannot be the input of an AWS Step Functions workflow.",
          "upvote_count": "1134",
          "selected_answers": ""
        },
        {
          "id": 396035,
          "date": "Tue 19 Oct 2021 22:27",
          "username": "MrCarter",
          "content": "Ans AAAAAAAA",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 236584,
          "date": "Wed 29 Sep 2021 06:06",
          "username": "gbrnq",
          "content": "That video shows how to trigger SQS from SF. . so it’s not relevant. Ans A",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 396036,
          "date": "Wed 20 Oct 2021 00:48",
          "username": "MrCarter",
          "content": "No, you are incorrect, SQS cannot be the input of an AWS Step Functions workflow.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 214527,
          "date": "Sun 19 Sep 2021 19:43",
          "username": "lionokeos",
          "content": "C seems to be correct answerSQS queue cannot trigger Step function",
          "upvote_count": "129",
          "selected_answers": ""
        },
        {
          "id": 215907,
          "date": "Mon 20 Sep 2021 04:40",
          "username": "keos",
          "content": "SQS queue cannot trigger Step function",
          "upvote_count": "9",
          "selected_answers": ""
        },
        {
          "id": 721751,
          "date": "Sat 19 Nov 2022 04:34",
          "username": "TonySu",
          "content": "I go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 689117,
          "date": "Sat 08 Oct 2022 09:45",
          "username": "caveman712",
          "content": "Workflow task can trigger other workflows: https://docs.aws.amazon.com/step-functions/latest/dg/concepts-nested-workflows.html",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 627739,
          "date": "Wed 06 Jul 2022 08:02",
          "username": "Enigmaaaaaa",
          "content": "Only A and C are valid butAnswer is A since SQS cannot trigger SFW ... <br>https://docs.aws.amazon.com/step-functions/latest/dg/concepts-invoke-sfn.html<br>Only lambda and another SF can do it (as described in A)",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 562496,
          "date": "Mon 07 Mar 2022 10:14",
          "username": "Dohecadi",
          "content": "C is wrong. SQS has to start a Lambda funtion first, which in turn will start Step Function.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 517907,
          "date": "Thu 06 Jan 2022 02:59",
          "username": "frankzeng",
          "content": "C.  when there are new items in the media catalog, a lambda function retrieve the list of media items and write the item information into SQS. The step function workflow read the item from SQS and run the LAMBDA functions in parallel.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 495206,
          "date": "Mon 06 Dec 2021 15:37",
          "username": "wemwassb",
          "content": "Ans C<br>https://www.youtube.com/watch?v=tPYa1r_cZ2Ethis step function does broadcast to SQS ... Useless LINK",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 694156,
          "date": "Thu 13 Oct 2022 19:30",
          "username": "wassb",
          "content": "this step function does broadcast to SQS ... Useless LINK",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492129,
          "date": "Thu 02 Dec 2021 05:08",
          "username": "AzureDP900",
          "content": "C <br><br>The best solution presented is to use a combination of AWS Step Functions and Amazon SQS. This results in each<br>Lambda function being able to run in parallel and use a queue for buffering the jobs.<br>CORRECT: “Create an AWS Step Functions workflow to run the Lambda functions in parallel. Create a Lambda<br>function to retrieve a list of files and write each item to an Amazon SQS queue. Configure the SQS queue as an input to the Step Functions workflow” is the correct answer",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 492127,
          "date": "Thu 02 Dec 2021 05:05",
          "username": "AzureDP900",
          "content": "c is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488632,
          "date": "Sun 28 Nov 2021 02:09",
          "username": "tiana528",
          "content": "D.  It is simple, straightforward. Stepfunctions is not needed here. lambda triggered by SQS can run in parallel pretty well.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 483008,
          "date": "Sun 21 Nov 2021 05:33",
          "username": "acloudguru",
          "content": "SQS needs lambda to trigger step function, can not do it directly. So C is not right.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 458733,
          "date": "Tue 02 Nov 2021 22:13",
          "username": "StelSen",
          "content": "Option-C.  Taken from AWS Website. https://docs.aws.amazon.com/step-functions/latest/dg/sample-project-express-high-volume-sqs.html (We can process items from SQS).",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 445965,
          "date": "Tue 02 Nov 2021 12:11",
          "username": "andylogan",
          "content": "It's A - SQS queue is not an input to the Step Functions workflow",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 435250,
          "date": "Thu 28 Oct 2021 00:50",
          "username": "tgv",
          "content": "AAA<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 433863,
          "date": "Sun 24 Oct 2021 22:03",
          "username": "blackgamer",
          "content": "I will go with A. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 414561,
          "date": "Sun 24 Oct 2021 00:42",
          "username": "mericovkirrim",
          "content": "A - https://aws.amazon.com/blogs/compute/accelerating-workloads-using-parallelism-in-aws-step-functions/This is absolutely the right answer.The entire question is about reducing the overall time to extract media by splitting it into multiple parallel processes, which is exactly what this blog post describes.",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 463304,
          "date": "Sun 07 Nov 2021 09:48",
          "username": "kirrim",
          "content": "This is absolutely the right answer.The entire question is about reducing the overall time to extract media by splitting it into multiple parallel processes, which is exactly what this blog post describes.",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#665",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A utility company wants to collect usage data every 5 minutes from its smart meters to facilitate time-of-use metering. When a meter sends data to AWS, the data is sent to Amazon API Gateway, processed by an AWS Lambda function and stored in an Amazon DynamoDB table. During the pilot phase, the Lambda functions took from 3 to 5 seconds to complete.<br>As more smart meters are deployed, the Engineers notice the Lambda functions are taking from 1 to 2 minutes to complete. The functions are also increasing in duration as new types of metrics are collected from the devices. There are many ProvisionedThroughputExceededException errors while performing PUT operations on DynamoDB, and there are also many TooManyRequestsException errors from Lambda.<br>Which combination of changes will resolve these issues? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: AD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#665",
          "answers": [
            {
              "choice": "<p>A. Increase the write capacity units to the DynamoDB table.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Increase the memory available to the Lambda functions.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Increase the payload size from the smart meters to send more data.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Stream the data into an Amazon Kinesis data stream from API Gateway and process the data in batches.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Collect data in an Amazon SQS FIFO queue, which triggers a Lambda function to process each message.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 215911,
          "date": "Thu 23 Sep 2021 02:15",
          "username": "keostuananhngo",
          "content": "would go for ADI DONT THINK SO. THE QUESTION DOES NOT MENTION DATA SHOULD BE PROCESSED IN REAL-TIME.  <br>I AM GOING WITH AB. ",
          "upvote_count": "236",
          "selected_answers": ""
        },
        {
          "id": 398891,
          "date": "Fri 22 Oct 2021 10:35",
          "username": "tuananhngo",
          "content": "I DONT THINK SO. THE QUESTION DOES NOT MENTION DATA SHOULD BE PROCESSED IN REAL-TIME.  <br>I AM GOING WITH AB. ",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 256683,
          "date": "Mon 04 Oct 2021 16:47",
          "username": "Bulti",
          "content": "E is out as IoT core cannot use Amazon SQS FIFO as target. C is out as increasing the payload size would not necessarily result in reduced volume over a period of time. Between B and D, I would go with D as batching the data before sending to Lambda would result in reducing the concurrency which is the reason for TooManyRequestsException. A is correct because Lambda is writing to Dynamo DB and batching wouldn't help with the rate at which Lambda is writing data to DynamoDB which is the cause of ProvisionedThroughputExceededException. So need to increase the WCU in DynamoDB.  Correct answer is A and D. ",
          "upvote_count": "19",
          "selected_answers": ""
        },
        {
          "id": 653588,
          "date": "Mon 29 Aug 2022 20:07",
          "username": "gnic",
          "content": "AD<br>D - The question talk about \\\"tooManyRequest\\\". Kinesis can batch data",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: AD"
        },
        {
          "id": 553797,
          "date": "Tue 22 Feb 2022 16:54",
          "username": "johnnsmith",
          "content": "D is vague. Does it use the same Lambda function? If yes, it doesn't work. If you do a batch of 10, it will take 20 minutes to finish. If a new design with EC2 is allowed, D is correct. The question says \\\"modification\\\" which implies same Lambda function. Then B is correct. Then what is currently memory size? If it is already 10GB, B is wrong. Overall, it is a badly worded question.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 542325,
          "date": "Mon 07 Feb 2022 12:31",
          "username": "Ishu_awsguyjoancarles",
          "content": "I would go for A and B. <br>The error on DynamoDb is because of the resources constraint since the requests are too high.<br>A for increasing WCU<br><br>B is supported by https://aws.amazon.com/premiumsupport/knowledge-center/lambda-troubleshoot-throttling/<br>The blog quotes below.<br>Check for spikes in Duration metrics for your function<br><br>Concurrency depends on function duration. If your function code is taking too long to complete, then there might not be enough compute resources.<br><br>Try increasing the function's memory setting. Then, use AWS X-Ray and CloudWatch Logs to isolate the cause of duration increases<br><br>D should not be ideal because it changes the whole architecture and will induce more latency I believe.Basically AWS Lambda has a default safety throttle of 100 concurrent executions per account per region. Increasing the lambda size doesn't solve the root problem, so D seems to be a better option.",
          "upvote_count": "22",
          "selected_answers": ""
        },
        {
          "id": 671520,
          "date": "Sat 17 Sep 2022 14:48",
          "username": "joancarles",
          "content": "Basically AWS Lambda has a default safety throttle of 100 concurrent executions per account per region. Increasing the lambda size doesn't solve the root problem, so D seems to be a better option.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 497776,
          "date": "Thu 09 Dec 2021 15:00",
          "username": "cldy",
          "content": "A.  Increase the write capacity units to the DynamoDB table.<br>D.  Stream the data into an Amazon Kinesis data stream from API Gateway and process the data in batches.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 492135,
          "date": "Thu 02 Dec 2021 05:18",
          "username": "AzureDP900",
          "content": "A,D seems to be correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 448478,
          "date": "Sat 06 Nov 2021 17:35",
          "username": "Bigbearcn",
          "content": "AD.  <br>https://alienattack.workshop.aws/en/short-labs/kinesis/300-ingestion-to-dynamodb.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 445973,
          "date": "Fri 05 Nov 2021 03:10",
          "username": "andylogan",
          "content": "It's A D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 439407,
          "date": "Wed 03 Nov 2021 05:07",
          "username": "student22",
          "content": "B,D<br>A good explanation is in XRiddlerX's answer below.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 436405,
          "date": "Sun 31 Oct 2021 21:35",
          "username": "tgv",
          "content": "AAA DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433864,
          "date": "Fri 29 Oct 2021 17:14",
          "username": "blackgamer",
          "content": "It is A and D. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413417,
          "date": "Tue 26 Oct 2021 16:34",
          "username": "WhyIronMan",
          "content": "I'll go for A,D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 407373,
          "date": "Sun 24 Oct 2021 18:23",
          "username": "Akhil254",
          "content": "AD Correct",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 396038,
          "date": "Wed 20 Oct 2021 08:09",
          "username": "MrCarter",
          "content": "This is straight out of Jon Bonso's exam questions. Answers are A and D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 383658,
          "date": "Tue 19 Oct 2021 11:19",
          "username": "kpcertkirrim",
          "content": "Ans : A & B<br>There are 2 issues here. <br>Issue 1 - Lambda function started taking more time when the load increases. Fix : Increase Lambda CPU by increasing the memory.<br>Issue 2 - TooManyRequetsException from DynamoDB. Fix:Increate WCU of DynamoDB<br><br>Since this change has already passed the pilot phase and the issue is happening in the production workload, the simple fix should be considered.+1<br><br>To increase CPU for a Lambda function, oddly enough, you give it more memory: https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-2/<br>(This is the same kind of indirect performance increase by adjusting something seemingly unrelated like increasing an EBS disk's IOPS by increasing the disk size.)<br><br>The \\\"ProvisionedThroughputExceeded\\\" exception is in the SDK the Lambda function is using to write to DynamoDB. When DynamoDB can't keep up, it throws that error back to Lambda, and Lambda logs it.But it's indicating that you've run out of Write Capacity Units in DDB:<br><br>https://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/services/dynamodbv2/model/ProvisionedThroughputExceededException.html",
          "upvote_count": "91",
          "selected_answers": ""
        },
        {
          "id": 463307,
          "date": "Sun 07 Nov 2021 15:44",
          "username": "kirrim",
          "content": "+1<br><br>To increase CPU for a Lambda function, oddly enough, you give it more memory: https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-2/<br>(This is the same kind of indirect performance increase by adjusting something seemingly unrelated like increasing an EBS disk's IOPS by increasing the disk size.)<br><br>The \\\"ProvisionedThroughputExceeded\\\" exception is in the SDK the Lambda function is using to write to DynamoDB. When DynamoDB can't keep up, it throws that error back to Lambda, and Lambda logs it.But it's indicating that you've run out of Write Capacity Units in DDB:<br><br>https://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/services/dynamodbv2/model/ProvisionedThroughputExceededException.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 360296,
          "date": "Mon 18 Oct 2021 15:54",
          "username": "pradhyumnakpcert",
          "content": "AB may still be correct. I think the hint here is that the data collection is not real time instead every 5 minutes which is kind of queueing, so we would not really need an SQS or a KDS. So, by simply increasing the memory, lambda can process faster and since it is processing faster, an increase in the WCU should really fix the issue.I Agree",
          "upvote_count": "41",
          "selected_answers": ""
        },
        {
          "id": 383660,
          "date": "Tue 19 Oct 2021 17:06",
          "username": "kpcert",
          "content": "I Agree",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#666",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>An ecommerce company has an order processing application it wants to migrate to AWS. The application has inconsistent data volume patterns, but needs to be avail at all times. Orders must be processed as they occur and in the order that they are received.<br>Which set of steps should a solutions architect take to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#666",
          "answers": [
            {
              "choice": "<p>A. Use AWS Transfer for SFTP and upload orders as they occur. Use On-Demand Instances in multiple Availability Zones for processing.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use Amazon SNS with FIFO and send orders as they occur. Use a single large Reserved Instance for processing.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use Amazon SQS with FIFO and send orders as they occur. Use Reserved Instances in multiple Availability Zones for processing.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use Amazon SQS with FIFO and send orders as they occur. Use Spot Instances in multiple Availability Zones for processing.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 214533,
          "date": "Tue 21 Sep 2021 07:07",
          "username": "lionokirrim",
          "content": "C is correct, SQS with FIFO to process the orders as they come and reserved instances for availability at all timesAgree, C is the best answer given<br><br>Better approach might be to:<br>- start with On-Demand instances in an ASG<br>- set the ASG scaling metric to SQS FIFO queue depth<br>- monitor for steady-state minimum number of instances needed<br>- purchase RIs for minimum number of instances needed<br>- use On-Demand instances for additional bursting instances in the ASG above base",
          "upvote_count": "192",
          "selected_answers": ""
        },
        {
          "id": 463308,
          "date": "Wed 03 Nov 2021 12:23",
          "username": "kirrim",
          "content": "Agree, C is the best answer given<br><br>Better approach might be to:<br>- start with On-Demand instances in an ASG<br>- set the ASG scaling metric to SQS FIFO queue depth<br>- monitor for steady-state minimum number of instances needed<br>- purchase RIs for minimum number of instances needed<br>- use On-Demand instances for additional bursting instances in the ASG above base",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 614301,
          "date": "Fri 10 Jun 2022 04:18",
          "username": "Anhdd",
          "content": "C for sure",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 607954,
          "date": "Fri 27 May 2022 08:58",
          "username": "bobsmith2000vijay1319",
          "content": "OK, everyone is on the same ground that it's between C and D. <br>RI vs Spot.<br>1) Data pattern is erratic.<br>2) The app must be available all the time.<br>3) Cost-effectiveness isn't mentioned.<br><br>First of all, if we set up the bid price to be equal the on-demand price of a particular instance, then we are always gonna get compute power. The stop price can't be higher on-demand one and it's never gonna be interrupted.<br>Second of all, we can't predict the amount of RI to purchase due to \\\"1)\\\".<br>Third of all, the Q states \\\"must be available all the time\\\".<br><br>The perfect answer would be use fleet with RI + Spot, because we can't predict how many RI to purchase.<br>Without giving it too much thoughts it's C.  But if you think about it for a bit longer, it seems to be D.  <br>Following KISS principle, let's say it's C. awesome explanation Bob !!!",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 704631,
          "date": "Wed 26 Oct 2022 13:37",
          "username": "vijay1319",
          "content": "awesome explanation Bob !!!",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 593485,
          "date": "Thu 28 Apr 2022 04:48",
          "username": "cooldeity",
          "content": "I think always means available to accept order, not necessarily for processing it",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 540647,
          "date": "Fri 04 Feb 2022 21:56",
          "username": "AMKazi",
          "content": "C is the right answer",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 514379,
          "date": "Sat 01 Jan 2022 06:19",
          "username": "cldy",
          "content": "C correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 509721,
          "date": "Sun 26 Dec 2021 18:24",
          "username": "vbalkemalgoklenuser0001",
          "content": "I don't see the point in using RI with SQS; https://aws.amazon.com/blogs/compute/running-cost-effective-queue-workers-with-amazon-sqs-and-amazon-ec2-spot-instances/<br>Answer: DThey meant RI for processing the SQS queue so answer is Cit is C because Orders must be handled on a first-come, first-serve basis and in the order in which they are received.<br><br>they are not asking for most cost effective",
          "upvote_count": "311",
          "selected_answers": ""
        },
        {
          "id": 513692,
          "date": "Thu 30 Dec 2021 20:53",
          "username": "kemalgoklen",
          "content": "They meant RI for processing the SQS queue so answer is C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 605730,
          "date": "Mon 23 May 2022 00:55",
          "username": "user0001",
          "content": "it is C because Orders must be handled on a first-come, first-serve basis and in the order in which they are received.<br><br>they are not asking for most cost effective",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492137,
          "date": "Thu 02 Dec 2021 05:21",
          "username": "AzureDP900",
          "content": "C is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 445974,
          "date": "Mon 01 Nov 2021 22:36",
          "username": "andylogan",
          "content": "It's C with Reserved instance",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436403,
          "date": "Fri 29 Oct 2021 11:46",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413421,
          "date": "Sun 24 Oct 2021 18:15",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 404898,
          "date": "Wed 20 Oct 2021 12:52",
          "username": "KittuCheeku",
          "content": "Option C: In order (FIFO) + Reserved Instances in X AZs (Availability)",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 366186,
          "date": "Wed 13 Oct 2021 13:31",
          "username": "mustpassla",
          "content": "C, SAA level question",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 356977,
          "date": "Wed 13 Oct 2021 03:38",
          "username": "Waiweng",
          "content": "it's C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 334369,
          "date": "Tue 12 Oct 2021 10:04",
          "username": "KnightVictor",
          "content": "Answer is C.  keywords \\\"needs to be avail at all times\\\", process the orders as they come",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 321713,
          "date": "Mon 11 Oct 2021 01:22",
          "username": "alisyech",
          "content": "C for sure",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 294197,
          "date": "Sun 10 Oct 2021 22:55",
          "username": "Kian1",
          "content": "going for C",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#667",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>An AWS partner company is building a service in AWS Organizations using its organization named org1. This service requires the partner company to have access to AWS resources in a customer account, which is in a separate organization named org2. The company must establish least privilege security access using an API or command line tool to the customer account.<br>What is the MOST secure way to allow org1 to access resources in org2?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: D</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#667",
          "answers": [
            {
              "choice": "<p>A. The customer should provide the partner company with their AWS account access keys to log in and perform the required tasks.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. The customer should create an IAM user and assign the required permissions to the IAM user. The customer should then provide the credentials to the partner company to log in and perform the required tasks.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. The customer should create an IAM role and assign the required permissions to the IAM role. The partner company should then use the IAM role's Amazon Resource Name (ARN) when requesting access to perform the required tasks.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. The customer should create an IAM role and assign the required permissions to the IAM role. The partner company should then use the IAM role's Amazon Resource Name (ARN), including the external ID in the IAM role's trust policy, when requesting access to perform the required tasks.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 213624,
          "date": "Wed 22 Sep 2021 22:25",
          "username": "A_New_Guyoscargeestudent22student22Kelvin1477kirrim",
          "content": "I think D is the Answer:<br>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.htmlNot correct. I think you mixed client and host role. Host owner should create IAM with external ID.  But in this case, reversed.Yes. I think the answer is C. Changing my answer to D. <br>Assuming the answer is not suggesting to include the external id when making the request.agree, external id is a safety precatious to only allow certain user in that third party app orgnizahttps://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-professional/view/68/#tion to assume the roleAgree, it's addressing the \\\"Confused Deputy problem\\\":<br><br>https://docs.aws.amazon.com/IAM/latest/UserGuide/confused-deputy.html",
          "upvote_count": "2021131",
          "selected_answers": ""
        },
        {
          "id": 371201,
          "date": "Tue 26 Oct 2021 09:18",
          "username": "oscargeestudent22student22",
          "content": "Not correct. I think you mixed client and host role. Host owner should create IAM with external ID.  But in this case, reversed.Yes. I think the answer is C. Changing my answer to D. <br>Assuming the answer is not suggesting to include the external id when making the request.",
          "upvote_count": "211",
          "selected_answers": ""
        },
        {
          "id": 439426,
          "date": "Mon 01 Nov 2021 13:59",
          "username": "student22student22",
          "content": "Yes. I think the answer is C. Changing my answer to D. <br>Assuming the answer is not suggesting to include the external id when making the request.",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 439429,
          "date": "Thu 04 Nov 2021 14:27",
          "username": "student22",
          "content": "Changing my answer to D. <br>Assuming the answer is not suggesting to include the external id when making the request.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 225377,
          "date": "Mon 27 Sep 2021 23:08",
          "username": "Kelvin1477kirrim",
          "content": "agree, external id is a safety precatious to only allow certain user in that third party app orgnizahttps://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-professional/view/68/#tion to assume the roleAgree, it's addressing the \\\"Confused Deputy problem\\\":<br><br>https://docs.aws.amazon.com/IAM/latest/UserGuide/confused-deputy.html",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 463318,
          "date": "Sat 06 Nov 2021 20:51",
          "username": "kirrim",
          "content": "Agree, it's addressing the \\\"Confused Deputy problem\\\":<br><br>https://docs.aws.amazon.com/IAM/latest/UserGuide/confused-deputy.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 578528,
          "date": "Wed 30 Mar 2022 22:01",
          "username": "OBA1",
          "content": "Answer is D<br>Difference between C and D is “ What is the SECUREST”",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 498434,
          "date": "Fri 10 Dec 2021 09:53",
          "username": "cldy",
          "content": "D.  The customer should create an IAM role and assign the required permissions to the IAM role. The partner company should then use the IAM roleג€™s Amazon Resource Name (ARN), including the external ID in the IAM roleג€™s trust policy, when requesting access to perform the required tasks.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 492139,
          "date": "Thu 02 Dec 2021 05:27",
          "username": "AzureDP900",
          "content": "D is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488819,
          "date": "Sun 28 Nov 2021 04:49",
          "username": "acloudguru",
          "content": "D is the Answer, such simple security question, hope I can have it in my real exam<br>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 445981,
          "date": "Fri 05 Nov 2021 03:47",
          "username": "andylogan",
          "content": "It's D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435252,
          "date": "Thu 28 Oct 2021 17:40",
          "username": "tgv",
          "content": "DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413423,
          "date": "Wed 27 Oct 2021 20:32",
          "username": "WhyIronMan",
          "content": "I'll go with D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357083,
          "date": "Sun 24 Oct 2021 20:09",
          "username": "Waiweng",
          "content": "it's D",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 343434,
          "date": "Sat 23 Oct 2021 07:33",
          "username": "blackgamer",
          "content": "Anwer is D. ",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 321714,
          "date": "Wed 20 Oct 2021 08:39",
          "username": "alisyech",
          "content": "i choose D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 296478,
          "date": "Mon 18 Oct 2021 23:48",
          "username": "Joaster",
          "content": "Definitely D: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 294199,
          "date": "Mon 18 Oct 2021 02:28",
          "username": "Kian1",
          "content": "will go with D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 284545,
          "date": "Sun 17 Oct 2021 06:07",
          "username": "Ebi",
          "content": "D is my choice",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 256687,
          "date": "Tue 12 Oct 2021 22:39",
          "username": "Bulti",
          "content": "Answer is D. ",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 256366,
          "date": "Mon 11 Oct 2021 06:22",
          "username": "petebear55kopper2019",
          "content": "Why do they have the correct answer as B ? when it is clearly D ?the idea behind examtopics is resolved the Qs use the crow and share and debate about the correct answers here not the ones depicted",
          "upvote_count": "14",
          "selected_answers": ""
        },
        {
          "id": 269346,
          "date": "Wed 13 Oct 2021 18:21",
          "username": "kopper2019",
          "content": "the idea behind examtopics is resolved the Qs use the crow and share and debate about the correct answers here not the ones depicted",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 247379,
          "date": "Wed 06 Oct 2021 01:26",
          "username": "devilman222somebodyelse",
          "content": "There is no way that A or B are correct.<br>Does reveal solution just pick a random answer?Yes it does.",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 436328,
          "date": "Sun 31 Oct 2021 04:20",
          "username": "somebodyelse",
          "content": "Yes it does.",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#668",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>An enterprise company is building an infrastructure services platform for its users. The company has the following requirements:<br>✑ Provide least privilege access to users when launching AWS infrastructure so users cannot provision unapproved services.<br>✑ Use a central account to manage the creation of infrastructure services.<br>✑ Provide the ability to distribute infrastructure services to multiple accounts in AWS Organizations.<br>Provide the ability to enforce tags on any infrastructure that is started by users.<br><img src=\"https://www.examtopics.com/https://examtopics.com/assets/media/exam-media/04241/0043900004.png\" class=\"in-exam-image\"><br>Which combination of actions using AWS services will meet these requirements? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BDE</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#668",
          "answers": [
            {
              "choice": "<p>A. Develop infrastructure services using AWS Cloud Formation templates. Add the templates to a central Amazon S3 bucket and add the-IAM roles or users that require access to the S3 bucket policy.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Develop infrastructure services using AWS Cloud Formation templates. Upload each template as an AWS Service Catalog product to portfolios created in a central AWS account. Share these portfolios with the Organizations structure created for the company.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Allow user IAM roles to have AWSCloudFormationFullAccess and AmazonS3ReadOnlyAccess permissions. Add an Organizations SCP at the AWS account root user level to deny all services except AWS CloudFormation and Amazon S3.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Allow user IAM roles to have ServiceCatalogEndUserAccess permissions only. Use an automation script to import the central portfolios to local AWS accounts, copy the TagOption assign users access and apply launch constraints.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Use the AWS Service Catalog TagOption Library to maintain a list of tags required by the company. Apply the TagOption to AWS Service Catalog products or portfolios.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>F. Use the AWS CloudFormation Resource Tags property to enforce the application of tags to any CloudFormation templates that will be created for users.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 214541,
          "date": "Mon 20 Sep 2021 22:53",
          "username": "liono",
          "content": "B,D,E seems to be the correct options",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 218442,
          "date": "Wed 22 Sep 2021 20:23",
          "username": "AK2020",
          "content": "B, D , E - Seems correct",
          "upvote_count": "8",
          "selected_answers": ""
        },
        {
          "id": 686363,
          "date": "Tue 04 Oct 2022 20:00",
          "username": "AwsBRFanpsou7",
          "content": "Considering BCE<br>https://docs.aws.amazon.com/servicecatalog/latest/adminguide/controlling_access.html<br><br>If you apply the ServiceCatalogEndUserAccess policy, your users have access to the end user console view, but they won't have the permissions that they need to launch products and manage provisioned products. You can grant these permissions directly to an end user in IAM, but if you want to limit the access that end users have to AWS resources, you should attach the policy to a launch role. You then use AWS Service Catalog to apply the launch role to a launch constraint for the product.Not 100% accurate. The question does not specify what kind of EndUserAccess is granted.<br>With EndUserFullAccess, user can launch products.<br>End users<br>AWSServiceCatalogEndUserFullAccess — Grants full access to the end user console view. Grants permission to launch products and manage provisioned products.<br><br>AWSServiceCatalogEndUserReadOnlyAccess — Grants read-only access to the end user console view. Does not grant permission to launch products or manage provisioned products.<br><br>BDE",
          "upvote_count": "11",
          "selected_answers": "Selected Answer: BCE"
        },
        {
          "id": 686687,
          "date": "Wed 05 Oct 2022 09:34",
          "username": "psou7",
          "content": "Not 100% accurate. The question does not specify what kind of EndUserAccess is granted.<br>With EndUserFullAccess, user can launch products.<br>End users<br>AWSServiceCatalogEndUserFullAccess — Grants full access to the end user console view. Grants permission to launch products and manage provisioned products.<br><br>AWSServiceCatalogEndUserReadOnlyAccess — Grants read-only access to the end user console view. Does not grant permission to launch products or manage provisioned products.<br><br>BDE",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 684204,
          "date": "Sat 01 Oct 2022 14:42",
          "username": "Ell89",
          "content": "BDE gets my vote",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BDE"
        },
        {
          "id": 615439,
          "date": "Sun 12 Jun 2022 19:11",
          "username": "CloudHell",
          "content": "It's BDE to me.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BDE"
        },
        {
          "id": 602797,
          "date": "Tue 17 May 2022 07:40",
          "username": "bobsmith2000",
          "content": "No-brainer.<br>Choose everything which is related to Service Catalog",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BDE"
        },
        {
          "id": 492140,
          "date": "Thu 02 Dec 2021 05:31",
          "username": "AzureDP900",
          "content": "B,D,E is correct answer",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 445983,
          "date": "Sun 31 Oct 2021 19:58",
          "username": "andylogan",
          "content": "It's B D E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 437146,
          "date": "Sun 31 Oct 2021 11:51",
          "username": "Kopa",
          "content": "B,D,E all related to Service Catalog",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436409,
          "date": "Tue 26 Oct 2021 12:47",
          "username": "tgv",
          "content": "BBB DDD EEE<br>---",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 433872,
          "date": "Sun 24 Oct 2021 21:00",
          "username": "blackgamer",
          "content": "BDE is the answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433330,
          "date": "Sat 23 Oct 2021 07:29",
          "username": "Suresh108",
          "content": "\\\"user cannot provision unapproved services\\\" --- choose 'service catalog' in all the options given. thats BDE. ",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 413426,
          "date": "Fri 22 Oct 2021 05:50",
          "username": "WhyIronMan",
          "content": "I'll go with B,D,E",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 411382,
          "date": "Fri 22 Oct 2021 01:34",
          "username": "student2020",
          "content": "I think BEF is a better option. D looks good but the ServiceCatalogEndUserAccess permission only allows read only access and users cannot launch products. And in B the portfolios have already been shared, why share again using automation scripts?<br>https://docs.aws.amazon.com/servicecatalog/latest/adminguide/controlling_access.html",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 366754,
          "date": "Thu 21 Oct 2021 19:02",
          "username": "mustpassla",
          "content": "BDE.  Easy question.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 357093,
          "date": "Thu 21 Oct 2021 15:35",
          "username": "Waiweng",
          "content": "it's B,D,E",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 322748,
          "date": "Thu 21 Oct 2021 07:59",
          "username": "awsnoob",
          "content": "BDE<br>https://aws.amazon.com/blogs/mt/how-to-launch-secure-and-governed-aws-resources-with-aws-cloudformation-and-aws-service-catalog/",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#669",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A Solutions Architect is building a solution for updating user metadata that is initiated by web servers. The solution needs to rapidly scale from hundreds to tens of thousands of jobs in less than 30 seconds. The solution must be asynchronous always avertable and minimize costs.<br>Which strategies should the Solutions Architect use to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#669",
          "answers": [
            {
              "choice": "<p>A. Create an AWS SWF worker that will update user metadata updating web application to start a new workflow for every job.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an AWS Lambda function that will update user metadata. Create an Amazon SOS queue and configure it as an event source for the Lambda function. Update the web application to send jobs to the queue.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create an AWS Lambda function that will update user metadata. Create AWS Step Functions that will trigger the Lambda function. Update the web application to initiate Step Functions for every job.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create an Amazon SQS queue. Create an AMI with a worker to check the queue and update user metadata. Configure an Amazon EC2 Auto Scaling group with the new AMI. Update the web application to send jobs to the queue.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 256928,
          "date": "Wed 06 Oct 2021 03:24",
          "username": "Bulti",
          "content": "Since this is a just a simple job to update the metadata, I would eliminate workflow options such as A and C.  Between B and D I would chose B because itwill be easier to scale with Lambda using SQS as an event source as per the requirement than it is with EC2 Auto scaling.",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 638891,
          "date": "Fri 29 Jul 2022 00:01",
          "username": "hilft",
          "content": "queue + lambda to decouple the task",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 623837,
          "date": "Tue 28 Jun 2022 10:21",
          "username": "KiraguJohn",
          "content": "What is SOS queue?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 499009,
          "date": "Sat 11 Dec 2021 00:44",
          "username": "challenger1",
          "content": "My answer B:<br>No Simple Workflow Service (SWF) or Step Functions needed.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 492141,
          "date": "Thu 02 Dec 2021 05:33",
          "username": "AzureDP900",
          "content": "B is perfect",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446005,
          "date": "Tue 02 Nov 2021 22:44",
          "username": "andylogan",
          "content": "It's B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 439431,
          "date": "Sat 30 Oct 2021 15:05",
          "username": "student22",
          "content": "B <br>SQS with Lambda",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436410,
          "date": "Thu 28 Oct 2021 07:39",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433883,
          "date": "Wed 27 Oct 2021 08:17",
          "username": "blackgamerkirrim",
          "content": "Yes, it is B.  <br><br>Lambda concurrent quota can increase up to Tens of thousands.Agree, here's the documentation for that:<br><br>https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html<br><br>The problem with D is that it takes time to spin up new instances in an ASG.And the question said \\\"rapidly scale from hundreds to tens of thousands of jobs in less than 30 seconds\\\".",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 463323,
          "date": "Sun 07 Nov 2021 06:59",
          "username": "kirrim",
          "content": "Agree, here's the documentation for that:<br><br>https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html<br><br>The problem with D is that it takes time to spin up new instances in an ASG.And the question said \\\"rapidly scale from hundreds to tens of thousands of jobs in less than 30 seconds\\\".",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413430,
          "date": "Mon 25 Oct 2021 11:18",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 356982,
          "date": "Fri 22 Oct 2021 13:32",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 321716,
          "date": "Tue 19 Oct 2021 05:00",
          "username": "alisyech",
          "content": "i go with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 298111,
          "date": "Sat 16 Oct 2021 23:21",
          "username": "cnethersstudent22champcloud",
          "content": "B is talking about SOS not SQS<br>If it was talking about SQS then B would make sense .. is that just a typo ?It's a typo. The questions also mentions 'avertable' instead of 'available'Yup probably a typo. Ans is B. ",
          "upvote_count": "212",
          "selected_answers": ""
        },
        {
          "id": 439432,
          "date": "Mon 01 Nov 2021 01:09",
          "username": "student22",
          "content": "It's a typo. The questions also mentions 'avertable' instead of 'available'",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 307720,
          "date": "Tue 19 Oct 2021 01:38",
          "username": "champcloud",
          "content": "Yup probably a typo. Ans is B. ",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 296280,
          "date": "Thu 14 Oct 2021 23:48",
          "username": "Joaster",
          "content": "B.  Asynchronous workflows have always been the primary use case for SQS.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 294208,
          "date": "Thu 14 Oct 2021 20:37",
          "username": "Kian1",
          "content": "going with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 284478,
          "date": "Wed 13 Oct 2021 12:21",
          "username": "Ebi",
          "content": "My choice is B, but even that is not a complete solution as Lambda concurrency limit must be increased as well which hasn't been included in this answer.<br>All other answers can be eliminated easily <br>A, no SWF is needed in here<br>C, No step function is needed, simple metadata update <br>D, Auto scaling group can not scale fast, can take more than 30 sec to launch new instances in asg",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 264353,
          "date": "Wed 06 Oct 2021 18:04",
          "username": "nqobzaJustuRedKane",
          "content": "The answer is D.  Anything involving lambda will not scale well in this scenario. Look at concurrent execution limits.https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.htmlNope, it's still B.  As Lambda max concurrent execution limits can be requested from default 1000 to Hundreds of thousands.<br><br>Scaling up ec2 enough to handle the need in 30 seconds seems impossible for me.Even that might not be needed if Lambda consumes SQS messages in batches. Batch size can be up to 10 000. With that it's possible to consume and process tens of thousands of messages with just several lambda functions running concurrently (if one wants to minimize number of concurrent functions and execution time for all messages in batch does not exceed 15 minutes)",
          "upvote_count": "141",
          "selected_answers": ""
        },
        {
          "id": 267277,
          "date": "Wed 13 Oct 2021 11:55",
          "username": "JustuRedKane",
          "content": "Nope, it's still B.  As Lambda max concurrent execution limits can be requested from default 1000 to Hundreds of thousands.<br><br>Scaling up ec2 enough to handle the need in 30 seconds seems impossible for me.Even that might not be needed if Lambda consumes SQS messages in batches. Batch size can be up to 10 000. With that it's possible to consume and process tens of thousands of messages with just several lambda functions running concurrently (if one wants to minimize number of concurrent functions and execution time for all messages in batch does not exceed 15 minutes)",
          "upvote_count": "41",
          "selected_answers": ""
        },
        {
          "id": 331685,
          "date": "Thu 21 Oct 2021 12:12",
          "username": "RedKane",
          "content": "Even that might not be needed if Lambda consumes SQS messages in batches. Batch size can be up to 10 000. With that it's possible to consume and process tens of thousands of messages with just several lambda functions running concurrently (if one wants to minimize number of concurrent functions and execution time for all messages in batch does not exceed 15 minutes)",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#670",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company's main intranet page has experienced degraded response times as its user base has increased although there are no reports of users seeing error pages. The application uses Amazon DynamoDB in read-only mode.<br>Amazon DynamoDB latency metrics for successful requests have been in a steady state even during times when users have reported degradation. The<br>Development team has correlated the issue to ProvisionedThrough put Exceeded exceptions in the application logs when doing Scan and read operations The team also identified an access pattern of steady spikes of read activity on a distributed set of individual data items.<br>The Chief Technology Officer wants to improve the user experience.<br>Which solutions will meet these requirements with the LEAST amount of changes to the application? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#670",
          "answers": [
            {
              "choice": "<p>A. Change the data model of the DynamoDB tables to ensure that all Scan and read operations meet DynamoDB best practices of uniform data access, reaching the full request throughput provisioned for the DynamoDB tables.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Enable DynamoDB Auto Scaling to manage the throughput capacity as table traffic increases. Set the upper and lower limits to control costs and set a target utilization given the peak usage and how quickly the traffic changes.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Provision Amazon ElastiCache for Redis with cluster mode enabled. The cluster should be provisioned with enough shards to spread the application load and provision at least one read replica node for each shard.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Implement the DynamoDB Accelerator (DAX) client and provision a DAX cluster with the appropriate node types to sustain the application load. Tune the item and query cache configuration for an optimal user experience.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Remove error retries and exponential backoffs in the application code to handle throttling errors.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 214547,
          "date": "Sun 19 Sep 2021 20:32",
          "username": "liono",
          "content": "B and D will require least amount of changes in the application while increasing over all performance",
          "upvote_count": "29",
          "selected_answers": ""
        },
        {
          "id": 284479,
          "date": "Fri 22 Oct 2021 07:04",
          "username": "Ebi",
          "content": "BD my choice",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 702422,
          "date": "Sun 23 Oct 2022 21:19",
          "username": "fdoxxx",
          "content": "For sure B, D",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 498597,
          "date": "Fri 10 Dec 2021 13:13",
          "username": "cldy",
          "content": "B.  Enable DynamoDB Auto Scaling to manage the throughput capacity as table traffic increases. Set the upper and lower limits to control costs and set a target utilization given the peak usage and how quickly the traffic changes.<br>D.  Implement the DynamoDB Accelerator (DAX) client and provision a DAX cluster with the appropriate node types to sustain the application load. Tune the item and query cache configuration for an optimal user experience.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492143,
          "date": "Thu 02 Dec 2021 05:36",
          "username": "AzureDP900",
          "content": "B,D is my choice",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488999,
          "date": "Sun 28 Nov 2021 09:51",
          "username": "acloudguru",
          "content": "BD are very easy one, hope I can have it in my exam",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 488550,
          "date": "Sat 27 Nov 2021 23:51",
          "username": "AzureDP900",
          "content": "B & D is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446010,
          "date": "Thu 04 Nov 2021 07:30",
          "username": "andylogan",
          "content": "It's B D - Auto scaling and DAX",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 437047,
          "date": "Wed 03 Nov 2021 05:24",
          "username": "tgv",
          "content": "BBB DDD<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 433901,
          "date": "Tue 02 Nov 2021 14:11",
          "username": "blackgamer",
          "content": "B and D.  Least amount of changes.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413435,
          "date": "Mon 01 Nov 2021 08:18",
          "username": "WhyIronMan",
          "content": "I'll go with B,D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 376898,
          "date": "Sat 30 Oct 2021 00:05",
          "username": "ss160700Viper57",
          "content": "why not B & C ?D is better than C.  DAX is specifically built for caching queries for DynamoDB. ",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 458378,
          "date": "Thu 04 Nov 2021 13:01",
          "username": "Viper57",
          "content": "D is better than C.  DAX is specifically built for caching queries for DynamoDB. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 375947,
          "date": "Fri 29 Oct 2021 03:37",
          "username": "pradhyumnaViper57frankzeng",
          "content": "A and D.  Implementing best practices for uniform data access and DAX to improve the read performance. <br>B may not be right, auto-scaling may not really help if the data is distributed, it will only increase cost by scaling up resources.A is wrong. This requires changing the data model of the entire database. The questions asks for the solution with the LEAST amount of changes to the application. B and D are correct.It is DynamoDB.  The data model can be changed with adding Global secondary index. No change to the application",
          "upvote_count": "321",
          "selected_answers": ""
        },
        {
          "id": 458379,
          "date": "Fri 05 Nov 2021 12:11",
          "username": "Viper57frankzeng",
          "content": "A is wrong. This requires changing the data model of the entire database. The questions asks for the solution with the LEAST amount of changes to the application. B and D are correct.It is DynamoDB.  The data model can be changed with adding Global secondary index. No change to the application",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 523877,
          "date": "Sat 15 Jan 2022 02:56",
          "username": "frankzeng",
          "content": "It is DynamoDB.  The data model can be changed with adding Global secondary index. No change to the application",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 356983,
          "date": "Wed 27 Oct 2021 08:56",
          "username": "Waiweng",
          "content": "it's B&D",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 321717,
          "date": "Sun 24 Oct 2021 13:36",
          "username": "alisyech",
          "content": "i choose B & D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 319708,
          "date": "Sun 24 Oct 2021 10:35",
          "username": "eji",
          "content": "why not CD?",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 294210,
          "date": "Sun 24 Oct 2021 01:52",
          "username": "Kian1",
          "content": "going for BD",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#671",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A solutions architect has implemented a SAML 2.0 federated identity solution with their company's on-premises identity provider (IdP) to authenticate users' access to the AWS environment. When the solutions architect tests authentication through the federated identity web portal, access to the AWS environment is granted. However, when test users attempt to authenticate through the federated identity web portal, they are not able to access the AWS environment.<br>Which items should the solutions architect check to ensure identity federation is properly configured? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BDF</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#671",
          "answers": [
            {
              "choice": "<p>A. The IAM user's permissions policy has allowed the use of SAML federation for that user.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. The IAM roles created for the federated users' or federated groups' trust policy have set the SAML provider as the principal.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Test users are not in the AWSFederatedUsers group in the company's IdR.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. The web portal calls the AWS STS AssumeRoleWithSAML API with the ARN of the SAML provider, the ARN of the IAM role, and the SAML assertion from IdR.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. The on-premises IdP's DNS hostname is reachable from the AWS environment VPCs.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>F. The company's IdP defines SAML assertions that properly map users or groups in the company to IAM roles with appropriate permissions.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 214549,
          "date": "Wed 22 Sep 2021 08:44",
          "username": "liono",
          "content": "B, D & F looks correct",
          "upvote_count": "29",
          "selected_answers": ""
        },
        {
          "id": 240659,
          "date": "Mon 27 Sep 2021 08:29",
          "username": "Cantaloupekirrim",
          "content": "B: \\\"In IAM, you create one or more IAM roles. In the role's trust policy, you set the SAML provider as the principal, which establishes a trust relationship between your organization and AWS\\\"<br><br>D: \\\"The client app calls the AWS STS AssumeRoleWithSAML API, passing the ARN of the SAML provider, the ARN of the role to assume, and the SAML assertion from IdP\\\"<br><br>F: \\\"In your organization's IdP, you define assertions that map users or groups in your organization to the IAM roles\\\"Where these quotes came from:<br><br>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_saml.html",
          "upvote_count": "184",
          "selected_answers": ""
        },
        {
          "id": 463327,
          "date": "Sat 06 Nov 2021 15:32",
          "username": "kirrim",
          "content": "Where these quotes came from:<br><br>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_saml.html",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 653974,
          "date": "Tue 30 Aug 2022 11:48",
          "username": "kadev",
          "content": "B,D,F<br>Explain:<br>Follow to accecc to AWS console by IDP 3rd:<br>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_enable-console-saml.html<br>From stituation of question, we know that: Flow is succesc to step 3 ( got Grant from Idp)<br>=> user cant not access to AWS console because failed at step 4 or step 5<br>So:<br>1. we need to verify SAML assertion (D) : \\\"The IAM role and IAM identity provider are specified as a comma-delimited pair of ARNs in the same format as the RoleArn and PrincipalArn\\\"<br>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_create_saml_assertions.html#saml-attribute-mapping<br><br>2, Next, Verify mapping User and Role is exaclty( F)<br><br>3, Verify \\\"Prerequisites for creating a role for SAML\\\" : Principal must has \\\"PROVIDER-NAME\\\"<br>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-idp_saml.html#idp_saml_Prerequisites",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 545979,
          "date": "Sat 12 Feb 2022 17:05",
          "username": "RVivekhancoms",
          "content": "Answer BDF <br>E is also require ?Can some one say why E is not rquired ?i think<br>'the AWS environment VPCs' -> it does not need to assume role for SAML in aws account side",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 701844,
          "date": "Sun 23 Oct 2022 03:09",
          "username": "hancoms",
          "content": "i think<br>'the AWS environment VPCs' -> it does not need to assume role for SAML in aws account side",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 504374,
          "date": "Sat 18 Dec 2021 19:13",
          "username": "vbalvbal",
          "content": "I can't see B an answer : The IAM roles created FOR the federated usersג€™ or federated groups???B is fine",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 504378,
          "date": "Sat 18 Dec 2021 19:17",
          "username": "vbal",
          "content": "B is fine",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 497339,
          "date": "Thu 09 Dec 2021 06:08",
          "username": "CloudChef",
          "content": "BDF is it.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496574,
          "date": "Wed 08 Dec 2021 07:06",
          "username": "cldy",
          "content": "B.  The IAM roles created for the federated usersג€™ or federated groupsג€™ trust policy have set the SAML provider as the principal.<br>D.  The web portal calls the AWS STS AssumeRoleWithSAML API with the ARN of the SAML provider, the ARN of the IAM role, and the SAML assertion from IdR.<br>F.  The companyג€™s IdP defines SAML assertions that properly map users or groups in the company to IAM roles with appropriate permissions.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488556,
          "date": "Sat 27 Nov 2021 23:57",
          "username": "AzureDP900",
          "content": "B,D,F is perfect answer for given scenario.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 483775,
          "date": "Mon 22 Nov 2021 02:19",
          "username": "acloudguru",
          "content": "B: \\\"In IAM, you create one or more IAM roles. In the role's trust policy, you set the SAML provider as the principal, which establishes a trust relationship between your organization and AWS\\\"<br><br>D: \\\"The client app calls the AWS STS AssumeRoleWithSAML API, passing the ARN of the SAML provider, the ARN of the role to assume, and the SAML assertion from IdP\\\"<br><br>F: \\\"In your organization's IdP, you define assertions that map users or groups in your organization to the IAM roles\\\"",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: BDF"
        },
        {
          "id": 446023,
          "date": "Sat 06 Nov 2021 04:30",
          "username": "andylogan",
          "content": "It's B D F",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436529,
          "date": "Sat 30 Oct 2021 19:22",
          "username": "tgv",
          "content": "BBB DDD FFF<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 433905,
          "date": "Fri 29 Oct 2021 00:52",
          "username": "blackgamer",
          "content": "BDF for me.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413463,
          "date": "Fri 29 Oct 2021 00:15",
          "username": "WhyIronMan",
          "content": "I'll go with B,D,F",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357099,
          "date": "Tue 26 Oct 2021 10:02",
          "username": "Waiweng",
          "content": "it's B,D and F",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 294214,
          "date": "Tue 26 Oct 2021 01:14",
          "username": "Kian1",
          "content": "will go with BDF",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 284483,
          "date": "Sun 24 Oct 2021 14:39",
          "username": "Ebi",
          "content": "BDF is my choice",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 278754,
          "date": "Sun 24 Oct 2021 12:47",
          "username": "gookseang",
          "content": "I will go BDF",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#672",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company's security compliance requirements state that all Amazon EC2 images must be scanned for vulnerabilities and must pass a CVE assessment. A solutions architect is developing a mechanism to create security- approved AMIs that can be used by developers. Any new AMIs should go through an automated assessment process and be marked as approved before developers can use them. The approved images must be scanned every 30 days to ensure compliance.<br>Which combination of steps should the solutions architect take to meet these requirements while following best practices? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BC</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#672",
          "answers": [
            {
              "choice": "<p>A. Use the AWS Systems Manager EC2 agent to run the CVE assessment on the EC2 instances launched from the AMIs that need to be scanned.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use AWS Lambda to write automatic approval rules. Store the approved AMI list in AWS Systems Manager Parameter Store. Use Amazon EventBridge to trigger an AWS Systems Manager Automation document on all EC2 instances every 30 days.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use Amazon Inspector to run the CVE assessment on the EC2 instances launched from the AMIs that need to be scanned.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use AWS Lambda to write automatic approval rules. Store the approved AMI list in AWS Systems Manager Parameter Store. Use a managed AWS Config rule for continuous scanning on all EC2 instances, and use AWS Systems Manager Automation documents for remediation.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>E. Use AWS CloudTrail to run the CVE assessment on the EC2 instances launched from the AMIs that need to be scanned.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 284484,
          "date": "Mon 18 Oct 2021 04:37",
          "username": "Ebi",
          "content": "BC,<br>For CVE we don't need continuoues scanning, so D is ruled out.",
          "upvote_count": "16",
          "selected_answers": ""
        },
        {
          "id": 216251,
          "date": "Tue 21 Sep 2021 07:10",
          "username": "bbnbnuyhelf78",
          "content": "https://aws.amazon.com/blogs/security/how-to-set-up-continuous-golden-ami-vulnerability-assessments-with-amazon-inspector/+1. Answers are B&C",
          "upvote_count": "82",
          "selected_answers": ""
        },
        {
          "id": 279622,
          "date": "Sun 17 Oct 2021 23:41",
          "username": "elf78",
          "content": "+1. Answers are B&C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 686376,
          "date": "Tue 04 Oct 2022 20:32",
          "username": "AwsBRFan",
          "content": "https://aws.amazon.com/blogs/mt/automate-vulnerability-management-and-remediation-in-aws-using-amazon-inspector-and-aws-systems-manager-part-1/",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BC"
        },
        {
          "id": 494224,
          "date": "Sun 05 Dec 2021 11:25",
          "username": "cldy",
          "content": "B.  Use AWS Lambda to write automatic approval rules. Store the approved AMI list in AWS Systems Manager Parameter Store. Use Amazon EventBridge to trigger an AWS Systems Manager Automation document on all EC2 instances every 30 days.<br>C.  Use Amazon Inspector to run the CVE assessment on the EC2 instances launched from the AMIs that need to be scanned.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492144,
          "date": "Thu 02 Dec 2021 05:39",
          "username": "AzureDP900",
          "content": "B,C Is my option",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488558,
          "date": "Sun 28 Nov 2021 00:00",
          "username": "AzureDP900",
          "content": "B,C is right choice",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446028,
          "date": "Tue 02 Nov 2021 00:33",
          "username": "andylogan",
          "content": "It's B C - Inspector and 30 days",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436531,
          "date": "Sun 31 Oct 2021 20:19",
          "username": "tgv",
          "content": "BBB CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433347,
          "date": "Mon 25 Oct 2021 01:44",
          "username": "Suresh108",
          "content": "easy to remember trick - <br><br>B - question has 30 days, this is the only answer has 30 days in it.<br>C - CVE needs to be inspected, use 'Amazon Inspector' only C has these words.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 425769,
          "date": "Sun 24 Oct 2021 10:56",
          "username": "Sean2021",
          "content": "C&D<br>You cannot use SSM document to scan",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357104,
          "date": "Tue 19 Oct 2021 20:19",
          "username": "Waiweng",
          "content": "it's B and C",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 345523,
          "date": "Tue 19 Oct 2021 11:05",
          "username": "Amitv2706",
          "content": "B and C for sure",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 294218,
          "date": "Mon 18 Oct 2021 23:06",
          "username": "Kian1",
          "content": "going with BC",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 269731,
          "date": "Mon 11 Oct 2021 23:02",
          "username": "kopper2019",
          "content": "B and C, for sure Amazon inspectos is needed",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 266201,
          "date": "Thu 07 Oct 2021 01:44",
          "username": "rkbala",
          "content": "A and B<br>https://aws.amazon.com/about-aws/whats-new/2020/10/now-use-aws-systems-manager-to-view-vulnerability-identifiers-for-missing-patches-on-your-linux-instances/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 263889,
          "date": "Mon 04 Oct 2021 11:38",
          "username": "Superomam",
          "content": "B, C.  Remediation activity is not asked into the question.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 256954,
          "date": "Sun 03 Oct 2021 10:48",
          "username": "Bulti",
          "content": "C is correct, Now between B and D, both might work but since we are asked to scan the EC2 instances every 30 days I will go with B.  So the final answer is B and C. ",
          "upvote_count": "4",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#673",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company uses AWS Organizations with a single OU named Production to manage multiple accounts. All accounts are members of the Production OU.<br>Administrators use deny list SCPs in the root of the organization to manage access to restricted services.<br>The company recently acquired a new business unit and invited the new unit's existing AWS account to the organization. Once onboarded, the administrators of the new business unit discovered that they are not able to update existing AWS Config rules to meet the company's policies.<br>Which option will allow administrators to make changes and continue to enforce the current policies without introducing additional long-term maintenance?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: D</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#673",
          "answers": [
            {
              "choice": "<p>A. Remove the organization's root SCPs that limit access to AWS Config. Create AWS Service Catalog products for the company's standard AWS Config rules and deploy them throughout the organization, including the new account.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the new account to the Production OU when adjustments to AWS Config are complete.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Convert the organization's root SCPs from deny list SCPs to allow list SCPs to allow the required services only. Temporally apply an SCP to the organization's root that allows AWS Config actions for principals only in the new account.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the organization's root SCP to the Production OU. Move the new account to the Production OU when adjustments to AWS Config are complete.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 226021,
          "date": "Thu 30 Sep 2021 06:04",
          "username": "avland",
          "content": "D.  The problem with B is that the new OU will be created within the root of the organization, and so the Deny on changes to Config rules (from the root of the organization) will then apply to the new OU as well. The new OU must not have a parent that denies changes to Config rules. That would be the case for D. ",
          "upvote_count": "26",
          "selected_answers": ""
        },
        {
          "id": 217465,
          "date": "Wed 29 Sep 2021 06:11",
          "username": "smartassX",
          "content": "D --> \\\"Administrators use deny list SCPs in the root of the organization to manage access to restricted services.\\\"In Option D \\\"Move the organization's root SCP to the Production OU. Move the new account to the Production OU when adjustments to AWS Config are complete.\\\"",
          "upvote_count": "10",
          "selected_answers": ""
        },
        {
          "id": 496027,
          "date": "Tue 07 Dec 2021 14:08",
          "username": "cldy",
          "content": "D.  Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the organizationג€™s root SCP to the Production OU. Move the new account to the Production OU when adjustments to AWS Config are complete.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488563,
          "date": "Sun 28 Nov 2021 00:04",
          "username": "AzureDP900",
          "content": "D Is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446036,
          "date": "Mon 01 Nov 2021 18:59",
          "username": "andylogan",
          "content": "It's D - create temporary OU",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436532,
          "date": "Mon 01 Nov 2021 14:56",
          "username": "tgv",
          "content": "DDD<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 413464,
          "date": "Sun 31 Oct 2021 11:22",
          "username": "WhyIronMan",
          "content": "I'll go with D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357116,
          "date": "Thu 28 Oct 2021 03:42",
          "username": "Waiweng",
          "content": "it's D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 328630,
          "date": "Mon 25 Oct 2021 22:24",
          "username": "ExtHo",
          "content": "D is correct as for B If the SCP applied on the organization's root has a \\\"deny\\\" permission, all OUs under the organization will inherit that rule. You cannot override an explicit \\\"deny\\\" permission with an explicit \\\"allow\\\" applied to the temporary Onboarding OU.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 307109,
          "date": "Sat 23 Oct 2021 18:40",
          "username": "awsnoob",
          "content": "B is not correct.... Deny takes precedent... it should be D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 301845,
          "date": "Mon 18 Oct 2021 13:52",
          "username": "kiev",
          "content": "OK review again. The answer is B.  Don't forget scp was already applicable to root do no need to apply it again and thus why D isn't correct",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 301769,
          "date": "Sat 16 Oct 2021 03:04",
          "username": "kiev",
          "content": "Guys anyone here having problems accessing exam topics from laptop? I just can't get access for over two days now. My answer is D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 284485,
          "date": "Fri 15 Oct 2021 21:14",
          "username": "Ebi",
          "content": "B does not work, deny at root does not allow member account even with an allow<br>D for sure",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 261823,
          "date": "Mon 11 Oct 2021 22:33",
          "username": "njthomas",
          "content": "Going with D, due to the \\\"allow administrators to make changes and continue to enforce the current policies\\\" part.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 258537,
          "date": "Mon 11 Oct 2021 21:05",
          "username": "njthomas",
          "content": "If scp is applied via deny policy at the root, we cannot enable it at a lower level. https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_inheritance_auth.html<br>I suggest C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 256964,
          "date": "Mon 11 Oct 2021 08:24",
          "username": "Bulti",
          "content": "I think the correct answer is D.  The best practice is to not assign an SCP to the root of the organization. So B is incorrect. https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html - Search for \\\"Testing effects of SCPs\\\".",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 241575,
          "date": "Thu 07 Oct 2021 07:15",
          "username": "T14102020",
          "content": "D is correct answer. The new OU must not have a parent that denies changes to Config rules.",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#674",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is launching a web-based application in multiple regions around the world. The application consists of both static content stored in a private Amazon<br>S3 bucket and dynamic content hosted in Amazon ECS containers content behind an Application Load Balancer (ALB). The company requires that the static and dynamic application content be accessible through Amazon CloudFront only.<br>Which combination of steps should a solutions architect recommend to restrict direct content access to CloudFront? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: ACF</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#674",
          "answers": [
            {
              "choice": "<p>A. Create a web ACL in AWS WAF with a rule to validate the presence of a custom header and associate the web ACL with the ALB. <br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create a web ACL in AWS WAF with a rule to validate the presence of a custom header and associate the web ACL with the CloudFront distribution.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Configure CloudFront to add a custom header to origin requests.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Configure the ALB to add a custom header to HTTP requests.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>E. Update the S3 bucket ACL to allow access from the CloudFront distribution only.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>F. Create a CloudFront Origin Access Identity (OAI) and add it to the CloudFront distribution. Update the S3 bucket policy to allow access to the OAI only.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 219517,
          "date": "Sun 26 Sep 2021 04:47",
          "username": "gookseangpetebear55shammouspetebear55MrCartertvsMrCarterKopa",
          "content": "A. C. F for sureYour answer a is wrong !!! .. If your going to come out with wild statements like this then back up your answers.. its B https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-awswaf.htmlHe is right, ... pete Red Herring.Repalce A with Bno mate nobody believes youPete read this https://aws.amazon.com/blogs/security/how-to-enhance-amazon-cloudfront-origin-security-with-aws-waf-and-aws-secrets-manager/#:~:text=In%20this%20blog%20post%2C%20you,it%20sends%20to%20your%20origin.ANSWER IS OBVIOUSLY A,C,F<br>Straight out of Jon Bonso's examsgood explanation",
          "upvote_count": "351325451",
          "selected_answers": ""
        },
        {
          "id": 256823,
          "date": "Tue 05 Oct 2021 14:18",
          "username": "petebear55shammouspetebear55MrCartertvsMrCarterKopa",
          "content": "Your answer a is wrong !!! .. If your going to come out with wild statements like this then back up your answers.. its B https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-awswaf.htmlHe is right, ... pete Red Herring.Repalce A with Bno mate nobody believes youPete read this https://aws.amazon.com/blogs/security/how-to-enhance-amazon-cloudfront-origin-security-with-aws-waf-and-aws-secrets-manager/#:~:text=In%20this%20blog%20post%2C%20you,it%20sends%20to%20your%20origin.ANSWER IS OBVIOUSLY A,C,F<br>Straight out of Jon Bonso's examsgood explanation",
          "upvote_count": "1325451",
          "selected_answers": ""
        },
        {
          "id": 280521,
          "date": "Wed 20 Oct 2021 19:39",
          "username": "shammous",
          "content": "He is right, ... pete Red Herring.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 256824,
          "date": "Thu 07 Oct 2021 07:00",
          "username": "petebear55MrCarter",
          "content": "Repalce A with Bno mate nobody believes you",
          "upvote_count": "25",
          "selected_answers": ""
        },
        {
          "id": 396051,
          "date": "Sun 31 Oct 2021 02:36",
          "username": "MrCarter",
          "content": "no mate nobody believes you",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 382517,
          "date": "Sat 30 Oct 2021 02:30",
          "username": "tvsMrCarterKopa",
          "content": "Pete read this https://aws.amazon.com/blogs/security/how-to-enhance-amazon-cloudfront-origin-security-with-aws-waf-and-aws-secrets-manager/#:~:text=In%20this%20blog%20post%2C%20you,it%20sends%20to%20your%20origin.ANSWER IS OBVIOUSLY A,C,F<br>Straight out of Jon Bonso's examsgood explanation",
          "upvote_count": "451",
          "selected_answers": ""
        },
        {
          "id": 396052,
          "date": "Sun 31 Oct 2021 10:09",
          "username": "MrCarter",
          "content": "ANSWER IS OBVIOUSLY A,C,F<br>Straight out of Jon Bonso's exams",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 480600,
          "date": "Thu 18 Nov 2021 11:24",
          "username": "Kopa",
          "content": "good explanation",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 256977,
          "date": "Thu 14 Oct 2021 19:16",
          "username": "BultishammousAkaAka401037",
          "content": "To ensure all requests are coming from CloudFront, the combination of steps should be C, A, F.  C will add the custom header. A will detect the presence of custom header using Web ACL rules in the WAF around ALB and then F will ensure that all request to access S3 buckets are coming from Cloudfront using the OAI.Great job Bulti, as always. Thank you for taking the time to explain your choices. I suggest everybody else do the same instead of just throwing their answers...Indeed, rookies like me really appreciate you guys' information :DAgree.<br>B and C are contradiction to each other.<br>If CloudFront adds the custom header, how could WAF in front of CloudFront validate the presence of the custom header.",
          "upvote_count": "27716",
          "selected_answers": ""
        },
        {
          "id": 280520,
          "date": "Wed 20 Oct 2021 10:15",
          "username": "shammousAkaAka4",
          "content": "Great job Bulti, as always. Thank you for taking the time to explain your choices. I suggest everybody else do the same instead of just throwing their answers...Indeed, rookies like me really appreciate you guys' information :D",
          "upvote_count": "71",
          "selected_answers": ""
        },
        {
          "id": 504840,
          "date": "Sun 19 Dec 2021 13:53",
          "username": "AkaAka4",
          "content": "Indeed, rookies like me really appreciate you guys' information :D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 271382,
          "date": "Tue 19 Oct 2021 07:17",
          "username": "01037",
          "content": "Agree.<br>B and C are contradiction to each other.<br>If CloudFront adds the custom header, how could WAF in front of CloudFront validate the presence of the custom header.",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 635812,
          "date": "Sun 24 Jul 2022 02:18",
          "username": "hilft",
          "content": "ACF<br>I saw the same one in Jon Bonso's exam. MrCarter got it too",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 626403,
          "date": "Sun 03 Jul 2022 06:23",
          "username": "aandc",
          "content": "deny direct access to S3 and ALB",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: ACF"
        },
        {
          "id": 579360,
          "date": "Fri 01 Apr 2022 08:28",
          "username": "KennethTam",
          "content": "ACF, you need to deny direct access to origin(ALB), but not cloudfront.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: ACF"
        },
        {
          "id": 557556,
          "date": "Sun 27 Feb 2022 20:26",
          "username": "Ni_yot",
          "content": "Agree with ACF.  CF is used to add custom http headers to request.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 539258,
          "date": "Thu 03 Feb 2022 00:53",
          "username": "HellGate",
          "content": "My answer is B C F. <br><br>To deliver contents through only CloudFront, we need associate the Web ACL with CloudFront, not ALB. ALB is for ECS here and for OAI, doesn’t need ALB. <br><br>https://docs.aws.amazon.com/waf/latest/developerguide/web-acl-associating-aws-resource.html<br>https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-serve-static-website/?nc1=h_ls",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 526965,
          "date": "Tue 18 Jan 2022 20:35",
          "username": "pititcu667",
          "content": "i chose acf",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ACF"
        },
        {
          "id": 503380,
          "date": "Fri 17 Dec 2021 06:44",
          "username": "Binoj_1985Binoj_1985",
          "content": "BCF right? Since static and dynamic application material must be available through Amazon CloudFront.ACF - Since validate rule to ALB",
          "upvote_count": "11",
          "selected_answers": "Selected Answer: BCF"
        },
        {
          "id": 503382,
          "date": "Fri 17 Dec 2021 06:46",
          "username": "Binoj_1985",
          "content": "ACF - Since validate rule to ALB",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492146,
          "date": "Thu 02 Dec 2021 05:45",
          "username": "AzureDP900",
          "content": "A,C,F Is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446042,
          "date": "Sat 06 Nov 2021 08:34",
          "username": "andylogan",
          "content": "It's C A F",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 439082,
          "date": "Fri 05 Nov 2021 22:31",
          "username": "DerekKey",
          "content": "A/C/F: very similar configuration is used by us in an environment that serves over 1 mln requests per second. The only difference is in usage of AWF.  This answer is a waste of money. ALB can check header in incoming traffic. You don't need WAF to do it.<br><br>CF sets custom header with a value<br>ALB check if custom header exists with this value<br>S3 uses CF OAI",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 435255,
          "date": "Fri 05 Nov 2021 03:22",
          "username": "tgv",
          "content": "AAA CCC FFF<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 433925,
          "date": "Thu 04 Nov 2021 03:43",
          "username": "blackgamer",
          "content": "CAF for me.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 414614,
          "date": "Tue 02 Nov 2021 07:41",
          "username": "mericov",
          "content": "ACF https://blogs.halodoc.io/implementation-of-custom-header-to-origin-requests/",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 407383,
          "date": "Mon 01 Nov 2021 19:46",
          "username": "Akhil254",
          "content": "ACF Correct",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 396058,
          "date": "Mon 01 Nov 2021 19:08",
          "username": "MrCarter",
          "content": "Official explanation:<br>The option that says: Use CloudFront to add a custom header to all origin requests. Using AWS WAF, create a web rule that denies all requests without this custom header. Associate the web ACL to the CloudFront distribution is incorrect. If any new requests are going to CloudFront, they won't have the custom header initially so AWS WAF may block the request immediately. This could deny any new connections to CloudFront. Therefore, you need to associate the web ACL to the ALB, which is after the CloudFront adds the custom header.",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#675",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has multiple lines of business (LOBs) that roll up to the parent company. The company has asked its solutions architect to develop a solution with the following requirements:<br>✑ Produce a single AWS invoice for all of the AWS accounts used by its LOBs.<br>✑ The costs for each LOB account should be broken out on the invoice.<br>✑ Provide the ability to restrict services and features in the LOB accounts, as defined by the company's governance policy.<br>✑ Each LOB account should be delegated full administrator permissions, regardless of the governance policy.<br>Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#675",
          "answers": [
            {
              "choice": "<p>A. Use AWS Organizations to create an organization in the parent account for each LOB.  Then, invite each LOB account to the appropriate organization.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use AWS Organizations to create a single organization in the parent account. Then, invite each LOB's AWS account to pin the organization.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Implement service quotas to define the services and features that are permitted and apply the quotas to each LOB as appropriate.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create an SCP that allows only approved services and features, then apply the policy to the LOB accounts. Enable consolidated billing in the parent account's billing console and link the LOB accounts.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 216415,
          "date": "Sat 25 Sep 2021 19:28",
          "username": "keos",
          "content": "BD, most likely",
          "upvote_count": "23",
          "selected_answers": ""
        },
        {
          "id": 284492,
          "date": "Wed 13 Oct 2021 15:00",
          "username": "Ebi",
          "content": "BD is my choice",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 648356,
          "date": "Thu 18 Aug 2022 10:34",
          "username": "gnic",
          "content": "BD is the right question",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 562502,
          "date": "Mon 07 Mar 2022 10:25",
          "username": "Dohecadi",
          "content": "Choice is between A and B for Organizations, and A is wrong. You cannot belong to more than one organization.<br>For permissions, coice is between C and D, and C is wrong. SCP is right.",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 516119,
          "date": "Mon 03 Jan 2022 23:56",
          "username": "Buggie",
          "content": "SCP can be applied to OU. NO other choice. hence A and D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 495950,
          "date": "Tue 07 Dec 2021 13:15",
          "username": "cldy",
          "content": "B.  Use AWS Organizations to create a single organization in the parent account. Then, invite each LOBג€™s AWS account to pin the organization.<br>D.  Create an SCP that allows only approved services and features, then apply the policy to the LOB accounts. Enable consolidated billing in the parent accountג€™s billing console and link the LOB accounts.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 488548,
          "date": "Sat 27 Nov 2021 23:47",
          "username": "AzureDP900",
          "content": "B, D is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 483082,
          "date": "Sun 21 Nov 2021 08:36",
          "username": "acloudguru",
          "content": "C is not right, should be BD. ",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 483081,
          "date": "Sun 21 Nov 2021 08:36",
          "username": "acloudguru",
          "content": "A rare simple question, BD hope I can have it in my exam",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446050,
          "date": "Sat 06 Nov 2021 17:36",
          "username": "andylogan",
          "content": "It's B D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 441575,
          "date": "Tue 02 Nov 2021 06:39",
          "username": "wakamewakame",
          "content": "Not B<br>This question says \\\"Produce a single AWS invoice for all of the AWS accounts used by its LOBs.\\\" and consolidated billing put together billing for accounts in an organization.<br>So B is wrong.<br>The answer is A and D. I made a mistake.<br>consolidated billing put together billing for accounts in an organization so The answer is BD. ",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 441579,
          "date": "Thu 04 Nov 2021 08:47",
          "username": "wakame",
          "content": "I made a mistake.<br>consolidated billing put together billing for accounts in an organization so The answer is BD. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 439111,
          "date": "Tue 02 Nov 2021 02:09",
          "username": "DerekKey",
          "content": "A wrong - correct but adds additional management overhead later. In this scenario we must assure: ability to restrict services and features in the LOB accounts, as defined by the company's governance policy. Same policy/restrictions for all.<br>B correct - and more suited to this case (simplification of management)<br>C wrong - quotas<br>D correct<br>E wrong - billing is by default. The other option is full features meaning billing and management. Btw. if you start with billing you can go up but this is one way process.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436533,
          "date": "Thu 28 Oct 2021 11:10",
          "username": "tgv",
          "content": "BBB DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433927,
          "date": "Sun 24 Oct 2021 14:51",
          "username": "blackgamer",
          "content": "BD but weird question.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413466,
          "date": "Thu 21 Oct 2021 16:25",
          "username": "WhyIronMan",
          "content": "I'll go with B,D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 359912,
          "date": "Thu 21 Oct 2021 15:23",
          "username": "digimaniacDerekKey",
          "content": "Can someone comment on \\\"Each LOB account should be delegated full administrator permissions, regardless of the governance policy.\\\" I think only A can satisfy this one.it doesn't matter if you have one org or many orgs. The process of registering delegated account uses account it and service principal. It means that this procedure works directly on an account.",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 439105,
          "date": "Sun 31 Oct 2021 12:38",
          "username": "DerekKey",
          "content": "it doesn't matter if you have one org or many orgs. The process of registering delegated account uses account it and service principal. It means that this procedure works directly on an account.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357130,
          "date": "Wed 20 Oct 2021 21:01",
          "username": "Waiweng",
          "content": "it's B,D",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#676",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>An ecommerce website running on AWS uses an Amazon RDS for MySQL DB instance with General Purpose SSD storage. The developers chose an appropriate instance type based on demand, and configured 100 GB of storage with a sufficient amount of free space.<br>The website was running smoothly for a few weeks until a marketing campaign launched. On the second day of the campaign, users reported long wait times and time outs. Amazon CloudWatch metrics indicated that both reads and writes to the DB instance were experiencing long response times. The CloudWatch metrics show 40% to 50% CPU and memory utilization, and sufficient free storage space is still available. The application server logs show no evidence of database connectivity issues.<br>What could be the root cause of the issue with the marketing campaign?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: A</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#676",
          "answers": [
            {
              "choice": "<p>A. It exhausted the I/O credit balance due to provisioning low disk storage during the setup phase.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. It caused the data in the tables to change frequently, requiring indexes to be rebuilt to optimize queries.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. It exhausted the maximum number of allowed connections to the database instance.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. It exhausted the network bandwidth available to the RDS for MySQL DB instance.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 216342,
          "date": "Tue 21 Sep 2021 10:10",
          "username": "bbnbnuyhCantaloupe",
          "content": "A.  100G GP2 is going to give roughtly 300 IOPS which is too lowYes. There is burst option but it can be exhausted<br>\\\"When using General Purpose SSD storage, your DB instance receives an initial I/O credit balance of 5.4 million I/O credits. This initial credit balance is enough to sustain a burst performance of 3,000 IOPS for 30 minutes.\\\"",
          "upvote_count": "276",
          "selected_answers": ""
        },
        {
          "id": 240677,
          "date": "Sun 26 Sep 2021 14:26",
          "username": "Cantaloupe",
          "content": "Yes. There is burst option but it can be exhausted<br>\\\"When using General Purpose SSD storage, your DB instance receives an initial I/O credit balance of 5.4 million I/O credits. This initial credit balance is enough to sustain a burst performance of 3,000 IOPS for 30 minutes.\\\"",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 284497,
          "date": "Fri 08 Oct 2021 11:34",
          "username": "Ebi",
          "content": "Answer is A,<br>Key is \\\"on the second day\\\", so all the credit have been used by then",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 634589,
          "date": "Thu 21 Jul 2022 14:35",
          "username": "5kk",
          "content": "A looks good.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 595552,
          "date": "Sun 01 May 2022 12:19",
          "username": "pankajrawat",
          "content": "A looks good",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 492149,
          "date": "Thu 02 Dec 2021 05:52",
          "username": "AzureDP900",
          "content": "A is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488872,
          "date": "Sun 28 Nov 2021 07:10",
          "username": "backfringe",
          "content": "I'd go with A",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488626,
          "date": "Sun 28 Nov 2021 01:57",
          "username": "AzureDP900Cal88",
          "content": "Before even reading answers my best bet was A.  I am with you guys, I am not sure why they want to fool us with C. This is one of the reason knowing concepts is very important rather than depending on answers :)An easy way to eliminate C is to read the question carefully<br>“The application server logs show no evidence of database connectivity issues.“<br>So there are no connectivity issues <br>I really hope that I read the questions carefully in my exam and not jump to any conclusions quickly",
          "upvote_count": "12",
          "selected_answers": ""
        },
        {
          "id": 709100,
          "date": "Tue 01 Nov 2022 13:14",
          "username": "Cal88",
          "content": "An easy way to eliminate C is to read the question carefully<br>“The application server logs show no evidence of database connectivity issues.“<br>So there are no connectivity issues <br>I really hope that I read the questions carefully in my exam and not jump to any conclusions quickly",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 482977,
          "date": "Sun 21 Nov 2021 02:59",
          "username": "acloudguru",
          "content": "There is burst option but it can be exhausted<br>\\\"When using General Purpose SSD storage, your DB instance receives an initial I/O credit balance of 5.4 million I/O credits. This initial credit balance is enough to sustain a burst performance of 3,000 IOPS for 30 minutes.\\\"",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 446233,
          "date": "Sat 06 Nov 2021 22:34",
          "username": "andylogan",
          "content": "It's A - exhausted allits initialI/O credits on the second day",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435260,
          "date": "Fri 05 Nov 2021 01:40",
          "username": "tgv",
          "content": "AAA<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433928,
          "date": "Wed 03 Nov 2021 00:33",
          "username": "blackgamer",
          "content": "A is the answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 416873,
          "date": "Sat 23 Oct 2021 19:57",
          "username": "jobe42",
          "content": "A Emerging similar happened Touch us.. So I've learned shout EBS burstable balance",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413467,
          "date": "Sat 23 Oct 2021 11:10",
          "username": "WhyIronMan",
          "content": "I'll go with A",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 366780,
          "date": "Thu 14 Oct 2021 22:52",
          "username": "mustpassla",
          "content": "A, a typical SAP IOPS related question",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357133,
          "date": "Sun 10 Oct 2021 04:55",
          "username": "Waiweng",
          "content": "it's A",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 294241,
          "date": "Fri 08 Oct 2021 16:52",
          "username": "Kian1",
          "content": "going with A",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 256986,
          "date": "Fri 08 Oct 2021 11:09",
          "username": "Bulti",
          "content": "A is the right answer. It must have exhausted all its I/O credits due to the marketing event and now operates with 300 IOPS which is pretty low for that event.",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#677",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A solutions architect has been assigned to migrate a 50 TB Oracle data warehouse that contains sales data from on-premises to Amazon Redshift. Major updates to the sales data occur on the final calendar day of the month. For the remainder of the month, the data warehouse only receives minor daily updates and is primarily used for reading and reporting. Because of this, the migration process must start on the first day of the month and must be complete before the next set of updates occur. This provides approximately 30 days to complete the migration and ensure that the minor daily changes have been synchronized with the<br>Amazon Redshift data warehouse. Because the migration cannot impact normal business network operations, the bandwidth allocated to the migration for moving data over the internet is 50 Mbps. The company wants to keep data migration costs low.<br>Which steps will allow the solutions architect to perform the migration within the specified timeline?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: D</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#677",
          "answers": [
            {
              "choice": "<p>A. Install Oracle database software on an Amazon EC2 instance. Configure VPN connectivity between AWS and the company's data center. Configure the Oracle database running on Amazon EC2 to join the Oracle Real Application Clusters (RAC). When the Oracle database on Amazon EC2 finishes synchronizing, create an AWS DMS ongoing replication task to migrate the data from the Oracle database on Amazon EC2 to Amazon Redshift. Verify the data migration is complete and perform the cut over to Amazon Redshift.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an AWS Snowball import job. Export a backup of the Oracle data warehouse. Copy the exported data to the Snowball device. Return the Snowball device to AWS. Create an Amazon RDS for Oracle database and restore the backup file to that RDS instance. Create an AWS DMS task to migrate the data from the RDS for Oracle database to Amazon Redshift. Copy daily incremental backups from Oracle in the data center to the RDS for Oracle database over the internet. Verify the data migration is complete and perform the cut over to Amazon Redshift.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Install Oracle database software on an Amazon EC2 instance. To minimize the migration time, configure VPN connectivity between AWS and the company's data center by provisioning a 1 Gbps AWS Direct Connect connection. Configure the Oracle database running on Amazon EC2 to be a read replica of the data center Oracle database. Start the synchronization process between the company's on-premises data center and the Oracle database on Amazon EC2. When the Oracle database on Amazon EC2 is synchronized with the on-premises database, create an AWS DMS ongoing replication task to migrate the data from the Oracle database read replica that is running on Amazon EC2 to Amazon Redshift. Verify the data migration is complete and perform the cut over to Amazon Redshift.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create an AWS Snowball import job. Configure a server in the company's data center with an extraction agent. Use AWS SCT to manage the extraction agent and convert the Oracle schema to an Amazon Redshift schema. Create a new project in AWS SCT using the registered data extraction agent. Create a local task and an AWS DMS task in AWS SCT with replication of ongoing changes. Copy data to the Snowball device and return the Snowball device to AWS. Allow AWS DMS to copy data from Amazon S3 to Amazon Redshift. Verify that the data migration is complete and perform the cut over to Amazon Redshift.<br></p>",
              "correct": true,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 214578,
          "date": "Mon 20 Sep 2021 09:26",
          "username": "lionokirrimsangkhuu",
          "content": "D is correct, you need Snowball for the size of the DB, SCT for converting from oracle to redshift and DMS for migration job<br>https://aws.amazon.com/getting-started/hands-on/migrate-oracle-to-amazon-redshift/50TB to transfer<br>- Transmitting over 50Mbps VPN ~ 90 days, not going to work<br>- Transmitting over 1Gbps DX ~ 4.3 days, but ~ 60 days to provision circuit, not going to work<br><br>A and C are automatically ruled out<br><br>- Transmitting via Snowball (Edge) ~ 3-5 days, can hold up to 80TB usable disk, feasible<br><br>Between B and D, difference is around whether to use SCT and DMS to Snowball in your datacenter, then move to AWS.Or, copy to Snowball in data center, move to AWS, then do DMS WITHOUT SCT within AWS.Clearly, you need SCT to go from Oracle to Redshift, so it has to be D<br><br>https://docs.aws.amazon.com/SchemaConversionTool/latest/userguide/agents.dw.htmlgreat explain!",
          "upvote_count": "2671",
          "selected_answers": ""
        },
        {
          "id": 463587,
          "date": "Sat 06 Nov 2021 22:51",
          "username": "kirrimsangkhuu",
          "content": "50TB to transfer<br>- Transmitting over 50Mbps VPN ~ 90 days, not going to work<br>- Transmitting over 1Gbps DX ~ 4.3 days, but ~ 60 days to provision circuit, not going to work<br><br>A and C are automatically ruled out<br><br>- Transmitting via Snowball (Edge) ~ 3-5 days, can hold up to 80TB usable disk, feasible<br><br>Between B and D, difference is around whether to use SCT and DMS to Snowball in your datacenter, then move to AWS.Or, copy to Snowball in data center, move to AWS, then do DMS WITHOUT SCT within AWS.Clearly, you need SCT to go from Oracle to Redshift, so it has to be D<br><br>https://docs.aws.amazon.com/SchemaConversionTool/latest/userguide/agents.dw.htmlgreat explain!",
          "upvote_count": "71",
          "selected_answers": ""
        },
        {
          "id": 697536,
          "date": "Mon 17 Oct 2022 17:46",
          "username": "sangkhuu",
          "content": "great explain!",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 274472,
          "date": "Wed 06 Oct 2021 04:00",
          "username": "hkwong",
          "content": "D.  SCT is a must for converting Oracle DATA WAREHOUSE to Redshift",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 610455,
          "date": "Thu 02 Jun 2022 07:45",
          "username": "Anhdd",
          "content": "I wonder that if we choose Snow Ball as the solution. It's perfect, but the time when we ship back to AWS (1 week maybe), on-premis data are not being synced. While the question requires that \\\"guarantee that small daily updates are synced with the Amazon Redshift data warehouse\\\" ? How this can be complete?",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 571030,
          "date": "Sat 19 Mar 2022 12:44",
          "username": "leoluo2020",
          "content": "mark D",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 499894,
          "date": "Sun 12 Dec 2021 10:09",
          "username": "palace",
          "content": "For a Oracle database running in the AWS Cloud on \\\"Target architecture\\\" SCT is not printed.<br>https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/migrate-an-oracle-database-to-amazon-redshift-using-aws-dms-and-aws-sct.html<br>With D the changes of the month will be lost.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 495732,
          "date": "Tue 07 Dec 2021 08:34",
          "username": "cldy",
          "content": "D.  Create an AWS Snowball import job. Configure a server in the companyג€™s data center with an extraction agent. Use AWS SCT to manage the extraction agent and convert the Oracle schema to an Amazon Redshift schema. Create a new project in AWS SCT using the registered data extraction agent. Create a local task and an AWS DMS task in AWS SCT with replication of ongoing changes. Copy data to the Snowball device and return the Snowball device to AWS. Allow AWS DMS to copy data from Amazon S3 to Amazon Redshift. Verify that the data migration is complete and perform the cut over to Amazon Redshift.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 491300,
          "date": "Wed 01 Dec 2021 06:41",
          "username": "backfringe",
          "content": "I go with D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488628,
          "date": "Sun 28 Nov 2021 02:01",
          "username": "AzureDP900",
          "content": "I just thought about D and all the candidates mentioned same. I am getting ready for exam :)",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 483003,
          "date": "Sun 21 Nov 2021 05:03",
          "username": "acloudguru",
          "content": "since it is Oracle to Redshit, it needs SCT. scan for the key word SCT and answer is D.  50T through network is impossible for A to finish in 30days, snowball is a must.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 449201,
          "date": "Thu 04 Nov 2021 07:56",
          "username": "moon2351",
          "content": "Answer is D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446234,
          "date": "Wed 03 Nov 2021 04:40",
          "username": "andylogan",
          "content": "It's D - for Oracle to Redshit, it needs SCT",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 439131,
          "date": "Sun 31 Oct 2021 06:57",
          "username": "DerekKey",
          "content": "Requirements:<br>1. \\\"the data warehouse only receives minor daily updates and is primarily used for reading and reporting\\\"<br>2. \\\"ensure that the minor daily changes have been synchronized with the<br>Amazon Redshift data warehouse\\\"<br><br>D - how would you make it working if Snowball will travel to AWS for 3-4 days and 1 day more will be spent on restoring database?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436535,
          "date": "Fri 29 Oct 2021 20:09",
          "username": "tgv",
          "content": "DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433934,
          "date": "Fri 29 Oct 2021 15:02",
          "username": "blackgamer",
          "content": "Only D makes sense, but the solution is not written very clearly.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433366,
          "date": "Thu 28 Oct 2021 14:27",
          "username": "Suresh108",
          "content": "This is question is so long and big as 50TB.  :D<br><br>since it is Oracle to Redshit, it needs SCT. scan for the key word SCT and answer is D. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 428281,
          "date": "Mon 25 Oct 2021 02:07",
          "username": "denccc",
          "content": "D: https://docs.aws.amazon.com/SchemaConversionTool/latest/userguide/agents.dw.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413468,
          "date": "Wed 20 Oct 2021 03:21",
          "username": "WhyIronMan",
          "content": "I'll go with D",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#678",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A solutions architect is designing a disaster recovery strategy for a three-tier application. The application has an RTO of 30 minutes and an RPO of 5 minutes for the data tier. The application and web tiers are stateless and leverage a fleet of Amazon EC2 instances. The data tier consists of a 50 TB Amazon Aurora database.<br>Which combination of steps satisfies the RTO and RPO requirements while optimizing costs? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#678",
          "answers": [
            {
              "choice": "<p>A. Create daily snapshots of the EC2 instances and replicate the snapshots to another Region.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Deploy a hot standby of the application to another Region.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create snapshots of the Aurora database every 5 minutes.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a cross-Region Aurora Replica of the database.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Create an AWS Backup job to replicate data to another Region.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 219199,
          "date": "Sat 25 Sep 2021 02:49",
          "username": "cpdstudent22tgvMikeyJ",
          "content": "Question is asking for: RTO of 30 minutes and an RPO of 5<br>RPO\t\t\tRTO\t\t->mode<br>24\t\t\t\t24hr\t\t->\tbackup<br>12\t\t\t\t4hr\t\t->pilot light<br>1.4\t\t\t\t15min\t\t->warm standup<br>15min\t\t\t5min\t\t->active-active<br>B because of above ^<br>D is obviousA,D<br>RPO/RTO is for the data tier.As this might be the general best practice, the question is asking to optimize costs and I think we can easily achieve the RTO / RPO with option AMy thinking too. If it hadn't specifically mentioned costs I would have said B. ",
          "upvote_count": "27341",
          "selected_answers": ""
        },
        {
          "id": 439476,
          "date": "Thu 04 Nov 2021 19:05",
          "username": "student22",
          "content": "A,D<br>RPO/RTO is for the data tier.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 435264,
          "date": "Tue 02 Nov 2021 12:06",
          "username": "tgvMikeyJ",
          "content": "As this might be the general best practice, the question is asking to optimize costs and I think we can easily achieve the RTO / RPO with option AMy thinking too. If it hadn't specifically mentioned costs I would have said B. ",
          "upvote_count": "41",
          "selected_answers": ""
        },
        {
          "id": 647064,
          "date": "Mon 15 Aug 2022 09:15",
          "username": "MikeyJ",
          "content": "My thinking too. If it hadn't specifically mentioned costs I would have said B. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 284426,
          "date": "Tue 19 Oct 2021 02:45",
          "username": "Ebi",
          "content": "I go with AD",
          "upvote_count": "22",
          "selected_answers": ""
        },
        {
          "id": 689933,
          "date": "Sun 09 Oct 2022 08:17",
          "username": "JohnPi",
          "content": "https://aws.amazon.com/blogs/architecture/disaster-recovery-dr-architecture-on-aws-part-iii-pilot-light-and-warm-standby/",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 687148,
          "date": "Wed 05 Oct 2022 20:46",
          "username": "psou7",
          "content": "I will go with A/D. <br>The question highlights \\\"optimizing costs\\\". B - Hot standby would work but is more expensive.<br>RTO and RPO is for data and D covers that.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 648685,
          "date": "Fri 19 Aug 2022 03:53",
          "username": "Kyperos",
          "content": "Because of \\\"The application and web layers are stateless\\\" so dont have any data stored in EC2 Instance. If application dont have multiple deployments in a day, option A is cost effective. Cross-Region Aurora will effect to RPO/RTO and meet requirements. --> AD are best options!",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 638388,
          "date": "Thu 28 Jul 2022 04:12",
          "username": "hilft",
          "content": "C and D is right answer.<br>A is non sense 24 hours \\\"DAILY\\\"",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 638387,
          "date": "Thu 28 Jul 2022 04:11",
          "username": "hilft",
          "content": "A is wrong. daily snapshot won't be enough for 30min/5min",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 625902,
          "date": "Sat 02 Jul 2022 04:30",
          "username": "aandc",
          "content": "AD, RTO & RPO only for Data tier,",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 623796,
          "date": "Tue 28 Jun 2022 08:49",
          "username": "TechX",
          "content": "AD for me<br>B will work but it's too expensive cause you have active-active model, and the RTO and RPO within only minute, while the question say that it's can up to 30 minutes. A will work and more cost effective",
          "upvote_count": "4",
          "selected_answers": "Selected Answer: AD"
        },
        {
          "id": 571623,
          "date": "Sun 20 Mar 2022 14:42",
          "username": "gorodetsky",
          "content": "B,D https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/plan-for-disaster-recovery-dr.html",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 555729,
          "date": "Fri 25 Feb 2022 04:23",
          "username": "good_tea",
          "content": "I go with BD<br>https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/plan-for-disaster-recovery-dr.html",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 544451,
          "date": "Thu 10 Feb 2022 11:30",
          "username": "lifebegins",
          "content": "Answer is B & D<br>Hot Standby is the correct answer: <br><br>Because, if we have fleet of EC2 Instances, which are stateless, why even we are taking snapshots. Suppost, if we have 5 instance in app later, 10 instances in BL, what is the use of taking the snapshot of the disk of App Layes which is stateless, instead of that, we can maintain thin layer of Hot Standby 1 instance in Web, 1 instance in BL behind autoscaling group with Cross Replication of Aurora, we can bring the entire layer with in few minutesby standing up the instance by Cloud Formation with the DR database:<br><br>https://www.wellarchitectedlabs.com/reliability/disaster-recovery/workshop_4/<br><br>https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database-disaster-recovery.html",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 527871,
          "date": "Wed 19 Jan 2022 20:57",
          "username": "Ni_yot",
          "content": "Will go with B and D. The host standby solves the 30minRTO and the DB cross replication solves the 5min RPO",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 519794,
          "date": "Sat 08 Jan 2022 23:14",
          "username": "CloudChef",
          "content": "B and D as stated on Digital Cloud Training.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 488633,
          "date": "Sun 28 Nov 2021 02:11",
          "username": "AzureDP900",
          "content": "I'll go with A,D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 480615,
          "date": "Thu 18 Nov 2021 11:43",
          "username": "Kopa",
          "content": "The prob with A to be copied this snapshot in 5 min?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 477738,
          "date": "Sat 13 Nov 2021 22:00",
          "username": "sashenkappandey96sashenkasashenkatomosabc1",
          "content": "BBB D.  Same exact question appears on the Tutorials Dojo test which has moderators and good credibility and their answer is [B]D with the explanation that it may take longer than 30 min to get the snapshot back up and running especially if there is manual intervention. Picture that a regional outage happens in the middle of the night on a weekend or holiday. What is the likelihood that someone can get an EC2 instance restored from a snapshot and fully operational from the time the region goes out. If you were the person responsible for that 30 min RTO SLA would you put YOUR JOB on the line? I too was inclined to select AD but the more I understand the explanation I can agree with BD. RPO and RTOis for data layer notapplicationAnd to make the 30 min RTO window even more critical is this, \\\"application and web layers are stateless and run on an Amazon EC2 fleet of instances\\\". Can one truly recover an EC2 fleet for both the Web and App tiers(we don't know how many but it sounds like more than a couple\\\" from a snapshot within 30 min from the time we have a failure?Take a look at the following guidance:<br>https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/plan-for-disaster-recovery-dr.html<br>What [A][D] describe is a Pilot light (RPO in minutes, RTO in hours) which DOES NOT MEET THE REQUIREMENTS: Replicate your data from one region to another and provision a copy of your core workload infrastructure. Resources required to support data replication and backup such as databases and object storage are always on. Other elements such as application servers are loaded with application code and configurations, but are switched off and are only used during testing or when Disaster Recovery failover is invoked.<br><br>What's needed here is Warm standby (RPO in seconds, RTO in minutes) but since that is not available the only valid option is [B][D] .Obviously, you don't understand what ppandey96 mean by his/her comment. Please read carefully.",
          "upvote_count": "31111",
          "selected_answers": ""
        },
        {
          "id": 526026,
          "date": "Mon 17 Jan 2022 20:13",
          "username": "ppandey96",
          "content": "RPO and RTOis for data layer notapplication",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 477741,
          "date": "Sat 13 Nov 2021 22:04",
          "username": "sashenkasashenkatomosabc1",
          "content": "And to make the 30 min RTO window even more critical is this, \\\"application and web layers are stateless and run on an Amazon EC2 fleet of instances\\\". Can one truly recover an EC2 fleet for both the Web and App tiers(we don't know how many but it sounds like more than a couple\\\" from a snapshot within 30 min from the time we have a failure?Take a look at the following guidance:<br>https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/plan-for-disaster-recovery-dr.html<br>What [A][D] describe is a Pilot light (RPO in minutes, RTO in hours) which DOES NOT MEET THE REQUIREMENTS: Replicate your data from one region to another and provision a copy of your core workload infrastructure. Resources required to support data replication and backup such as databases and object storage are always on. Other elements such as application servers are loaded with application code and configurations, but are switched off and are only used during testing or when Disaster Recovery failover is invoked.<br><br>What's needed here is Warm standby (RPO in seconds, RTO in minutes) but since that is not available the only valid option is [B][D] .Obviously, you don't understand what ppandey96 mean by his/her comment. Please read carefully.",
          "upvote_count": "111",
          "selected_answers": ""
        },
        {
          "id": 477754,
          "date": "Sat 13 Nov 2021 22:25",
          "username": "sashenkatomosabc1",
          "content": "Take a look at the following guidance:<br>https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/plan-for-disaster-recovery-dr.html<br>What [A][D] describe is a Pilot light (RPO in minutes, RTO in hours) which DOES NOT MEET THE REQUIREMENTS: Replicate your data from one region to another and provision a copy of your core workload infrastructure. Resources required to support data replication and backup such as databases and object storage are always on. Other elements such as application servers are loaded with application code and configurations, but are switched off and are only used during testing or when Disaster Recovery failover is invoked.<br><br>What's needed here is Warm standby (RPO in seconds, RTO in minutes) but since that is not available the only valid option is [B][D] .Obviously, you don't understand what ppandey96 mean by his/her comment. Please read carefully.",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 693354,
          "date": "Wed 12 Oct 2022 21:50",
          "username": "tomosabc1",
          "content": "Obviously, you don't understand what ppandey96 mean by his/her comment. Please read carefully.",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#679",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has a primary Amazon S3 bucket that receives thousands of objects every day. The company needs to replicate these objects into several other S3 buckets from various AWS accounts. A solutions architect is designing a new AWS Lambda function that is triggered when an object is created in the main bucket and replicates the object into the target buckets. The objects do not need to be replicated in real time. There is concern that this function may impact other critical<br>Lambda functions due to Lambda's regional concurrency limit.<br>How can the solutions architect ensure this new Lambda function will not impact other critical Lambda functions?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#679",
          "answers": [
            {
              "choice": "<p>A. Set the new Lambda function reserved concurrency limit to ensure the executions do not impact other critical Lambda functions. Monitor existing critical Lambda functions with Amazon CloudWatch alarms for the Throttles Lambda metric.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Increase the execution timeout of the new Lambda function to 5 minutes. Monitor existing critical Lambda functions with Amazon CloudWatch alarms for the Throttles Lambda metric.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Configure S3 event notifications to add events to an Amazon SQS queue in a separate account. Create the new Lambda function in the same account as the SQS queue and trigger the function when a message arrives in the queue.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Ensure the new Lambda function implements an exponential backoff algorithm. Monitor existing critical Lambda functions with Amazon CloudWatch alarms for the Throttles Lambda metric.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 215118,
          "date": "Sun 19 Sep 2021 18:49",
          "username": "lionogerhardblcpdrscloudkirrim",
          "content": "A is correct, <br>https://aws.amazon.com/blogs/compute/managing-aws-lambda-function-concurrency/But those other Lambda functions would now be running in different accounts where the target buckets are, hence there would be no impact on the 'key' Lambdas in the main account. Also by using Lambda to process SQS, it will pull multiple messages off the queue at once, instead of firing up a new concurrent Lambda for every object that needs to be copied. Lastly, if you set a Reserved Concurrency limit on the Lambdas that process these large quantities of S3 uploads, and the limit is hit, you will start losing data and your buckets will be out of sync. I think just using Reserved Concurrency is too simple here; they are looking for one step further.Thank you, very nice blog.Thankyou, very informative blog!<br>A is correctAgree!<br><br>Another document supporting A:<br><br>https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html<br><br>\\\"Your function can't scale out of control – Reserved concurrency also limits your function from using concurrency from the unreserved pool, which caps its maximum concurrency. You can reserve concurrency to prevent your function from using all the available concurrency in the Region, or from overloading downstream resources.\\\"",
          "upvote_count": "251121",
          "selected_answers": ""
        },
        {
          "id": 649327,
          "date": "Sat 20 Aug 2022 09:52",
          "username": "gerhardbl",
          "content": "But those other Lambda functions would now be running in different accounts where the target buckets are, hence there would be no impact on the 'key' Lambdas in the main account. Also by using Lambda to process SQS, it will pull multiple messages off the queue at once, instead of firing up a new concurrent Lambda for every object that needs to be copied. Lastly, if you set a Reserved Concurrency limit on the Lambdas that process these large quantities of S3 uploads, and the limit is hit, you will start losing data and your buckets will be out of sync. I think just using Reserved Concurrency is too simple here; they are looking for one step further.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 219205,
          "date": "Tue 21 Sep 2021 01:17",
          "username": "cpd",
          "content": "Thank you, very nice blog.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 246063,
          "date": "Fri 24 Sep 2021 11:11",
          "username": "rscloud",
          "content": "Thankyou, very informative blog!<br>A is correct",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 463596,
          "date": "Sun 07 Nov 2021 06:16",
          "username": "kirrim",
          "content": "Agree!<br><br>Another document supporting A:<br><br>https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html<br><br>\\\"Your function can't scale out of control – Reserved concurrency also limits your function from using concurrency from the unreserved pool, which caps its maximum concurrency. You can reserve concurrency to prevent your function from using all the available concurrency in the Region, or from overloading downstream resources.\\\"",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 289791,
          "date": "Sun 26 Sep 2021 17:22",
          "username": "PredaOvdecannottellname",
          "content": "I choose C.  Let me explain why I don't think A is the right approach: if you set Reserved concurrency to let's say 200, I make myself 2 questions:<br>1) 800 instances will remain available for other lambdas. How do you guarantee 800 is enough for other lambdas? Perhaps 999 lambdas was answering in a timely manner to all the requests and adding a new lambda will break everything.<br>2) Assigning 200 Reserved instances to the new Lambda does not guarantee that will be enough for the new Lambda. Maybe it requires 500? <br><br>So, adding SQS queue resolve both of the problems. Thoughts?I believe SQS queue + Lamda Reserve will help solve the issue. Not keeping Lambda limit/reserve have a chance that concurrency is fully utilized by this only.",
          "upvote_count": "142",
          "selected_answers": ""
        },
        {
          "id": 542829,
          "date": "Tue 08 Feb 2022 03:56",
          "username": "cannottellname",
          "content": "I believe SQS queue + Lamda Reserve will help solve the issue. Not keeping Lambda limit/reserve have a chance that concurrency is fully utilized by this only.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 721419,
          "date": "Fri 18 Nov 2022 17:38",
          "username": "timmysixstrings",
          "content": "This is what reserved concurrency is for",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 716006,
          "date": "Fri 11 Nov 2022 12:28",
          "username": "Amsa",
          "content": "Straight from Jon Bonso tests and correct answer is A. <br>Explanation:<br><br>Concurrency is the number of requests that your function is serving at any given time. When your function is invoked, Lambda allocates an instance of it to process the event. When the function code finishes running, it can handle another request. If the function is invoked again while a request is still being processed, another instance is allocated, which increases the function's concurrency. Concurrency is subject to a Regional quota that is shared by all functions in a Region.<br><br>There are two types of concurrency available:<br><br>Reserved concurrency – Reserved concurrency creates a pool of requests that can only be used by its function, and also prevents its function from using unreserved concurrency.<br><br>Provisioned concurrency – Provisioned concurrency initializes a requested number of execution environments so that they are prepared to respond to your function's invocations.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 660250,
          "date": "Mon 05 Sep 2022 16:07",
          "username": "astalavista1",
          "content": "\\\"The objects do not need to be processed in real-time\\\" - SQS gives you the option to process in batches, you can also delay delivery to ensure Lambda isn't swarmed with multiple concurrent executions from the object upload.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 624998,
          "date": "Thu 30 Jun 2022 04:33",
          "username": "jyrajan69",
          "content": "Key point, addition of this new Lambda function has no adverse effect on other key Lambda functions? So how does C address that? Only A provides and answer with reserved concurrency",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 615262,
          "date": "Sun 12 Jun 2022 12:31",
          "username": "azurehunter",
          "content": "Answer is A. <br><br>C is wrong because the Lamdba functions which read the message from SQS may scale out to 1000 if hundreds of thousands of upload occur in a very short time. It will impact the other Lamdba functions.<br><br>Refer to https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 577853,
          "date": "Tue 29 Mar 2022 22:21",
          "username": "jj22222",
          "content": "C.  Configure S3 event notifications to add events to an Amazon SQS queue in a separate account. Create the new Lambda function in the same account as the SQS queue and trigger the function when a message arrives in the queue.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 547895,
          "date": "Tue 15 Feb 2022 18:12",
          "username": "pititcu667",
          "content": "I think A is correct.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 532393,
          "date": "Tue 25 Jan 2022 21:29",
          "username": "shotty1",
          "content": "I think this is C",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 528338,
          "date": "Thu 20 Jan 2022 11:53",
          "username": "tkanmani76",
          "content": "C is right - The concurrency space available is common for all the functions in the region. By reserving concurrency for a function we ensure no other function can use that concurrency space. However this limits the ability to use the concurrency from open pool.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 498694,
          "date": "Fri 10 Dec 2021 15:27",
          "username": "cldy",
          "content": "C.  Configure S3 event notifications to add events to an Amazon SQS queue in a separate account. Create the new Lambda function in the same account as the SQS queue and trigger the function when a message arrives in the queue.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492152,
          "date": "Thu 02 Dec 2021 05:59",
          "username": "AzureDP900",
          "content": "I am going with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 490415,
          "date": "Tue 30 Nov 2021 05:54",
          "username": "kaleen_bhaiya",
          "content": "Answer is C, only C assures to copy all the. files, if you throttle the Lambda many of the copy requests will fail. And there is no need to have synchronous copying of data.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 450780,
          "date": "Sun 07 Nov 2021 02:00",
          "username": "student22",
          "content": "A<br>---<br>The question mentions \\\"The objects do not need to be replicated in real time.\\\", hinting at A. <br>C is too much work.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446428,
          "date": "Sat 06 Nov 2021 15:44",
          "username": "andylogan",
          "content": "It's A",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 439170,
          "date": "Thu 04 Nov 2021 18:24",
          "username": "DerekKey",
          "content": "Question is:<br>\\\"How can the solutions architect ensure this new Lambda function will not impact other critical Lambda functions?\\\"<br>WILL NOT IMPACT<br>Any usage of the new replication lambda in current account will impact critical Lambda functions.<br>C is CORRECT in my opinion",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#680",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company wants to run a serverless application on AWS. The company plans to provision its application in Docker containers running in an Amazon ECS cluster.<br>The application requires a MySQL database and the company plans to use Amazon RDS. The company has documents that need to be accessed frequently for the first 3 months, and rarely after that. The document must be retained for 7 years.<br>What is the MOST cost-effective solution to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#680",
          "answers": [
            {
              "choice": "<p>A. Create an ECS cluster using On-Demand Instances. Provision the database and its read replicas in Amazon RDS using Spot Instances. Store the documents in an encrypted EBS volume, and create a cron job to delete the documents after 7 years.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an ECS cluster using a fleet of Spot Instances, with Spot Instance draining enabled. Provision the database and its read replicas in Amazon RDS using Reserved Instances. Store the documents in a secured Amazon S3 bucket with a lifecycle policy to move the documents that are older than 3 months to Amazon S3 Glacier, then delete the documents from Amazon S3 Glacier that are more than 7 years old.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create an ECS cluster using On-Demand Instances. Provision the database and its read replicas in Amazon RDS using On-Demand Instances. Store the documents in Amazon EFS. Create a cron job to move the documents that are older than 3 months to Amazon S3 Glacier. Create an AWS Lambda function to delete the documents in S3 Glacier that are older than 7 years.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create an ECS cluster using a fleet of Spot Instances with Spot Instance draining enabled. Provision the database and its read replicas in Amazon RDS using On-Demand Instances. Store the documents in a secured Amazon S3 bucket with a lifecycle policy to move the documents that are older than 3 months to Amazon S3 Glacier, then delete the documents in Amazon S3 Glacier after 7 years.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 215122,
          "date": "Tue 21 Sep 2021 13:36",
          "username": "lionokirrim",
          "content": "B seems to be correct, spot instances for ECS cluster and Reserved instances for RDBAgree, more info:<br><br>A with RDS on spot instances is automatically ruled out<br>B is feasible by using a \\\"Diversified\\\" allocation strategy when setting up the Spot provisioning ECS cluster<br>C is feasible but more expensive to do RDS on-demand instances than RDS RI as in B, and uses EFS instead of S3 to store the documents, not as cost effective<br>D is feasible but more expensive to do RDS on-demand instances than RDS RI as in B<br><br>https://aws.amazon.com/ec2/spot/containers-for-less/get-started/<br>https://aws.amazon.com/ec2/spot/instance-advisor/",
          "upvote_count": "152",
          "selected_answers": ""
        },
        {
          "id": 463602,
          "date": "Mon 01 Nov 2021 19:53",
          "username": "kirrim",
          "content": "Agree, more info:<br><br>A with RDS on spot instances is automatically ruled out<br>B is feasible by using a \\\"Diversified\\\" allocation strategy when setting up the Spot provisioning ECS cluster<br>C is feasible but more expensive to do RDS on-demand instances than RDS RI as in B, and uses EFS instead of S3 to store the documents, not as cost effective<br>D is feasible but more expensive to do RDS on-demand instances than RDS RI as in B<br><br>https://aws.amazon.com/ec2/spot/containers-for-less/get-started/<br>https://aws.amazon.com/ec2/spot/instance-advisor/",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 284429,
          "date": "Mon 18 Oct 2021 17:21",
          "username": "Ebi",
          "content": "B for sure",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 716013,
          "date": "Fri 11 Nov 2022 12:35",
          "username": "Amsa",
          "content": "B is correct, straight from Don Bonso's test",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 639912,
          "date": "Sun 31 Jul 2022 07:13",
          "username": "KiraguJohn",
          "content": "I was skeptical of spot instance on ECS until i read this;<br>Amazon Elastic Container Service (ECS) supports Automated Spot Instance Draining, a new capability that reduces service interruptions due to Spot termination for ECS workloads. This feature will enable ECS customers to safely manage any interruptions of ECS tasks running on Spot instances due to termination of the underlying EC2 Spot instance.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 526695,
          "date": "Tue 18 Jan 2022 15:12",
          "username": "frankzeng",
          "content": "https://aws.amazon.com/about-aws/whats-new/2019/09/amazon-ecs-supports-automated-draining-for-spot-instances-running-ecs-services/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 513960,
          "date": "Fri 31 Dec 2021 09:50",
          "username": "cldy",
          "content": "B is correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 507023,
          "date": "Wed 22 Dec 2021 12:23",
          "username": "Ni_yot",
          "content": "B for me.youwant to use reserved instances as its cost effective.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 494911,
          "date": "Mon 06 Dec 2021 06:09",
          "username": "vramchn",
          "content": "B for sure",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492153,
          "date": "Thu 02 Dec 2021 06:03",
          "username": "AzureDP900",
          "content": "B Is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446433,
          "date": "Sun 31 Oct 2021 19:10",
          "username": "andylogan",
          "content": "It's B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436538,
          "date": "Sat 30 Oct 2021 21:53",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433388,
          "date": "Fri 29 Oct 2021 19:50",
          "username": "Suresh108",
          "content": "method of elimination - <br><br>choosing B as answer. <br>A and C areeliminated - due to cron usage<br>D - eliminated due to on-demand instance where DB cost can be reduced by reserved instances (seems it needs to be run for several years).",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413471,
          "date": "Tue 26 Oct 2021 06:11",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 411504,
          "date": "Mon 25 Oct 2021 08:46",
          "username": "Kopa",
          "content": "B, AWS RDS Reserved instances more cost efficent as it says the company will operate more then 7 years.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357145,
          "date": "Sat 23 Oct 2021 06:53",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 294263,
          "date": "Wed 20 Oct 2021 19:06",
          "username": "Kian1",
          "content": "going with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 269339,
          "date": "Thu 14 Oct 2021 10:48",
          "username": "kopper2019",
          "content": "B is the correct one spot instances and Reserved for DB",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#681",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A financial services company receives a regular data feed from its credit card servicing partner. Approximately 5,000 records are sent every 15 minutes in plaintext, delivered over HTTPS directly into an Amazon S3 bucket with server-side encryption. This feed contains sensitive credit card primary account number<br>(PAN) data. The company needs to automatically mask the PAN before sending the data to another S3 bucket for additional internal processing. The company also needs to remove and merge specific fields, and then transform the record into JSON format. Additionally, extra feeds are likely to be added in the future, so any design needs to be easily expandable.<br>Which solutions will meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#681",
          "answers": [
            {
              "choice": "<p>A. Trigger an AWS Lambda function on file delivery that extracts each record and writes it to an Amazon SQS queue. Trigger another Lambda function when new messages arrive in the SQS queue to process the records, writing the results to a temporary location in Amazon S3. Trigger a final Lambda function once the SQS queue is empty to transform the records into JSON format and send the results to another S3 bucket for internal processing.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Trigger an AWS Lambda function on file delivery that extracts each record and writes it to an Amazon SQS queue. Configure an AWS Fargate container application to automatically scale to a single instance when the SQS queue contains messages. Have the application process each record, and transform the record into JSON format. When the queue is empty, send the results to another S3 bucket for internal processing and scale down the AWS Fargate instance.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create an AWS Glue crawler and custom classifier based on the data feed formats and build a table definition to match. Trigger an AWS Lambda function on file delivery to start an AWS Glue ETL job to transform the entire record according to the processing and transformation requirements. Define the output format as JSON. Once complete, have the ETL job send the results to another S3 bucket for internal processing.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create an AWS Glue crawler and custom classifier based upon the data feed formats and build a table definition to match. Perform an Amazon Athena query on file delivery to start an Amazon EMR ETL job to transform the entire record according to the processing and transformation requirements. Define the output format as JSON. Once complete, send the results to another S3 bucket for internal processing and scale down the EMR cluster.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 215129,
          "date": "Sun 19 Sep 2021 20:15",
          "username": "lionofabianjanu",
          "content": "C seems to be correct<br>https://docs.aws.amazon.com/glue/latest/dg/trigger-job.htmlI agree. A) can bring cost problems and concurrency limits in lambda. Furthermore, Glue already solves these issues with much less development.",
          "upvote_count": "224",
          "selected_answers": ""
        },
        {
          "id": 222732,
          "date": "Sat 25 Sep 2021 19:30",
          "username": "fabianjanu",
          "content": "I agree. A) can bring cost problems and concurrency limits in lambda. Furthermore, Glue already solves these issues with much less development.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 343299,
          "date": "Tue 26 Oct 2021 20:43",
          "username": "blackgamerkirrim",
          "content": "C is the correct answer. <br><br>https://d1.awsstatic.com/Products/product-name/diagrams/product-page-diagram_Glue_Event-driven-ETL-Pipelines.e24d59bb79a9e24cdba7f43ffd234ec0482a60e2.pngBeautiful diagram!<br><br>Just in case the URL for that image gets modifed, scroll down to \\\"Use Cases\\\" on the home page for Glue:https://aws.amazon.com/glue/",
          "upvote_count": "61",
          "selected_answers": ""
        },
        {
          "id": 463607,
          "date": "Tue 02 Nov 2021 06:07",
          "username": "kirrim",
          "content": "Beautiful diagram!<br><br>Just in case the URL for that image gets modifed, scroll down to \\\"Use Cases\\\" on the home page for Glue:https://aws.amazon.com/glue/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 615444,
          "date": "Sun 12 Jun 2022 19:22",
          "username": "CloudHell",
          "content": "I'm going with C. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 497320,
          "date": "Thu 09 Dec 2021 05:39",
          "username": "cldy",
          "content": "C.  Create an AWS Glue crawler and custom classifier based on the data feed formats and build a table definition to match. Trigger an AWS Lambda function on file delivery to start an AWS Glue ETL job to transform the entire record according to the processing and transformation requirements. Define the output format as JSON. Once complete, have the ETL job send the results to another S3 bucket for internal processing.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492412,
          "date": "Thu 02 Dec 2021 12:48",
          "username": "AzureDP900",
          "content": "c is correct<br>You can use a Glue crawler to populate the AWS Glue Data Catalog with tables. The Lambda function can be triggered<br>using S3 event notifications when object create events occur. The Lambda function will then trigger the Glue ETL job<br>to transform the records masking the sensitive data and modifying the output format to JSON. This solution meets all<br>requirements.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488537,
          "date": "Sat 27 Nov 2021 23:28",
          "username": "AzureDP900",
          "content": "C is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 484100,
          "date": "Mon 22 Nov 2021 11:58",
          "username": "acloudguru",
          "content": "https://aws.amazon.com/glue/",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 446436,
          "date": "Sat 30 Oct 2021 22:24",
          "username": "andylogan",
          "content": "It's C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436540,
          "date": "Fri 29 Oct 2021 12:12",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413923,
          "date": "Thu 28 Oct 2021 00:17",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 366856,
          "date": "Wed 27 Oct 2021 13:19",
          "username": "mustpassla",
          "content": "D, a use case of Glue crawler.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 357149,
          "date": "Wed 27 Oct 2021 11:59",
          "username": "Waiweng",
          "content": "it's C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 334613,
          "date": "Tue 26 Oct 2021 09:00",
          "username": "KnightVictor",
          "content": "going with C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 318659,
          "date": "Sun 24 Oct 2021 23:30",
          "username": "eji",
          "content": "i think D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 313456,
          "date": "Thu 21 Oct 2021 22:29",
          "username": "wasabidev",
          "content": "C for me",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 294266,
          "date": "Tue 19 Oct 2021 19:44",
          "username": "Kian1",
          "content": "I will go with C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 288178,
          "date": "Thu 14 Oct 2021 20:03",
          "username": "Ebi",
          "content": "I go with C",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#682",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A media company is serving video files stored in Amazon S3 using Amazon CloudFront. The development team needs access to the logs to diagnose faults and perform service monitoring. The log files from CloudFront may contain sensitive information about users.<br>The company uses a log processing service to remove sensitive information before making the logs available to the development team. The company has the following requirements for the unprocessed logs:<br>✑ The logs must be encrypted at rest and must be accessible by the log processing service only.<br>✑ Only the data protection team can control access to the unprocessed log files.<br>✑ AWS CloudFormation templates must be stored in AWS CodeCommit.<br>✑ AWS CodePipeline must be triggered on commit to perform updates made to CloudFormation templates.<br>CloudFront is already writing the unprocessed logs to an Amazon S3 bucket, and the log processing service is operating against this S3 bucket.<br><img src=\"https://www.examtopics.com/https://examtopics.com/assets/media/exam-media/04241/0044800005.png\" class=\"in-exam-image\"><br>Which combination of steps should a solutions architect take to meet the company's requirements? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: AD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#682",
          "answers": [
            {
              "choice": "<p>A. Create an AWS KMS key that allows the AWS Logs Delivery account to generate data keys for encryption Configure S3 default encryption to use server-side encryption with KMS managed keys (SSE-KMS) on the log storage bucket using the new KMS key. Modify the KMS key policy to allow the log processing service to perform decrypt operations.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an AWS KMS key that follows the CloudFront service role to generate data keys for encryption Configure S3 default encryption to use KMS managed keys (SSE-KMS) on the log storage bucket using the new KMS key Modify the KMS key policy to allow the log processing service to perform decrypt operations.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Configure S3 default encryption to use AWS KMS managed keys (SSE-KMS) on the log storage bucket using the AWS Managed S3 KMS key. Modify the KMS key policy to allow the CloudFront service role to generate data keys for encryption Modify the KMS key policy to allow the log processing service to perform decrypt operations.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Create a new CodeCommit repository for the AWS KMS key template. Create an IAM policy to allow commits to the new repository and attach it to the data protection team's users. Create a new CodePipeline pipeline with a custom IAM role to perform KMS key updates using CloudFormation Modify the KMS key policy to allow the CodePipeline IAM role to modify the key policy.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Use the existing CodeCommit repository for the AWS KMS key template. Create an IAM policy to allow commits to the new repository and attach it to the data protection team's users. Modify the existing CodePipeline pipeline to use a custom IAM role and to perform KMS key updates using CloudFormation. Modify the KMS key policy to allow the CodePipeline IAM role to modify the key policy.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 339725,
          "date": "Sun 10 Oct 2021 02:57",
          "username": "MrflipLCC92",
          "content": "AD<br>`There is no such Role called Cloudfront service link role. Cloudfront uses the awslogsdelivery to deliver logs to s3 bucket -> https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#AccessLogsBucketAndFileOwnershipFrom the link Meflip gives:<br>If you enabled server-side encryption for your Amazon S3 bucket using AWS KMS-managed keys (SSE-KMS) with a customer-managed Customer Master Key (CMK), you must add the following to the key policy for your CMK to enable writing log files to the bucket. You cannot use the default CMK because CloudFront won't be able to upload the log files to the bucket.<br>{<br>\\\"Sid\\\": \\\"Allow CloudFront Flow Logs to use the key\\\",<br>\\\"Effect\\\": \\\"Allow\\\",<br>\\\"Principal\\\": {<br>\\\"Service\\\": \\\"delivery.logs.amazonaws.com\\\"<br>},<br>\\\"Action\\\": \\\"kms:GenerateDataKey*\\\",<br>\\\"Resource\\\": \\\"*\\\"<br>}",
          "upvote_count": "133",
          "selected_answers": ""
        },
        {
          "id": 360408,
          "date": "Fri 15 Oct 2021 01:00",
          "username": "LCC92",
          "content": "From the link Meflip gives:<br>If you enabled server-side encryption for your Amazon S3 bucket using AWS KMS-managed keys (SSE-KMS) with a customer-managed Customer Master Key (CMK), you must add the following to the key policy for your CMK to enable writing log files to the bucket. You cannot use the default CMK because CloudFront won't be able to upload the log files to the bucket.<br>{<br>\\\"Sid\\\": \\\"Allow CloudFront Flow Logs to use the key\\\",<br>\\\"Effect\\\": \\\"Allow\\\",<br>\\\"Principal\\\": {<br>\\\"Service\\\": \\\"delivery.logs.amazonaws.com\\\"<br>},<br>\\\"Action\\\": \\\"kms:GenerateDataKey*\\\",<br>\\\"Resource\\\": \\\"*\\\"<br>}",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 329642,
          "date": "Wed 06 Oct 2021 14:01",
          "username": "SD13pablobairatbobsmith2000",
          "content": "B & D: These are correct options —<br><br>If you enabled server-side encryption for your Amazon S3 bucket using AWS KMS-managed keys (SSE-KMS) with a customer-managed Customer Master Key (CMK), you must add the following to the key policy for your CMK to enable writing log files to the bucket. You cannot use the default CMK because CloudFront won't be able to upload the log files to the bucket.<br><br>URL : https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#AccessLogsKMSPermissionsAccording to that link and the paragraph you have pasted, the correct answers are C & DC is wrong. You cannot modify a key policy of a AWS managed KMS key.<br>https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#aws-managed-cmk",
          "upvote_count": "1113",
          "selected_answers": ""
        },
        {
          "id": 427998,
          "date": "Wed 20 Oct 2021 22:09",
          "username": "pablobairatbobsmith2000",
          "content": "According to that link and the paragraph you have pasted, the correct answers are C & DC is wrong. You cannot modify a key policy of a AWS managed KMS key.<br>https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#aws-managed-cmk",
          "upvote_count": "13",
          "selected_answers": ""
        },
        {
          "id": 601479,
          "date": "Sat 14 May 2022 09:55",
          "username": "bobsmith2000",
          "content": "C is wrong. You cannot modify a key policy of a AWS managed KMS key.<br>https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#aws-managed-cmk",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 493599,
          "date": "Sat 04 Dec 2021 09:59",
          "username": "ryu10_09bobsmith2000",
          "content": "according to AWS:<br>If the S3 bucket for your standard logs uses server-side encryption with AWS KMS keys (SSE-KMS) using a customer managed key, you must add the following statement to the key policy for your customer managed key. This allows CloudFront to write log files to the bucket. (You can’t use SSE-KMS with the AWS managed key because CloudFront won’t be able to write log files to the bucket.)<br>with this I go with A&DThere's no such thing as \\\"AWS Logs Delivery account\\\".<br>It's a service",
          "upvote_count": "23",
          "selected_answers": ""
        },
        {
          "id": 601480,
          "date": "Sat 14 May 2022 09:56",
          "username": "bobsmith2000",
          "content": "There's no such thing as \\\"AWS Logs Delivery account\\\".<br>It's a service",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 459410,
          "date": "Thu 04 Nov 2021 06:11",
          "username": "student22",
          "content": "A,D<br>AWS Logs Delivery account + new repository",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 446455,
          "date": "Tue 02 Nov 2021 22:16",
          "username": "andylogan",
          "content": "It's A D as tgv's comment",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 437832,
          "date": "Sat 30 Oct 2021 06:49",
          "username": "Kopa",
          "content": "Coorect A, D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436547,
          "date": "Sat 30 Oct 2021 05:44",
          "username": "tgv",
          "content": "AAA DDD<br>---<br>CloudFront service role doesn't exist. It uses \\\"delivery.logs.amazonaws.com\\\" which is the \\\"awslogsdelivery account\\\"<br>---> https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 433967,
          "date": "Fri 22 Oct 2021 21:50",
          "username": "blackgamerblackgamer",
          "content": "B &hasD for me.Change to A& D after reading this document. <br><br>https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/encrypt-log-data-kms.html",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 436050,
          "date": "Thu 28 Oct 2021 14:29",
          "username": "blackgamer",
          "content": "Change to A& D after reading this document. <br><br>https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/encrypt-log-data-kms.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 431563,
          "date": "Thu 21 Oct 2021 14:06",
          "username": "denccc",
          "content": "B and D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413929,
          "date": "Sat 16 Oct 2021 15:45",
          "username": "WhyIronMan",
          "content": "I'll go with B,D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 383935,
          "date": "Fri 15 Oct 2021 14:34",
          "username": "WaiwengDashL",
          "content": "it's A&D, no such thing as cloudfront service roleWhichever service delivers logs to S3 needs to have permission to use the CMK. In this case CloudFront delivers the logs to AWS Logs Delivery account. Then AWS Logs Delivery account delivers the logs to S3. In this case, CloudFront doesn't encrypt the logs - the AWS Logs Delivery account does. CloudFront isn't even aware of the fact that the logs are being encrypted.",
          "upvote_count": "65",
          "selected_answers": ""
        },
        {
          "id": 397854,
          "date": "Fri 15 Oct 2021 15:57",
          "username": "DashL",
          "content": "Whichever service delivers logs to S3 needs to have permission to use the CMK. In this case CloudFront delivers the logs to AWS Logs Delivery account. Then AWS Logs Delivery account delivers the logs to S3. In this case, CloudFront doesn't encrypt the logs - the AWS Logs Delivery account does. CloudFront isn't even aware of the fact that the logs are being encrypted.",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 377960,
          "date": "Fri 15 Oct 2021 10:01",
          "username": "ss160700bobsmith2000",
          "content": "A & D - CloudFront will use \\\"Service\\\": \\\"delivery.logs.amazonaws.com\\\" to log to S3. Need action\\\": \\\"kms:GenerateDataKey*\\\" to the principal.Isn't it a service? A states that it's account, but in documentation it's shown as service",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 601481,
          "date": "Sat 14 May 2022 10:03",
          "username": "bobsmith2000",
          "content": "Isn't it a service? A states that it's account, but in documentation it's shown as service",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 360577,
          "date": "Fri 15 Oct 2021 06:00",
          "username": "ladh",
          "content": "why not E?",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 337960,
          "date": "Sat 09 Oct 2021 00:47",
          "username": "CarisB",
          "content": "Thanks for the link SD13. My first choice was AD, but BD seems right.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 328579,
          "date": "Mon 04 Oct 2021 14:17",
          "username": "Pupu86",
          "content": "Option C is correct as SSE-S3 is needed minimally to encrypt at rest and reduce unnecessary cost of SSE-KMS.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 323800,
          "date": "Sun 03 Oct 2021 10:56",
          "username": "M_Asep",
          "content": "BD<br>For me because<br>A seems not right because it using AWS SSE you can't use your own key",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 318666,
          "date": "Sat 02 Oct 2021 08:53",
          "username": "eji",
          "content": "BD for me",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#683",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company's service for video game recommendations has just gone viral. The company has new users from all over the world. The website for the service is hosted on a set of Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB). The website consists of static content with different resources being loaded depending on the device type.<br>Users recently reported that the load time for the website has increased. Administrators are reporting high loads on the EC2 instances that host the service.<br>Which set actions should a solutions architect take to improve response times?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#683",
          "answers": [
            {
              "choice": "<p>A. Create separate Auto Scaling groups based on device types. Switch to Network Load Balancer (NLB). Use the User-Agent HTTP header in the NLB to route to a different set of EC2 instances.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Move content to Amazon S3. Create an Amazon CloudFront distribution to serve content out of the S3 bucket. Use Lambda@Edge to load different resources based on the User-Agent HTTP header.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create a separate ALB for each device type. Create one Auto Scaling group behind each ALB.  Use Amazon Route 53 to route to different ALBs depending on the User-Agent HTTP header.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Move content to Amazon S3. Create an Amazon CloudFront distribution to serve content out of the S3 bucket. Use the User-Agent HTTP header to load different content.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 215145,
          "date": "Tue 21 Sep 2021 20:33",
          "username": "lionodolphina02",
          "content": "B seems to fulfill the requirementsI'll say.",
          "upvote_count": "171",
          "selected_answers": ""
        },
        {
          "id": 216290,
          "date": "Thu 23 Sep 2021 10:26",
          "username": "dolphina02",
          "content": "I'll say.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 648520,
          "date": "Thu 18 Aug 2022 18:30",
          "username": "Ni_yot",
          "content": "B is obs",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 561322,
          "date": "Sat 05 Mar 2022 10:06",
          "username": "pal40sg",
          "content": "https://aws.amazon.com/blogs/networking-and-content-delivery/dynamically-route-viewer-requests-to-any-origin-using-lambdaedge/",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 532309,
          "date": "Tue 25 Jan 2022 18:50",
          "username": "shotty1",
          "content": "it is B",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 521494,
          "date": "Tue 11 Jan 2022 12:40",
          "username": "pititcu667",
          "content": "B seems correct",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 492424,
          "date": "Thu 02 Dec 2021 12:59",
          "username": "AzureDP900",
          "content": "it is B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446458,
          "date": "Wed 03 Nov 2021 18:39",
          "username": "andylogan",
          "content": "It's B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436548,
          "date": "Wed 03 Nov 2021 09:36",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433973,
          "date": "Tue 02 Nov 2021 22:39",
          "username": "blackgamer",
          "content": "Answer is B.  Refer below on the explanation.<br><br>https://aws.amazon.com/blogs/networking-and-content-delivery/dynamically-route-viewer-requests-to-any-origin-using-lambdaedge/",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 416964,
          "date": "Tue 02 Nov 2021 21:01",
          "username": "tiffannykirrim",
          "content": "For those who confuse between B and D.  Check this link https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-examples.html#lambda-examples-redirecting-examplesTotally agree on B, and great document!<br><br>Here's the exact fragment URL on that page to the code to redirect based on device type:<br>https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-examples.html#lambda-examples-vary-on-device-type",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 463613,
          "date": "Fri 05 Nov 2021 21:58",
          "username": "kirrim",
          "content": "Totally agree on B, and great document!<br><br>Here's the exact fragment URL on that page to the code to redirect based on device type:<br>https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-examples.html#lambda-examples-vary-on-device-type",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413935,
          "date": "Mon 01 Nov 2021 14:56",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 385602,
          "date": "Fri 29 Oct 2021 14:05",
          "username": "hk436",
          "content": "B for sure.!",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357152,
          "date": "Thu 28 Oct 2021 04:32",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 343309,
          "date": "Wed 27 Oct 2021 00:11",
          "username": "blackgamer",
          "content": "The answer is B. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 313438,
          "date": "Mon 25 Oct 2021 13:17",
          "username": "wasabidev",
          "content": "B is correct",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 294269,
          "date": "Thu 21 Oct 2021 10:29",
          "username": "Kian1",
          "content": "will go with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 284430,
          "date": "Thu 21 Oct 2021 01:23",
          "username": "Ebi",
          "content": "I go with B",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#684",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is planning a large event where a promotional offer will be introduced. The company's website is hosted on AWS and backed by an Amazon RDS for<br>PostgreSQL DB instance. The website explains the promotion and includes a sign-up page that collects user information and preferences. Management expects large and unpredictable volumes of traffic periodically, which will create many database writes. A solutions architect needs to build a solution that does not change the underlying data model and ensures that submissions are not dropped before they are committed to the database.<br>Which solution meets these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#684",
          "answers": [
            {
              "choice": "<p>A. Immediately before the event, scale up the existing DB instance to meet the anticipated demand. Then scale down after the event.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use Amazon SQS to decouple the application and database layers. Configure an AWS Lambda function to write items from the queue into the database.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Migrate to Amazon DynamoDB and manage throughput capacity with automatic scaling.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use Amazon ElastiCache for Memcached to increase write capacity to the DB instance.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 234274,
          "date": "Tue 05 Oct 2021 03:22",
          "username": "petebear55ryu10_09gerhardblredipaPAUGURUstudent22",
          "content": "Come on Guys !! .. Ive seen the discussions below ... if you can not get this one then you are no where near to taking the exam !! .. the problem here is a WRITE issue .. so for that we would use SQS to help hold the solution until it is ready to be written ... Elastichche is for caching solution .. so we would use that in READ situation .... ANSWER IS B .. really concerned why the incorrect answer appears in the answer boxmaybe you should not take the exam yourself. havn't you heard of write-through cache before:<br>https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/Strategies.html#Strategies.WriteThroughI guess you kind of just proved his point.caching is for read speed. write-through cache doesn't increase write speed to the DB, it just means any new writes to the DB are also written to the cache along the way.Agree 100%, these questions are the easy ones...Well said! Answers in the answer box make me worried. It's good that we have a great community here.",
          "upvote_count": "4212276",
          "selected_answers": ""
        },
        {
          "id": 484821,
          "date": "Tue 23 Nov 2021 09:12",
          "username": "ryu10_09gerhardblredipa",
          "content": "maybe you should not take the exam yourself. havn't you heard of write-through cache before:<br>https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/Strategies.html#Strategies.WriteThroughI guess you kind of just proved his point.caching is for read speed. write-through cache doesn't increase write speed to the DB, it just means any new writes to the DB are also written to the cache along the way.",
          "upvote_count": "122",
          "selected_answers": ""
        },
        {
          "id": 646792,
          "date": "Sun 14 Aug 2022 17:18",
          "username": "gerhardbl",
          "content": "I guess you kind of just proved his point.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 611240,
          "date": "Fri 03 Jun 2022 21:09",
          "username": "redipa",
          "content": "caching is for read speed. write-through cache doesn't increase write speed to the DB, it just means any new writes to the DB are also written to the cache along the way.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 239253,
          "date": "Thu 07 Oct 2021 02:59",
          "username": "PAUGURU",
          "content": "Agree 100%, these questions are the easy ones...",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 439580,
          "date": "Sat 06 Nov 2021 13:37",
          "username": "student22",
          "content": "Well said! Answers in the answer box make me worried. It's good that we have a great community here.",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 217625,
          "date": "Sun 26 Sep 2021 15:05",
          "username": "smartassXbesopetebear55petebear55",
          "content": "B is the answer! SQS with Lambda.SQS with lambda is eventually consistent, we are looking here for strong consistent which is option A?\\\"large and unpredictable volumes of traffic periodically\\\" beso a can not be the answerWELL DONE",
          "upvote_count": "30131",
          "selected_answers": ""
        },
        {
          "id": 220986,
          "date": "Wed 29 Sep 2021 00:08",
          "username": "besopetebear55",
          "content": "SQS with lambda is eventually consistent, we are looking here for strong consistent which is option A?\\\"large and unpredictable volumes of traffic periodically\\\" beso a can not be the answer",
          "upvote_count": "13",
          "selected_answers": ""
        },
        {
          "id": 256913,
          "date": "Mon 18 Oct 2021 23:09",
          "username": "petebear55",
          "content": "\\\"large and unpredictable volumes of traffic periodically\\\" beso a can not be the answer",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 256906,
          "date": "Sun 17 Oct 2021 23:35",
          "username": "petebear55",
          "content": "WELL DONE",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 690771,
          "date": "Mon 10 Oct 2022 08:35",
          "username": "skywalker",
          "content": "B. . SQS to capture new writes before storing in DB will help<br>D is wrong as it only provide enhancement during READ operation.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 622834,
          "date": "Mon 27 Jun 2022 00:04",
          "username": "kangtamo",
          "content": "Agree with B: SQS.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 606297,
          "date": "Mon 23 May 2022 21:45",
          "username": "user0001Cal88",
          "content": "A :because they dont want to introduce change \\\"A solutions architect must provide a solution that does not alter the underlying data architecture\\\"<br>B would be better if they do allow changesThey don’t wanna introduce change to the “data mode” so no change to the DB type.<br>No one said anything about changing the way to process the writes.<br>if you choose A , what capacity will you chose to scale up?<br>Remember its unpredictable traffic which a really important keyword in the question.<br>B is the best way to achieve what is asked in the question",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 709398,
          "date": "Tue 01 Nov 2022 20:21",
          "username": "Cal88",
          "content": "They don’t wanna introduce change to the “data mode” so no change to the DB type.<br>No one said anything about changing the way to process the writes.<br>if you choose A , what capacity will you chose to scale up?<br>Remember its unpredictable traffic which a really important keyword in the question.<br>B is the best way to achieve what is asked in the question",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492861,
          "date": "Fri 03 Dec 2021 01:20",
          "username": "vbal",
          "content": "D is NOT correct. The write-through strategy adds data or updates data in the cache whenever data is written to the database. Every write involves two trips:<br>A write to the cache<br>A write to the database<br>Which adds latency to the process.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492430,
          "date": "Thu 02 Dec 2021 13:02",
          "username": "AzureDP900",
          "content": "going with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 484822,
          "date": "Tue 23 Nov 2021 09:13",
          "username": "ryu10_09",
          "content": "I would still go with using memcached and the write-through capabilities for it:https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/Strategies.html#Strategies.WriteThrough<br>SQS is also an option here",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436550,
          "date": "Fri 05 Nov 2021 15:52",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 433975,
          "date": "Fri 05 Nov 2021 09:20",
          "username": "blackgamer",
          "content": "B is the answer.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 431531,
          "date": "Tue 02 Nov 2021 16:32",
          "username": "tiffanny",
          "content": "lol but in real life, aws user are using A option. LOL because they are too lazy to change the infra.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 366868,
          "date": "Tue 02 Nov 2021 09:24",
          "username": "mustpassla",
          "content": "B, use SQS to ensures that submissions are not dropped. A is not correct as scaling up manually cant help as the volumes of traffic are unpredictable.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 357156,
          "date": "Mon 01 Nov 2021 13:48",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 313431,
          "date": "Wed 27 Oct 2021 23:56",
          "username": "wasabidev",
          "content": "B.  in my opinion, one of the easiest question",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 294273,
          "date": "Tue 26 Oct 2021 06:31",
          "username": "Kian1",
          "content": "going for B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 284431,
          "date": "Thu 21 Oct 2021 20:13",
          "username": "Ebi",
          "content": "B for sure",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 283701,
          "date": "Tue 19 Oct 2021 21:26",
          "username": "Trap_D0_r",
          "content": "B<br>This is literally the use case for SQS why are people fighting about it?",
          "upvote_count": "4",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#685",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A mobile app has become very popular, and usage has gone from a few hundred to millions of users. Users capture and upload images of activities within a city, and provide ratings and recommendations. Data access patterns are unpredictable. The current application is hosted on Amazon EC2 instances behind an<br>Application Load Balancer (ALB). The application is experiencing slowdowns and costs are growing rapidly.<br>Which changes should a solutions architect make to the application architecture to control costs and improve performance?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#685",
          "answers": [
            {
              "choice": "<p>A. Create an Amazon CloudFront distribution and place the ALB behind the distribution. Store static content in Amazon S3 in an Infrequent Access storage class.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Store static content in an Amazon S3 bucket using the Intelligent Tiering storage class. Use an Amazon CloudFront distribution in front of the S3 bucket and the ALB. <br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Place AWS Global Accelerator in front of the ALB.  Migrate the static content to Amazon EFS, and then run an AWS Lambda function to resize the images during the migration process.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Move the application code to AWS Fargate containers and swap out the EC2 instances with the Fargate containers.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 308875,
          "date": "Fri 01 Oct 2021 01:02",
          "username": "kalyan_krishna742020",
          "content": "B.  Keywords: \\\"Data access patterns are unpredictable\\\" best fits to Intelligent Tiering",
          "upvote_count": "25",
          "selected_answers": ""
        },
        {
          "id": 357163,
          "date": "Fri 08 Oct 2021 21:38",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 644278,
          "date": "Tue 09 Aug 2022 01:45",
          "username": "hahaaaaa",
          "content": "I will go with D<br>there is no mention of storage related to the current environment, in this question.<br>So, B cannot be the answer.<br>EC2: Predictable and sustained workloads having high utilization rates <br>Fargate: Automatic provisioning of workloads is required. More flexibility is required",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 640839,
          "date": "Mon 01 Aug 2022 23:36",
          "username": "kapara",
          "content": "its B!!",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 621814,
          "date": "Fri 24 Jun 2022 20:22",
          "username": "skyblue07",
          "content": "\\\"Data access patterns are unpredictable\\\", cloud front cache will be inefficient. <br>And with B option you are not solving the bottleneck.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 497581,
          "date": "Thu 09 Dec 2021 11:11",
          "username": "cldy",
          "content": "B.  Store static content in an Amazon S3 bucket using the Intelligent Tiering storage class. Use an Amazon CloudFront distribution in front of the S3 bucket and the ALB. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 488530,
          "date": "Sat 27 Nov 2021 23:03",
          "username": "AzureDP900",
          "content": "I will go with B, The patterns of data access are unexpected is the key word in this question.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446468,
          "date": "Fri 05 Nov 2021 01:15",
          "username": "andylogan",
          "content": "It's B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436551,
          "date": "Thu 04 Nov 2021 05:52",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413940,
          "date": "Wed 03 Nov 2021 11:26",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 366874,
          "date": "Mon 01 Nov 2021 02:58",
          "username": "mustpassla",
          "content": "B, SAA level.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 363856,
          "date": "Thu 28 Oct 2021 13:57",
          "username": "vkbajoria",
          "content": "it's B for me",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 337963,
          "date": "Sat 02 Oct 2021 10:55",
          "username": "CarisB",
          "content": "B seems good.<br>https://aws.amazon.com/about-aws/whats-new/2018/11/s3-intelligent-tiering/?nc1=h_ls",
          "upvote_count": "4",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#686",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A financial company with multiple departments wants to expand its on-premises environment to the AWS Cloud. The company must retain centralized access control using an existing on-premises Active Directory (AD) service. Each department should be allowed to create AWS accounts with preconfigured networking and should have access to only a specific list of approved services. Departments are not permitted to have account administrator permissions.<br>What should a solutions architect do to meet these security requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#686",
          "answers": [
            {
              "choice": "<p>A. Configure AWS Identity and Access Management (IAM) with a SAML identity provider (IdP) linked to the on-premises Active Directory, and create a role to grant access. Configure AWS Organizations with SCPs and create new member accounts. Use AWS CloudFormation templates to configure the member account networking.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Deploy an AWS Control Tower landing zone. Create an AD Connector linked to the on-premises Active Directory. Change the identity source in AWS Single Sign-On to use Active Directory. Allow department administrators to use Account Factory to create new member accounts and networking. Grant the departments AWS power user permissions on the created accounts.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Deploy an Amazon Cloud Directory. Create a two-way trust relationship with the on-premises Active Directory, and create a role to grant access. Set up an AWS Service Catalog to use AWS CloudFormation templates to create the new member accounts and networking. Use IAM roles to allow access to approved AWS services.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Configure AWS Directory Service for Microsoft Active Directory with AWS Single Sign-On. Join the service to the on-premises Active Directory. Use AWS CloudFormation to create new member accounts and networking. Use IAM roles to allow access to approved AWS services.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 329274,
          "date": "Wed 06 Oct 2021 05:44",
          "username": "ExtHoheany",
          "content": "B it looks<br>AWS Control Tower automates the setup of a new landing zone using best-practices blueprints for identity, federated access, and account structure.<br>The account factory automates provisioning of new accounts in your organization. As a configurable account template, it helps you standardize the provisioning of new accounts with pre-approved account configurations. You can configure your account factory with pre-approved network configuration and region selections.<br><br>https://aws.amazon.com/controltower/features/A doesn't address ‘Each department should be allowed to create AWS accounts with preconfigured networking’<br>B and C doesn't address ' should have access to only a specific list of approved services'<br>D doesn't make sense.<br>If SCP can be added to B, then b is a perfect answer. Anyway this q&A is not a good one",
          "upvote_count": "141",
          "selected_answers": ""
        },
        {
          "id": 695896,
          "date": "Sun 16 Oct 2022 05:37",
          "username": "heany",
          "content": "A doesn't address ‘Each department should be allowed to create AWS accounts with preconfigured networking’<br>B and C doesn't address ' should have access to only a specific list of approved services'<br>D doesn't make sense.<br>If SCP can be added to B, then b is a perfect answer. Anyway this q&A is not a good one",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496620,
          "date": "Wed 08 Dec 2021 08:59",
          "username": "cldy",
          "content": "B.  Deploy an AWS Control Tower landing zone. Create an AD Connector linked to the on-premises Active Directory. Change the identity source in AWS Single Sign-On to use Active Directory. Allow department administrators to use Account Factory to create new member accounts and networking. Grant the departments AWS power user permissions on the created accounts.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492450,
          "date": "Thu 02 Dec 2021 13:21",
          "username": "AzureDP900",
          "content": "B is perfect",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 459412,
          "date": "Wed 03 Nov 2021 00:43",
          "username": "student22",
          "content": "B<br>Control Tower + AD Connector + Account Factory",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 446472,
          "date": "Sun 31 Oct 2021 14:37",
          "username": "andylogan",
          "content": "It's B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435302,
          "date": "Wed 27 Oct 2021 20:15",
          "username": "tgv",
          "content": "BBB<br>---<br>Key: \\\"Each department should be allowed to create AWS accounts with preconfigured networking\\\"",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413943,
          "date": "Sun 24 Oct 2021 21:07",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357167,
          "date": "Sun 17 Oct 2021 05:35",
          "username": "Waiweng",
          "content": "it's B<br>https://docs.aws.amazon.com/controltower/latest/userguide/what-is-control-tower.html",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 338675,
          "date": "Tue 12 Oct 2021 18:37",
          "username": "Kayode",
          "content": "The answer is B<br>https://docs.aws.amazon.com/controltower/latest/userguide/what-is-control-tower.html",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 334692,
          "date": "Fri 08 Oct 2021 00:30",
          "username": "TerrenceC",
          "content": "Although option #A points out the key factor SCP, however, it does not emphasize its major functionality which is the service boundary in this case. All the options here are more about how to govern the accounts. According to the introduction (https://aws.amazon.com/controltower/?nc2=h_ql_prod_mg_ct), there are two highlights to make option #B is much more ideal than #A. <br><br>1) Blueprints are available to provide identity management, federate access to accounts, centralize logging, establish cross-account security audits, define workflows for provisioning accounts, and implement account baselines with network configurations.<br><br>2) Control Tower provides mandatory and strongly recommended high-level rules, called guardrails, that help enforce your policies using service control policies (SCPs), or detect policy violations using AWS Config rules.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 324639,
          "date": "Tue 05 Oct 2021 05:18",
          "username": "KevinZhong",
          "content": "Seems to be B<br>------------<br>AWS Control Tower seems to maintain the control of AWS Organizations, AWS Service Catalog and AWS Config<br>------ https://d1.awsstatic.com/whitepapers/aws-overview.pdf (46)",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 319689,
          "date": "Sun 03 Oct 2021 13:04",
          "username": "Flosuccessmijeko8879",
          "content": "Is service catalog not more in line with \\\"access to only a specific list of approved services\\\"? maybe C. C it is https://aws.amazon.com/blogs/mt/automate-account-creation-and-resource-provisioning-using-aws-service-catalog-aws-organizations-and-aws-lambda/",
          "upvote_count": "33",
          "selected_answers": ""
        },
        {
          "id": 339478,
          "date": "Thu 14 Oct 2021 04:14",
          "username": "mijeko8879",
          "content": "C it is https://aws.amazon.com/blogs/mt/automate-account-creation-and-resource-provisioning-using-aws-service-catalog-aws-organizations-and-aws-lambda/",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 318674,
          "date": "Sat 02 Oct 2021 20:21",
          "username": "ejisarah_t",
          "content": "I go for A, keyword \\\"access to only a specific list of approved services. \\\" it means SCPIn ControlTower you can apply guardrails to OUs (restricting what those accounts can do). With AccontFactory you can determine which OU the newly created account belongs to.",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 334714,
          "date": "Fri 08 Oct 2021 07:48",
          "username": "sarah_t",
          "content": "In ControlTower you can apply guardrails to OUs (restricting what those accounts can do). With AccontFactory you can determine which OU the newly created account belongs to.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 315454,
          "date": "Thu 30 Sep 2021 08:16",
          "username": "awsnoobawsnoob",
          "content": "Should be A <br><br>https://aws.amazon.com/blogs/security/aws-federated-authentication-with-active-directory-federation-services-ad-fs/Nvm, it is B.  I misread the question.",
          "upvote_count": "13",
          "selected_answers": ""
        },
        {
          "id": 315459,
          "date": "Sat 02 Oct 2021 00:25",
          "username": "awsnoob",
          "content": "Nvm, it is B.  I misread the question.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 313418,
          "date": "Fri 24 Sep 2021 06:16",
          "username": "wasabidev",
          "content": "I think A",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#687",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A large financial company is deploying applications that consist of Amazon EC2 and Amazon RDS instances to the AWS Cloud using AWS CloudFormation.<br>The CloudFormation stack has the following stack policy:<br><img src=\"https://www.examtopics.com/https://examtopics.com/assets/media/exam-media/04241/0045200001.png\" class=\"in-exam-image\"><br>The company wants to ensure that developers do not lose data by accidentally removing or replacing RDS instances when updating the CloudFormation stack.<br>Developers also still need to be able to modify or remove EC2 instances as needed.<br>How should the company change the stack policy to meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#687",
          "answers": [
            {
              "choice": "<p>A. Modify the statement to specify ג€Effectג€: ג€Denyג€, ג€Actionג€:[ג€Update:*ג€] for all logical RDS resources.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Modify the statement to specify ג€Effectג€: ג€Denyג€, ג€Actionג€:[ג€Update:Deleteג€] for all logical RDS resources.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Add a second statement that specifies ג€Effectג€: ג€Denyג€, ג€Actionג€:[ג€Update:Deleteג€, ג€Update:Replaceג€] for all logical RDS resources.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Add a second statement that specifies ג€Effectג€: ג€Denyג€, ג€Actionג€:[ג€Update:*ג€] for all logical RDS resources.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 357170,
          "date": "Fri 22 Oct 2021 20:20",
          "username": "Waiweng",
          "content": "it's C",
          "upvote_count": "10",
          "selected_answers": ""
        },
        {
          "id": 329659,
          "date": "Mon 18 Oct 2021 09:13",
          "username": "SD13",
          "content": "C :<br>Supporting link : https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html#protect-stack-resources-modifying<br>Prevent replacement updates for an instance<br>The following policy denies updates that would cause a replacement of the instance with the MyInstance logical ID.  It allows all update actions on all other stack resources with an Allow statement. The Allow statement doesn't apply to the MyInstance resource because the Deny statement always overrides allow actions.<br><br>Prevent replacement updates for an instance<br>The following policy denies updates that would cause a replacement of the instance with the MyInstance logical ID.  It allows all update actions on all other stack resources with an Allow statement. The Allow statement doesn't apply to the MyInstance resource because the Deny statement always overrides allow actions.",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 707824,
          "date": "Sun 30 Oct 2022 14:17",
          "username": "awsa37430",
          "content": "cccccccc",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 494913,
          "date": "Mon 06 Dec 2021 06:13",
          "username": "cldy",
          "content": "C.  Add a second statement that specifies ג€Effectג€: ג€Denyג€, ג€Actionג€:[ג€Update:Deleteג€, ג€Update:Replaceג€] for all logical RDS resources.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492458,
          "date": "Thu 02 Dec 2021 13:25",
          "username": "AzureDP900",
          "content": "C is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 484028,
          "date": "Mon 22 Nov 2021 10:18",
          "username": "backfringe",
          "content": "CCCCCCC",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 478573,
          "date": "Mon 15 Nov 2021 10:29",
          "username": "ByomkeshDas",
          "content": "C is correct",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436552,
          "date": "Tue 02 Nov 2021 19:16",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413956,
          "date": "Tue 02 Nov 2021 07:48",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 385612,
          "date": "Mon 25 Oct 2021 08:25",
          "username": "hk436",
          "content": "c for sure.!",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 328605,
          "date": "Mon 11 Oct 2021 02:21",
          "username": "Pupu86Pupu86kirrimMrCarter",
          "content": "D is correct, with Update: * (representing delete & replace) on 2nd statement. This explicitly denies any updates to database resources only. You do not have to explicitly indicate Update with delete and replace (like what option C did).My apologies, Answer should be C as Action: Modify should be implicitly allowedAgree with C!<br><br>A & B are invalid because by overwriting that allow statement, you would not allow updates to anything.Whereas C & D leave the general allow statement in place, but add another statement with more specific deny actions for the RDS resources<br><br>Between C & D, there are four options for the Update action:<br>- Update:Modify<br>- Update:Replace<br>- Update:Delete<br>- Update:*<br>The question says to deny \\\"removing or replacing RDS instances\\\", so that means we only need to deny Update:Replace and Update:Delete, while still allowing Update:Modify<br><br>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html#stack-policy-referenceYes, the question says prevent replacement or deletion but not modification of existing RDS resource",
          "upvote_count": "1432",
          "selected_answers": ""
        },
        {
          "id": 330825,
          "date": "Wed 20 Oct 2021 00:34",
          "username": "Pupu86kirrimMrCarter",
          "content": "My apologies, Answer should be C as Action: Modify should be implicitly allowedAgree with C!<br><br>A & B are invalid because by overwriting that allow statement, you would not allow updates to anything.Whereas C & D leave the general allow statement in place, but add another statement with more specific deny actions for the RDS resources<br><br>Between C & D, there are four options for the Update action:<br>- Update:Modify<br>- Update:Replace<br>- Update:Delete<br>- Update:*<br>The question says to deny \\\"removing or replacing RDS instances\\\", so that means we only need to deny Update:Replace and Update:Delete, while still allowing Update:Modify<br><br>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html#stack-policy-referenceYes, the question says prevent replacement or deletion but not modification of existing RDS resource",
          "upvote_count": "432",
          "selected_answers": ""
        },
        {
          "id": 463623,
          "date": "Thu 04 Nov 2021 06:11",
          "username": "kirrim",
          "content": "Agree with C!<br><br>A & B are invalid because by overwriting that allow statement, you would not allow updates to anything.Whereas C & D leave the general allow statement in place, but add another statement with more specific deny actions for the RDS resources<br><br>Between C & D, there are four options for the Update action:<br>- Update:Modify<br>- Update:Replace<br>- Update:Delete<br>- Update:*<br>The question says to deny \\\"removing or replacing RDS instances\\\", so that means we only need to deny Update:Replace and Update:Delete, while still allowing Update:Modify<br><br>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html#stack-policy-reference",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 396115,
          "date": "Mon 25 Oct 2021 21:34",
          "username": "MrCarter",
          "content": "Yes, the question says prevent replacement or deletion but not modification of existing RDS resource",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 322313,
          "date": "Tue 05 Oct 2021 10:02",
          "username": "nasuuDashL",
          "content": "This answer is C.  Question is about CloudFormation Stack Policy, not CLI. <br>\\\"Update:Delete\\\" and \\\"Update:Replace\\\" should be applied for only RDS. C explains that.<br><br>https://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/protect-stack-resources.htmlThis link is in Chinese/Japanese/Korean. Open at your own risk.<br>Here is the correct link: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 398435,
          "date": "Fri 29 Oct 2021 07:06",
          "username": "DashL",
          "content": "This link is in Chinese/Japanese/Korean. Open at your own risk.<br>Here is the correct link: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 318675,
          "date": "Thu 30 Sep 2021 07:48",
          "username": "ejieji",
          "content": "i agree with Csorry i think D, because you can modify or remove for ec2, but you cannot do update or delete for rds resources",
          "upvote_count": "31",
          "selected_answers": ""
        },
        {
          "id": 318679,
          "date": "Sun 03 Oct 2021 23:42",
          "username": "eji",
          "content": "sorry i think D, because you can modify or remove for ec2, but you cannot do update or delete for rds resources",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 315467,
          "date": "Sat 25 Sep 2021 15:10",
          "username": "awsnoob",
          "content": "Should be C, policies are implicit deny and explicit allow.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 310875,
          "date": "Tue 21 Sep 2021 05:25",
          "username": "sek12324",
          "content": "Sorry its B, you modify the the same statement",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 310872,
          "date": "Tue 21 Sep 2021 00:17",
          "username": "sek12324tvs",
          "content": "C<br>{<br>\\\"Statement\\\" : [<br>{<br>\\\"Effect\\\" : \\\"Deny\\\",<br>\\\"Action\\\" : \\\"Update:*\\\",<br>\\\"Principal\\\": \\\"*\\\",<br>\\\"Resource\\\" : \\\"LogicalResourceId/MyDatabase\\\"<br>},<br>{<br>\\\"Effect\\\" : \\\"Allow\\\",<br>\\\"Action\\\" : \\\"Update:*\\\",<br>\\\"Principal\\\": \\\"*\\\",<br>\\\"Resource\\\" : \\\"*\\\"<br>}<br>]<br>}this will block all DB update ,we need to block only delete and replace.",
          "upvote_count": "32",
          "selected_answers": ""
        },
        {
          "id": 381108,
          "date": "Sat 23 Oct 2021 21:32",
          "username": "tvs",
          "content": "this will block all DB update ,we need to block only delete and replace.",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#688",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is currently in the design phase of an application that will need an RPO of less than 5 minutes and an RTO of less than 10 minutes. The solutions architecture team is forecasting that the database will store approximately 10 TB of data. As part of the design, they are looking for a database solution that will provide the company with the ability to fail over to a secondary Region.<br>Which solution will meet these business requirements at the LOWEST cost?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#688",
          "answers": [
            {
              "choice": "<p>A. Deploy an Amazon Aurora DB cluster and take snapshots of the cluster every 5 minutes. Once a snapshot is complete, copy the snapshot to a secondary Region to serve as a backup in the event of a failure.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Deploy an Amazon RDS instance with a cross-Region read replica in a secondary Region. In the event of a failure, promote the read replica to become the primary.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Deploy an Amazon Aurora DB cluster in the primary Region and another in a secondary Region. Use AWS DMS to keep the secondary Region in sync.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Deploy an Amazon RDS instance with a read replica in the same Region. In the event of a failure, promote the read replica to become the primary.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 313766,
          "date": "Sun 19 Sep 2021 20:22",
          "username": "nitinz",
          "content": "B works for me.",
          "upvote_count": "15",
          "selected_answers": ""
        },
        {
          "id": 626517,
          "date": "Sun 03 Jul 2022 12:43",
          "username": "KiraguJohn",
          "content": "I do not know if the questions are designed to confuse us or just typos. \\\"response time of fewer than five minutes and a response time of less than ten minutes.\\\" Anyway because it talks of cost i would go for B. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 498472,
          "date": "Fri 10 Dec 2021 10:18",
          "username": "cldy",
          "content": "B.  Deploy an Amazon RDS instance with a cross-Region read replica in a secondary Region. In the event of a failure, promote the read replica to become the primary.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492465,
          "date": "Thu 02 Dec 2021 13:29",
          "username": "AzureDP900",
          "content": "B works fine",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436553,
          "date": "Sun 07 Nov 2021 11:47",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 413960,
          "date": "Thu 04 Nov 2021 18:29",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 385613,
          "date": "Mon 18 Oct 2021 17:54",
          "username": "hk436",
          "content": "b is my answer!",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 366891,
          "date": "Sat 09 Oct 2021 07:02",
          "username": "mustpassla",
          "content": "B for sure, C is expensive.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357172,
          "date": "Sat 02 Oct 2021 00:19",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 342210,
          "date": "Mon 27 Sep 2021 20:58",
          "username": "nil3112MrCartertvsvictordunWhyIronMankirrim",
          "content": "what is the problem with C ? Aurora can have multi-master nowMulti master is a regional service, so no multi master cross region for Aurora yetcost, so go with B. C is proposing two db clusters in 2 regionsvery expensive@nil3112, it sounds to me like you're referring to Aurora global database which probably didn't exist when this question was written, but exists now.<br><br>https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html<br><br>Even with Aurora global DB, C refers to using DMS to sync the DB, which is invalid.And even if you ignore the DMS problem, it's still going to be more costly to run an Aurora cluster in each region as opposed to the classic use case of a single read replica in the DR region and promote to master during a DR scenario.And B also allows you to pick any RDS engine you want (as long as it supports read replicas), not just Aurora",
          "upvote_count": "223222",
          "selected_answers": ""
        },
        {
          "id": 396120,
          "date": "Sat 30 Oct 2021 07:18",
          "username": "MrCarter",
          "content": "Multi master is a regional service, so no multi master cross region for Aurora yet",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 382559,
          "date": "Wed 13 Oct 2021 01:07",
          "username": "tvs",
          "content": "cost, so go with B. ",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 365641,
          "date": "Tue 05 Oct 2021 19:50",
          "username": "victordunWhyIronMan",
          "content": "C is proposing two db clusters in 2 regionsvery expensive",
          "upvote_count": "22",
          "selected_answers": ""
        },
        {
          "id": 413959,
          "date": "Wed 03 Nov 2021 16:07",
          "username": "WhyIronMan",
          "content": "very expensive",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 463626,
          "date": "Sun 07 Nov 2021 17:31",
          "username": "kirrim",
          "content": "@nil3112, it sounds to me like you're referring to Aurora global database which probably didn't exist when this question was written, but exists now.<br><br>https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html<br><br>Even with Aurora global DB, C refers to using DMS to sync the DB, which is invalid.And even if you ignore the DMS problem, it's still going to be more costly to run an Aurora cluster in each region as opposed to the classic use case of a single read replica in the DR region and promote to master during a DR scenario.And B also allows you to pick any RDS engine you want (as long as it supports read replicas), not just Aurora",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 338165,
          "date": "Thu 23 Sep 2021 14:06",
          "username": "CarisB",
          "content": "Agree on B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 334093,
          "date": "Mon 20 Sep 2021 22:55",
          "username": "Ziegler",
          "content": "B is the more cost effective",
          "upvote_count": "3",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#689",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has a web application that uses Amazon API Gateway, AWS Lambda, and Amazon DynamoDB.  A recent marketing campaign has increased demand.<br>Monitoring software reports that many requests have significantly longer response times than before the marketing campaign.<br>A solutions architect enabled Amazon CloudWatch Logs for API Gateway and noticed that errors are occurring on 20% of the requests. In CloudWatch, the<br>Lambda function Throttles metric represents 1% of the requests and the Errors metric represents 10% of the requests. Application logs indicate that, when errors occur, there is a call to DynamoDB. <br>What change should the solutions architect make to improve the current response times as the web application becomes more popular?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#689",
          "answers": [
            {
              "choice": "<p>A. Increase the concurrency limit of the Lambda function<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Implement DynamoDB auto scaling on the table<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Increase the API Gateway throttle limit<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Re-create the DynamoDB table with a better-partitioned primary index<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 316039,
          "date": "Sat 25 Sep 2021 20:36",
          "username": "certainlyKelvin",
          "content": "i think it is B, application log indicate there is error when access to database. <br>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.htmlYes, it's B.  DynamoDB problem causing Lambda failed.",
          "upvote_count": "183",
          "selected_answers": ""
        },
        {
          "id": 340052,
          "date": "Wed 13 Oct 2021 07:16",
          "username": "Kelvin",
          "content": "Yes, it's B.  DynamoDB problem causing Lambda failed.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 313769,
          "date": "Tue 21 Sep 2021 21:56",
          "username": "nitinz",
          "content": "B is okay",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 707062,
          "date": "Sat 29 Oct 2022 10:18",
          "username": "losdwindeshmet2012",
          "content": "Why Not D? Is Auto Scaling a built-in feature of DynamoDB?yes it is",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 710230,
          "date": "Thu 03 Nov 2022 05:23",
          "username": "eshmet2012",
          "content": "yes it is",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 498468,
          "date": "Fri 10 Dec 2021 10:14",
          "username": "cldy",
          "content": "B.  Implement DynamoDB auto scaling on the table",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496965,
          "date": "Wed 08 Dec 2021 17:57",
          "username": "AzureDP900",
          "content": "B is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435305,
          "date": "Thu 04 Nov 2021 07:17",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413964,
          "date": "Mon 01 Nov 2021 23:41",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 385616,
          "date": "Mon 25 Oct 2021 21:47",
          "username": "hk436",
          "content": "B is my answer!",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 375990,
          "date": "Sun 24 Oct 2021 00:15",
          "username": "tvs",
          "content": "could be B . \\\"longer response time\\\"which means API gateway is retrying the request. if it is throttle issue you get 4XX error and no retry https://docs.aws.amazon.com/apigateway/api-reference/handling-errors/",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 366900,
          "date": "Tue 19 Oct 2021 08:52",
          "username": "mustpassla",
          "content": "B for sure",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 357174,
          "date": "Thu 14 Oct 2021 15:18",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 340631,
          "date": "Wed 13 Oct 2021 12:47",
          "username": "Kayode",
          "content": "I will go with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 338454,
          "date": "Wed 06 Oct 2021 17:57",
          "username": "consultsk",
          "content": "Application logs indicate that, when errors occur, there is a call to DynamoDB. <br>It indicates that the requests passed API Gateway and happening when a call from the application is made to DB.  <br>I would for B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 329816,
          "date": "Fri 01 Oct 2021 08:14",
          "username": "ExtHo",
          "content": "looks B I think key hint is \\\"when errors occur, there is a call to DynamoDB\\\"",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 329666,
          "date": "Fri 01 Oct 2021 00:23",
          "username": "SD13MrCarter",
          "content": "Correct Option C : 20% errors are occurring at the API gateway level, so this should be addressed first.No. Re-read the question properly",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 396122,
          "date": "Sat 30 Oct 2021 15:18",
          "username": "MrCarter",
          "content": "No. Re-read the question properly",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 315481,
          "date": "Fri 24 Sep 2021 18:52",
          "username": "awsnoobMrCarter",
          "content": "Should be CAbsolutely not",
          "upvote_count": "42",
          "selected_answers": ""
        },
        {
          "id": 396123,
          "date": "Sun 31 Oct 2021 03:38",
          "username": "MrCarter",
          "content": "Absolutely not",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 314435,
          "date": "Thu 23 Sep 2021 17:54",
          "username": "txrocker13LisXmijeko8879",
          "content": "Seems to me the problem is at the API gateway, so that's where it should be addressed.<br>https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html<br>I think C is the way to go.The issue is stated as \\\"significantly longer response time\\\". Throttling issue would return 409 instead.slower response time indicates query and/or scan operations taking longer on the dynamodb table (as the table grows) and/or API retries caused by timeouts and/or throttles. all relate to capacity problems caused potentially (but not necessary) by design issues. short term fix: increase capacity. answer B (long term review design especially anticipating table growth)",
          "upvote_count": "212",
          "selected_answers": ""
        },
        {
          "id": 336524,
          "date": "Fri 01 Oct 2021 10:54",
          "username": "LisX",
          "content": "The issue is stated as \\\"significantly longer response time\\\". Throttling issue would return 409 instead.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 339510,
          "date": "Sat 09 Oct 2021 09:30",
          "username": "mijeko8879",
          "content": "slower response time indicates query and/or scan operations taking longer on the dynamodb table (as the table grows) and/or API retries caused by timeouts and/or throttles. all relate to capacity problems caused potentially (but not necessary) by design issues. short term fix: increase capacity. answer B (long term review design especially anticipating table growth)",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#690",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A European online newspaper service hosts its public-facing WordPress site in a collocated data center in London. The current WordPress infrastructure consists of a load balancer, two web servers, and one MySQL database server. A solutions architect is tasked with designing a solution with the following requirements:<br>✑ Improve the website's performance<br>✑ Make the web tier scalable and stateless<br>✑ Improve the database server performance for read-heavy loads<br>✑ Reduce latency for users across Europe and the US<br>✑ Design the new architecture with a goal of 99.9% availability<br>Which solution meets these requirements while optimizing operational efficiency?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: A</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#690",
          "answers": [
            {
              "choice": "<p>A. Use an Application Load Balancer (ALB) in front of an Auto Scaling group of WordPress Amazon EC2 instances in one AWS Region and three Availability Zones. Configure an Amazon ElastiCache cluster in front of a Multi-AZ Amazon Aurora MySQL DB cluster. Move the WordPress shared files to Amazon EFS. Configure Amazon CloudFront with the ALB as the origin, and select a price class that includes the US and Europe.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use an Application Load Balancer (ALB) in front of an Auto Scaling group of WordPress Amazon EC2 instances in two AWS Regions and two Availability Zones in each Region. Configure an Amazon ElastiCache cluster in front of a global Amazon Aurora MySQL database. Move the WordPress shared files to Amazon EFS. Configure Amazon CloudFront with the ALB as the origin, and select a price class that includes the US and Europe. Configure EFS cross- Region replication.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use an Application Load Balancer (ALB) in front of an Auto Scaling group of WordPress Amazon EC2 instances in one AWS Region and three Availability Zones. Configure an Amazon DocumentDB table in front of a Multi-AZ Amazon Aurora MySQL DB cluster. Move the WordPress shared files to Amazon EFS. Configure Amazon CloudFront with the ALB as the origin, and select a price class that includes all global locations.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use an Application Load Balancer (ALB) in front of an Auto Scaling group of WordPress Amazon EC2 instances in two AWS Regions and three Availability Zones in each Region. Configure an Amazon ElastiCache cluster in front of a global Amazon Aurora MySQL database. Move the WordPress shared files to Amazon FSx with cross-Region synchronization. Configure Amazon CloudFront with the ALB as the origin and a price class that includes the US and Europe.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 316582,
          "date": "Wed 22 Sep 2021 15:42",
          "username": "certainlynitinz",
          "content": "Correct choice is A.  <br>B and D are eliminated since Auto Scaling spans across multiple Availability Zones within the same region but cannot span across regions. C doesn't make sense by DocumentDB infront of another database.thanks for the comment, you are right. All LB are regional resources. you need route 53 to do it at global level.",
          "upvote_count": "303",
          "selected_answers": ""
        },
        {
          "id": 319507,
          "date": "Thu 30 Sep 2021 15:39",
          "username": "nitinz",
          "content": "thanks for the comment, you are right. All LB are regional resources. you need route 53 to do it at global level.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 728643,
          "date": "Sun 27 Nov 2022 22:53",
          "username": "SureNot",
          "content": "At first sight it looks like an active-active cluster with all requirements - D fits well.<br>But then you read it two more times and realize there is a mistake. Blame on question maker! =)",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 662536,
          "date": "Wed 07 Sep 2022 15:30",
          "username": "astalavista1",
          "content": "BD - Wrong as you can't configure ALB across regions but across AZ, need R53 first for multi-region config before moving to ALB. <br>C - Wrong once it starts mentioning DocumentDB. <br>A- Correct as it's a single Region with ALB across Multi-AZ, Cache in front of DB and Multi-AZ DB.  Which satisfies all the requirements.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 635804,
          "date": "Sun 24 Jul 2022 01:56",
          "username": "hilft",
          "content": "A for me<br>For B, regarding EFS cross region replication feature. As of 2022 Jan, AWS support EFS cross-region replication<br>https://aws.amazon.com/blogs/aws/new-replication-for-amazon-elastic-file-system-efs/",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 557560,
          "date": "Sun 27 Feb 2022 20:31",
          "username": "Ni_yot",
          "content": "A for me",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 495992,
          "date": "Tue 07 Dec 2021 13:44",
          "username": "cldy",
          "content": "A.  Use an Application Load Balancer (ALB) in front of an Auto Scaling group of WordPress Amazon EC2 instances in one AWS Region and three Availability Zones. Configure an Amazon ElastiCache cluster in front of a Multi-AZ Amazon Aurora MySQL DB cluster. Move the WordPress shared files to Amazon EFS. Configure Amazon CloudFront with the ALB as the origin, and select a price class that includes the US and Europe.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 492468,
          "date": "Thu 02 Dec 2021 13:32",
          "username": "AzureDP900",
          "content": "A is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436557,
          "date": "Fri 05 Nov 2021 01:40",
          "username": "tgv",
          "content": "AAA<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413970,
          "date": "Thu 04 Nov 2021 16:01",
          "username": "WhyIronMan",
          "content": "I'll go with A",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 385618,
          "date": "Sat 23 Oct 2021 12:20",
          "username": "hk436",
          "content": "A is my answer.!",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 366901,
          "date": "Sat 23 Oct 2021 10:52",
          "username": "mustpassla",
          "content": "A, B is not operational efficiency.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 362031,
          "date": "Mon 11 Oct 2021 14:33",
          "username": "LCC92",
          "content": "B is wrong \\\"Configure EFS cross- Region replication.\\\" is not possible, can only use Datasync to replicate EFS.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 357178,
          "date": "Fri 08 Oct 2021 15:04",
          "username": "Waiweng",
          "content": "it's A",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 334249,
          "date": "Thu 07 Oct 2021 07:54",
          "username": "Ziegler",
          "content": "A is the right option",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 316648,
          "date": "Sun 26 Sep 2021 09:03",
          "username": "SD13SD13",
          "content": "D for meChanging it to A",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 329668,
          "date": "Wed 06 Oct 2021 01:26",
          "username": "SD13",
          "content": "Changing it to A",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 313774,
          "date": "Wed 22 Sep 2021 00:40",
          "username": "nitinznitinz",
          "content": "B works for me.changing to A. ",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 319505,
          "date": "Tue 28 Sep 2021 08:05",
          "username": "nitinz",
          "content": "changing to A. ",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#691",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company built an ecommerce website on AWS using a three-tier web architecture. The application is Java-based and composed of an Amazon CloudFront distribution, an Apache web server layer of Amazon EC2 instances in an Auto Scaling group, and a backend Amazon Aurora MySQL database.<br>Last month, during a promotional sales event, users reported errors and timeouts while adding items to their shopping carts. The operations team recovered the logs created by the web servers and reviewed Aurora DB cluster performance metrics. Some of the web servers were terminated before logs could be collected and the Aurora metrics were not sufficient for query performance analysis.<br>Which combination of steps must the solutions architect take to improve application performance visibility during peak traffic events? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: ABD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#691",
          "answers": [
            {
              "choice": "<p>A. Configure the Aurora MySQL DB cluster to publish slow query and error logs to Amazon CloudWatch Logs.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Implement the AWS X-Ray SDK to trace incoming HTTP requests on the EC2 instances and implement tracing of SQL queries with the X-Ray SDK for Java.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Configure the Aurora MySQL DB cluster to stream slow query and error logs to Amazon Kinesis<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Install and configure an Amazon CloudWatch Logs agent on the EC2 instances to send the Apache logs to CloudWatch Logs.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Enable and configure AWS CloudTrail to collect and analyze application activity from Amazon EC2 and Aurora.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>F. Enable Aurora MySQL DB cluster performance benchmarking and publish the stream to AWS X-Ray.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 313388,
          "date": "Fri 24 Sep 2021 15:22",
          "username": "wasabidevkpcert",
          "content": "ABD for meA,B and D are correct answers.",
          "upvote_count": "203",
          "selected_answers": ""
        },
        {
          "id": 352637,
          "date": "Tue 19 Oct 2021 16:04",
          "username": "kpcert",
          "content": "A,B and D are correct answers.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 338340,
          "date": "Sun 03 Oct 2021 10:17",
          "username": "CarisBKelvin",
          "content": "Yes, ABD:<br>https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_LogAccess.Concepts.MySQL.html#USER_LogAccess.MySQLDB. PublishAuroraMySQLtoCloudWatchLogs<br>https://aws.amazon.com/blogs/mt/simplifying-apache-server-logs-with-amazon-cloudwatch-logs-insights/<br>https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-dotnet-messagehandler.html<br>https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-java-sqlclients.htmlABD is correct.",
          "upvote_count": "112",
          "selected_answers": ""
        },
        {
          "id": 340090,
          "date": "Sun 10 Oct 2021 18:13",
          "username": "Kelvin",
          "content": "ABD is correct.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 714974,
          "date": "Thu 10 Nov 2022 07:38",
          "username": "janvandermerwer",
          "content": "Going with everyone elses suggestions.<br>A - DB cluster level logs, which cloudwatch will collate for later revision.<br>B - Xray is great for tracing requests/queries<br>D - need some method to send logs from the instances to cloudwatch, this is where the agent can come in.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ABD"
        },
        {
          "id": 693141,
          "date": "Wed 12 Oct 2022 15:56",
          "username": "Blair77",
          "content": "ABD! Let's GO!",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: ABD"
        },
        {
          "id": 577749,
          "date": "Tue 29 Mar 2022 19:08",
          "username": "jj22222",
          "content": "ABD looks right",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ABD"
        },
        {
          "id": 532321,
          "date": "Tue 25 Jan 2022 19:07",
          "username": "shotty1",
          "content": "i think it is abd",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ABD"
        },
        {
          "id": 521552,
          "date": "Tue 11 Jan 2022 14:22",
          "username": "pititcu667",
          "content": "abd for me",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: ABD"
        },
        {
          "id": 496967,
          "date": "Wed 08 Dec 2021 17:58",
          "username": "AzureDP900",
          "content": "I'll go with A,B,D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 449304,
          "date": "Sat 06 Nov 2021 10:28",
          "username": "moon2351",
          "content": "Answer is ABD",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446876,
          "date": "Mon 01 Nov 2021 08:35",
          "username": "andylogan",
          "content": "It's A B D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436564,
          "date": "Fri 29 Oct 2021 18:24",
          "username": "tgv",
          "content": "AAA BBB DDD<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 434005,
          "date": "Thu 28 Oct 2021 16:22",
          "username": "blackgamer",
          "content": "ABD for me as well.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413978,
          "date": "Wed 27 Oct 2021 23:20",
          "username": "WhyIronMan",
          "content": "I'll go with A,B,D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 366920,
          "date": "Wed 27 Oct 2021 18:56",
          "username": "mustpassla",
          "content": "ABD, use case of X-Ray. Send custom logs out using CW agent.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357738,
          "date": "Wed 20 Oct 2021 22:33",
          "username": "Waiweng",
          "content": "it's A,B,D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 343337,
          "date": "Tue 12 Oct 2021 04:22",
          "username": "blackgamer",
          "content": "Yes, ABD",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 316594,
          "date": "Thu 30 Sep 2021 15:00",
          "username": "certainly",
          "content": "ABD sounds good.",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#692",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A solutions architect has an operational workload deployed on Amazon EC2 instances in an Auto Scaling group. The VPC architecture spans two Availability<br>Zones (AZ) with a subnet in each that the Auto Scaling group is targeting. The VPC is connected to an on-premises environment and connectivity cannot be interrupted. The maximum size of the Auto Scaling group is 20 instances in service. The VPC IPv4 addressing is as follows:<br><br>VPC CIDR: 10.0.0.0/23 -<br><br>AZ1 subnet CIDR: 10.0.0.0/24 -<br><br>AZ2 subnet CIDR: 10.0.1.0/24 -<br>Since deployment, a third AZ has become available in the Region. The solutions architect wants to adopt the new AZ without adding additional IPv4 address space and without service downtime.<br>Which solution will meet these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: A</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#692",
          "answers": [
            {
              "choice": "<p>A. Update the Auto Scaling group to use the AZ2 subnet only. Delete and re-create the AZ1 subnet using half the previous address space. Adjust the Auto Scaling group to also use the new AZ1 subnet. When the instances are healthy, adjust the Auto Scaling group to use the AZ1 subnet only. Remove the current AZ2 subnet. Create a new AZ2 subnet using the second half of the address space from the original AZ1 subnet. Create a new AZ3 subnet using half the original AZ2 subnet address space, then update the Auto Scaling group to target all three new subnets.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Terminate the EC2 instances in the AZ1 subnet. Delete and re-create the AZ1 subnet using half the address space. Update the Auto Scaling group to use this new subnet. Repeat this for the second AZ. Define a new subnet in AZ3, then update the Auto Scaling group to target all three new subnets.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create a new VPC with the same IPv4 address space and define three subnets, with one for each AZ. Update the existing Auto Scaling group to target the new subnets in the new VPC. <br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Update the Auto Scaling group to use the AZ2 subnet only. Update the AZ1 subnet to have the previous address space. Adjust the Auto Scaling group to also use the AZ1 subnet again. When the instances are healthy, adjust the Auto Scaling group to use the AZ1 subnet only. Update the current AZ2 subnet and assign the second half of the address space from the original AZ1 subnet. Create a new AZ3 subnet using half the original AZ2 subnet address space, then update the Auto Scaling group to target all three new subnets.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 322632,
          "date": "Thu 23 Sep 2021 16:25",
          "username": "KevinZhong",
          "content": "A<br>-------------------------<br>https://aws.amazon.com/premiumsupport/knowledge-center/vpc-ip-address-range/?nc1=h_ls<br>It's not possible to modify the IP address range of an existing virtual private cloud (VPC) or subnet. You must delete the VPC or subnet, and then create a new VPC or subnet with your preferred CIDR block.",
          "upvote_count": "20",
          "selected_answers": ""
        },
        {
          "id": 313779,
          "date": "Sun 19 Sep 2021 19:37",
          "username": "nitinz",
          "content": "A sounds like it",
          "upvote_count": "6",
          "selected_answers": ""
        },
        {
          "id": 621861,
          "date": "Fri 24 Jun 2022 22:35",
          "username": "kangtamo",
          "content": "Agree with A. ",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 587202,
          "date": "Sun 17 Apr 2022 14:03",
          "username": "dev10fanq10",
          "content": "You need to terminate the instances before you can delete the subnet which option B states. <br>If you no longer need a subnet, you can delete it. You cannot delete a subnet if it contains any network interfaces. For example, you must terminate any instances in a subnet before you can delete it. <br>link: https://docs.aws.amazon.com/vpc/latest/userguide/working-with-subnets.html<br>A: It says delete and recreate, however you need to terminate instances as well which option B points out clearly.<br>C: does not allow to use this approach as VPC is physically attached to on-prem<br>D: Modify is not allowed, you need to delete and create subnetsYou do not need to terminate instances as when you update ASG only use AZ1, it will automatically recreate instances in AZ1, once all the instances created in AZ1, then you can delete the subnet. Tested it in my lab. <br>So answer is A. ",
          "upvote_count": "22",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 698090,
          "date": "Tue 18 Oct 2022 11:43",
          "username": "fanq10",
          "content": "You do not need to terminate instances as when you update ASG only use AZ1, it will automatically recreate instances in AZ1, once all the instances created in AZ1, then you can delete the subnet. Tested it in my lab. <br>So answer is A. ",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 496969,
          "date": "Wed 08 Dec 2021 17:59",
          "username": "AzureDP900",
          "content": "It is A",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446875,
          "date": "Thu 04 Nov 2021 04:46",
          "username": "andylogan",
          "content": "It's A - cannot modify",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 436565,
          "date": "Tue 02 Nov 2021 20:12",
          "username": "tgv",
          "content": "AAA<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 413982,
          "date": "Thu 28 Oct 2021 21:13",
          "username": "WhyIronMan",
          "content": "I'll go with A",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 366923,
          "date": "Sat 23 Oct 2021 20:17",
          "username": "mustpassla",
          "content": "A, no downtime, D is incorrect as CIDR cant be updated in this case.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 363891,
          "date": "Fri 08 Oct 2021 02:56",
          "username": "vkbajoria",
          "content": "it is A, cannot modify CIDR block",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 357744,
          "date": "Sun 26 Sep 2021 22:50",
          "username": "Waiweng",
          "content": "it's A",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 318602,
          "date": "Thu 23 Sep 2021 15:12",
          "username": "eji",
          "content": "The answer is A because we cannot modify the IPv4 CIDR for the subnet so we need to delete and recreate",
          "upvote_count": "4",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#693",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is storing data on premises on a Windows file server. The company produces 5 GB of new data daily.<br>The company migrated part of its Windows-based workload to AWS and needs the data to be available on a file system in the cloud. The company already has established an AWS Direct Connect connection between the on-premises network and AWS.<br>Which data migration strategy should the company use?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#693",
          "answers": [
            {
              "choice": "<p>A. Use the file gateway option in AWS Storage Gateway to replace the existing Windows file server, and point the existing file share to the new file gateway<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon FSx<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use AWS Data Pipeline to schedule a daily task to replicate data between the on-premises Windows file server and Amazon Elastic File System (Amazon EFS)<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon Elastic File System (Amazon EFS)<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 315488,
          "date": "Sun 26 Sep 2021 12:53",
          "username": "awsnoob",
          "content": "B is correct, the workload on cloud relies on the Windows based storage",
          "upvote_count": "20",
          "selected_answers": ""
        },
        {
          "id": 319493,
          "date": "Mon 04 Oct 2021 21:08",
          "username": "chris1025chris1025rb39",
          "content": "I believe it's A.  DataSync is for initial migration but it's not meant for ongoing. The better answer would be to use DataSync first then file gateway.Going with B.  While I believe my initial comment is correct, the questions asks for data migration strategy.A is wrong - question asks about migrating a portion of workloads, no replacement of Windows server",
          "upvote_count": "544",
          "selected_answers": ""
        },
        {
          "id": 326943,
          "date": "Tue 12 Oct 2021 10:36",
          "username": "chris1025rb39",
          "content": "Going with B.  While I believe my initial comment is correct, the questions asks for data migration strategy.A is wrong - question asks about migrating a portion of workloads, no replacement of Windows server",
          "upvote_count": "44",
          "selected_answers": ""
        },
        {
          "id": 499382,
          "date": "Sat 11 Dec 2021 13:14",
          "username": "rb39",
          "content": "A is wrong - question asks about migrating a portion of workloads, no replacement of Windows server",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 728648,
          "date": "Sun 27 Nov 2022 23:08",
          "username": "SureNot",
          "content": "data migration strategy",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 712152,
          "date": "Sun 06 Nov 2022 05:58",
          "username": "alxjandroleiva",
          "content": "B: \\\"and needs the data to be available on a file system in the cloud. \\\"<br>No, access like a file system....on a file system",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 682495,
          "date": "Thu 29 Sep 2022 11:20",
          "username": "JohnPi",
          "content": "It is clear that we need Amazon Fx on the AWS side. For the on-prem, we can achieve this with DataSync or with Amazon FSx File Gateway (https://aws.amazon.com/storagegateway/file/fsx/). Option A is incomplete, cannot decide between A and B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 641897,
          "date": "Wed 03 Aug 2022 14:59",
          "username": "gondohwe",
          "content": "if the company already relocated its workload to the cloud then storage gateway is the way...A make sense tho",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 628798,
          "date": "Fri 08 Jul 2022 16:03",
          "username": "asfsdfsdfNaj_64",
          "content": "Have to choose B - Windows based share file system + Question clearly states \\\"requires data to be accessible through a cloud file system\\\".<br>A - cannot be right since it will use NFS/SMB protocol to cache & transfer files to an S3 bucket which is not a FS.The Storage Gateway can be an FSx File GW, that way the file share data is synchronized with an FSx file system in the cloud.",
          "upvote_count": "21",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 694235,
          "date": "Thu 13 Oct 2022 21:32",
          "username": "Naj_64",
          "content": "The Storage Gateway can be an FSx File GW, that way the file share data is synchronized with an FSx file system in the cloud.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 613570,
          "date": "Thu 09 Jun 2022 03:34",
          "username": "Harry_01",
          "content": "the statement says \\\"Relocated\\\" which means the migration has already happened and now what they want is just access to the data on-prem. So has to be storage gateway.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 609967,
          "date": "Wed 01 Jun 2022 03:49",
          "username": "AnhddAnhdd",
          "content": "It's say that \\\"relocated a portion of its Windows-based workload to AWS\\\". So in this case we have to use Storage Gateway, because we need to access data both from on-premis and on AWS. So we can't use DataSync which is used for transfer 100% data to AWS and keep no data remain on-premis. That's my opinion, so the answer should be ANHso the answer should be A* (my miss spell :D )",
          "upvote_count": "11",
          "selected_answers": "Selected Answer: A"
        },
        {
          "id": 609968,
          "date": "Wed 01 Jun 2022 03:51",
          "username": "Anhdd",
          "content": "so the answer should be A* (my miss spell :D )",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 607637,
          "date": "Thu 26 May 2022 14:29",
          "username": "Racinely",
          "content": "aggreed with hansmong",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 515691,
          "date": "Mon 03 Jan 2022 13:29",
          "username": "hansmongDuke_YUGatesChi",
          "content": "A - access file on s3 from on-prem<br>C - datapipeline is an ETL tool, should be datasync in this case<br>D - efs does not support Windowshttps://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/AmazonEFS.htmlWhy \\\"access file on S3 from on-prem\\\" is not an option? I don't like it but don't think it is impossible.You will need to re-write whatever program using the file share.",
          "upvote_count": "311",
          "selected_answers": ""
        },
        {
          "id": 521192,
          "date": "Tue 11 Jan 2022 00:41",
          "username": "Duke_YUGatesChi",
          "content": "Why \\\"access file on S3 from on-prem\\\" is not an option? I don't like it but don't think it is impossible.You will need to re-write whatever program using the file share.",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 583288,
          "date": "Sat 09 Apr 2022 13:48",
          "username": "GatesChi",
          "content": "You will need to re-write whatever program using the file share.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 501620,
          "date": "Tue 14 Dec 2021 19:58",
          "username": "vbal",
          "content": "You can use AWS DataSync to migrate on-premises data to Amazon S3, Amazon EFS, and Amazon FSx for Windows File Server. Configure DataSync to make an initial copy of your entire dataset, and schedule subsequent incremental transfers of changing data until the final cut-over from on-premises to AWS.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496970,
          "date": "Wed 08 Dec 2021 18:00",
          "username": "AzureDP900",
          "content": "B is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 494216,
          "date": "Sun 05 Dec 2021 11:16",
          "username": "cldyuser0001",
          "content": "B.  Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon FSxB is wrong in this case , A is right",
          "upvote_count": "22",
          "selected_answers": ""
        },
        {
          "id": 597881,
          "date": "Fri 06 May 2022 22:53",
          "username": "user0001",
          "content": "B is wrong in this case , A is right",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 446929,
          "date": "Sun 07 Nov 2021 00:22",
          "username": "andylogan",
          "content": "It's B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 439641,
          "date": "Thu 04 Nov 2021 10:37",
          "username": "student22",
          "content": "B<br>'needs the data to be available on a file system in the cloud'",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435308,
          "date": "Wed 03 Nov 2021 21:53",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#694",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company uses AWS Organizations to manage one parent account and nine member accounts. The number of member accounts is expected to grow as the business grows. A security engineer has requested consolidation of AWS CloudTrail logs into the parent account for compliance purposes. Existing logs currently stored in Amazon S3 buckets in each individual member account should not be lost. Future member accounts should comply with the logging strategy.<br>Which operationally efficient solution meets these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#694",
          "answers": [
            {
              "choice": "<p>A. Create an AWS Lambda function in each member account with a cross-account role. Trigger the Lambda functions when new CloudTrail logs are created and copy the CloudTrail logs to a centralized S3 bucket. Set up an Amazon CloudWatch alarm to alert if CloudTrail is not configured properly.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Configure CloudTrail in each member account to deliver log events to a central S3 bucket. Ensure the central S3 bucket policy allows PutObject access from the member accounts. Migrate existing logs to the central S3 bucket. Set up an Amazon CloudWatch alarm to alert if CloudTrail is not configured properly.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Configure an organization-level CloudTrail in the parent account to deliver log events to a central S3 bucket. Migrate the existing CloudTrail logs from each member account to the central S3 bucket. Delete the existing CloudTrail and logs in the member accounts.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Configure an organization-level CloudTrail in the parent account to deliver log events to a central S3 bucket. Configure CloudTrail in each member account to deliver log events to the central S3 bucket.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 316711,
          "date": "Sat 25 Sep 2021 12:39",
          "username": "kalyan_krishna742020",
          "content": "I think answer is C.  <br>https://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html",
          "upvote_count": "15",
          "selected_answers": ""
        },
        {
          "id": 329993,
          "date": "Mon 11 Oct 2021 06:07",
          "username": "ExtHo",
          "content": "C is correct <br>https://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html<br>see section Best practices for moving from member account trails to organization trails why delete the existing CloudTrail and logs in the member accounts <br>Thanks tokalyan_krishna742020 providing official AWS link",
          "upvote_count": "9",
          "selected_answers": ""
        },
        {
          "id": 649581,
          "date": "Sun 21 Aug 2022 04:36",
          "username": "Kyperos",
          "content": "I think that consolidate Cloudtrail Log will stream logs all member accounts to parent accounts. If choose D, existing logs in member account still retain in S3 bucket member account. If choose C,existing logs in member account are migrated to S3 bucket central account.<br>So C will adhere to consolidate logging approach! --> Answer is C",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 645041,
          "date": "Wed 10 Aug 2022 16:55",
          "username": "Andykris",
          "content": "B & C is deleting existing logs which defeats the requirements. D is the answer",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 628803,
          "date": "Fri 08 Jul 2022 16:13",
          "username": "asfsdfsdf",
          "content": "Have to choose C. <br>The \\\"most operationally efficient solution\\\" is to create 1 org trail which capture and send events to a central bucket- deploy it on all member accounts- move old member accounts logs to the central buckets and delete them. see below link:<br>https://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 627820,
          "date": "Wed 06 Jul 2022 12:16",
          "username": "ksarusb333",
          "content": "People those answered C - note that the question states that logs must be retained in the member account S3 buckets and this option deletes them.<br>Hence, D is correct.The logs should not be lost, so you copy them to the centralized bucket. Then there is no more need for them in the member accounts. The question does not state that they must remain in the member accounts. The answer is C. ",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 692216,
          "date": "Tue 11 Oct 2022 17:19",
          "username": "sb333",
          "content": "The logs should not be lost, so you copy them to the centralized bucket. Then there is no more need for them in the member accounts. The question does not state that they must remain in the member accounts. The answer is C. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 622520,
          "date": "Sun 26 Jun 2022 13:42",
          "username": "kangtamo",
          "content": "Agree with C. ",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 594931,
          "date": "Sat 30 Apr 2022 11:13",
          "username": "TechIsi",
          "content": "Correct answer is C, when you create an organizational trail and specify a bucket, all account trails are automatically configured to send to that bucket. You also have to configure the bucket policy to allow put action for all the accounts.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 584977,
          "date": "Wed 13 Apr 2022 05:42",
          "username": "westcon",
          "content": "DDD<br>https://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 578123,
          "date": "Wed 30 Mar 2022 09:43",
          "username": "jj22222",
          "content": "D.  Configure an organization-level CloudTrail in the parent account to deliver log events to a central S3 bucket. Configure CloudTrail in each member account to deliver log events to the central S3 bucket.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 553641,
          "date": "Tue 22 Feb 2022 12:57",
          "username": "lifebegins",
          "content": "Sorry Dear Friends, Answer is C. <br>We can created the CloudTrail in Parent Account and the set the level to Entire Orgranization, Automatically Cloud Trail applied to all member accounts.<br><br>When i practically done, I understand the Truth. <br>Answer is C:",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 553632,
          "date": "Tue 22 Feb 2022 12:45",
          "username": "lifebegins",
          "content": "Answer B: <br>https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-receive-logs-from-multiple-accounts.html<br><br>Cloud Trail cannot manage the logs for others. Only Destination bucket can be shared centrally",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 553626,
          "date": "Tue 22 Feb 2022 12:39",
          "username": "lifebegins",
          "content": "Answer is B:<br><br>https://d0.awsstatic.com/aws-answers/AWS_Multi_Account_Security_Strategy.pdf<br><br>Refer Logging Account Structure",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 552957,
          "date": "Mon 21 Feb 2022 16:30",
          "username": "Yardenfayer",
          "content": "its D<br>https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-receive-logs-from-multiple-accounts.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 550773,
          "date": "Sat 19 Feb 2022 09:39",
          "username": "futen0326Alvindo",
          "content": "It's D.  Question explicitly states that the logs in the member accounts should not be lost. Deleting them does exactly that.thought that as well BUT answer c says to migrate the existing logs to central s3 bucket so it wouldn't be lost and i believe enabling cloud trail(whole organization) in the central account is enough and you don't need to do it in each account",
          "upvote_count": "11",
          "selected_answers": "Selected Answer: D"
        },
        {
          "id": 561360,
          "date": "Sat 05 Mar 2022 11:23",
          "username": "Alvindo",
          "content": "thought that as well BUT answer c says to migrate the existing logs to central s3 bucket so it wouldn't be lost and i believe enabling cloud trail(whole organization) in the central account is enough and you don't need to do it in each account",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 536842,
          "date": "Mon 31 Jan 2022 11:46",
          "username": "HellGate",
          "content": "My answer is C.  <br>We don't need to use Lambda function to move logs...<br><br>https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-receive-logs-from-multiple-accounts.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496972,
          "date": "Wed 08 Dec 2021 18:01",
          "username": "AzureDP900",
          "content": "I will go with C",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#695",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A weather service provides high-resolution weather maps from a web application hosted on AWS in the eu-west-1 Region. The weather maps are updated frequently and stored in Amazon S3 along with static HTML content. The web application is fronted by Amazon CloudFront.<br>The company recently expanded to serve users in the us-east-1 Region, and these new users report that viewing their respective weather maps is slow from time to time.<br>Which combination of steps will resolve the us-east-1 performance issues? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#695",
          "answers": [
            {
              "choice": "<p>A. Configure the AWS Global Accelerator endpoint for the S3 bucket in eu-west-1. Configure endpoint groups for TCP ports 80 and 443 in us-east-1.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create a new S3 bucket in us-east-1. Configure S3 cross-Region replication to synchronize from the S3 bucket in eu-west-1.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use Lambda@Edge to modify requests from North America to use the S3 Transfer Acceleration endpoint in us-east-1.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use Lambda@Edge to modify requests from North America to use the S3 bucket in us-east-1.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Configure the AWS Global Accelerator endpoint for us-east-1 as an origin on the CloudFront distribution. Use Lambda@Edge to modify requests from North America to use the new origin.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 313333,
          "date": "Tue 21 Sep 2021 21:29",
          "username": "wasabidevnitinz",
          "content": "BD.  with replication there is not more need to use S3 Transfer Accelerationi agree",
          "upvote_count": "251",
          "selected_answers": ""
        },
        {
          "id": 313790,
          "date": "Sun 26 Sep 2021 01:14",
          "username": "nitinz",
          "content": "i agree",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 317028,
          "date": "Fri 01 Oct 2021 22:24",
          "username": "KevinZhongcertainlycertainlyKevinZhong",
          "content": "BC<br>Seems S3 Transfer Acceleration it better to work with Edge.<br>-------------<br>Amazon S3 Transfer Acceleration is a bucket-level feature that enables fast, easy, and secure transfers of files over long distances between your client and an S3 bucket. Transfer Acceleration takes advantage of the globally distributed edge locations in Amazon CloudFront.sorry, upvoted by mistake. BD are correct. <br>S3 Transfer Acceleration is for upload not download.https://aws.amazon.com/about-aws/whats-new/2016/04/transfer-files-into-amazon-s3-up-to-300-percent-faster/my bad, it's also can be used for download from s3. <br>https://aws.amazon.com/blogs/aws/aws-storage-update-amazon-s3-transfer-acceleration-larger-snowballs-in-more-regions<br>however,i still think it is not needed as the maps are updated frequently so caching should not help much.changed my mind to BD, seems it's not the case to use Transfer Acceleration<br>------------------<br>Why use Transfer Acceleration?<br>You might want to use Transfer Acceleration on a bucket for various reasons:<br> 1. Your customers upload to a centralized bucket from all over the world.<br> 2. You transfer gigabytes to terabytes of data on a regular basis across continents.<br> 3. You can't use all of your available bandwidth over the internet when uploading to Amazon S3.",
          "upvote_count": "6327",
          "selected_answers": ""
        },
        {
          "id": 317647,
          "date": "Wed 06 Oct 2021 13:52",
          "username": "certainlycertainly",
          "content": "sorry, upvoted by mistake. BD are correct. <br>S3 Transfer Acceleration is for upload not download.https://aws.amazon.com/about-aws/whats-new/2016/04/transfer-files-into-amazon-s3-up-to-300-percent-faster/my bad, it's also can be used for download from s3. <br>https://aws.amazon.com/blogs/aws/aws-storage-update-amazon-s3-transfer-acceleration-larger-snowballs-in-more-regions<br>however,i still think it is not needed as the maps are updated frequently so caching should not help much.",
          "upvote_count": "32",
          "selected_answers": ""
        },
        {
          "id": 317660,
          "date": "Fri 08 Oct 2021 18:44",
          "username": "certainly",
          "content": "my bad, it's also can be used for download from s3. <br>https://aws.amazon.com/blogs/aws/aws-storage-update-amazon-s3-transfer-acceleration-larger-snowballs-in-more-regions<br>however,i still think it is not needed as the maps are updated frequently so caching should not help much.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 320921,
          "date": "Tue 12 Oct 2021 07:42",
          "username": "KevinZhong",
          "content": "changed my mind to BD, seems it's not the case to use Transfer Acceleration<br>------------------<br>Why use Transfer Acceleration?<br>You might want to use Transfer Acceleration on a bucket for various reasons:<br> 1. Your customers upload to a centralized bucket from all over the world.<br> 2. You transfer gigabytes to terabytes of data on a regular basis across continents.<br> 3. You can't use all of your available bandwidth over the internet when uploading to Amazon S3.",
          "upvote_count": "7",
          "selected_answers": ""
        },
        {
          "id": 691422,
          "date": "Mon 10 Oct 2022 20:34",
          "username": "tomosabc1tomosabc1",
          "content": "Similar to StanM's response, I don't think S3 cross region replication is a good fit for this scenario, as weather map are updated frequently. The CRR replication lag means that the users in us-east-1 is always 15 minutes(or even 2 hours) slower than the users in eu-west-1 in seeing the updated weather data, which doesn't sound right in a real world scenario.<br><br>S3 CRR Replication Lag<br>Cross-Region Replication is an asynchronous process, and the objects are eventually replicated. Most objects replicate within 15 minutes, but sometimes replication can take a couple hours or more. <br>https://aws.amazon.com/premiumsupport/knowledge-center/s3-crr-replication-time/<br><br>Can anyone explain why AC is wrong?Of course, BD surely resolves the issue in question, that is, these new users report that viewing their respective weather maps is slow from time to time. But it will create a new issue, which is the users in us-east-1 is always 15 minutes(or even 2 hours) slower than the users in eu-west-1 in seeing the updated weather data. That's not good.",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 691425,
          "date": "Mon 10 Oct 2022 20:39",
          "username": "tomosabc1",
          "content": "Of course, BD surely resolves the issue in question, that is, these new users report that viewing their respective weather maps is slow from time to time. But it will create a new issue, which is the users in us-east-1 is always 15 minutes(or even 2 hours) slower than the users in eu-west-1 in seeing the updated weather data. That's not good.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 605444,
          "date": "Sun 22 May 2022 14:02",
          "username": "p2010",
          "content": "S3 Transfer Acceleration is for upload not download",
          "upvote_count": "3",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 597898,
          "date": "Fri 06 May 2022 23:50",
          "username": "user0001",
          "content": "C is wrong, you can't configure o use the S3 Transfer Acceleration endpoint in us-east-1",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 569703,
          "date": "Thu 17 Mar 2022 13:14",
          "username": "kenchou73",
          "content": "https://aws.amazon.com/blogs/apn/using-amazon-cloudfront-with-multi-region-amazon-s3-origins/",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 568805,
          "date": "Wed 16 Mar 2022 07:24",
          "username": "RVD",
          "content": "ANS: BD are correct, C is use for data upload to local region or nearest region and from there it will transfer to destination bucket using aws backbone",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BD"
        },
        {
          "id": 496977,
          "date": "Wed 08 Dec 2021 18:08",
          "username": "AzureDP900",
          "content": "I'll go with B, D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 494290,
          "date": "Sun 05 Dec 2021 12:56",
          "username": "cldy",
          "content": "B.  Create a new S3 bucket in us-east-1. Configure S3 cross-Region replication to synchronize from the S3 bucket in eu-west-1.<br>D.  Use Lambda@Edge to modify requests from North America to use the S3 bucket in us-east-1.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 482286,
          "date": "Sat 20 Nov 2021 07:16",
          "username": "backfringe",
          "content": "B and D",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 446948,
          "date": "Wed 03 Nov 2021 13:08",
          "username": "andylogan",
          "content": "It's B D - since S3 Transfer Acceleration for transferring of files over long distances<br>this case we need replica and Lambda@Edge",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 439699,
          "date": "Wed 03 Nov 2021 01:33",
          "username": "DerekKey",
          "content": "B&D correct. see also<br>https://aws.amazon.com/blogs/networking-and-content-delivery/dynamically-route-viewer-requests-to-any-origin-using-lambdaedge/",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 438366,
          "date": "Sat 30 Oct 2021 11:48",
          "username": "Kopa",
          "content": "B,D Company that has implemented the same scenarios says:<br><br>To serve content from these other regions, we need to route requests to the different Amazon S3 buckets we’re using. In this post, we explore how to accomplished this by using Amazon CloudFront as a content delivery network and Lambda@Edge as a router. We will also take a quick look at how this impacts latency and cost.<br><br>Reference : https://aws.amazon.com/blogs/apn/using-amazon-cloudfront-with-multi-region-amazon-s3-origins/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 436570,
          "date": "Fri 29 Oct 2021 09:40",
          "username": "tgv",
          "content": "BBB DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 434012,
          "date": "Wed 27 Oct 2021 21:00",
          "username": "blackgamer",
          "content": "B and D for sure.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 414008,
          "date": "Tue 26 Oct 2021 05:54",
          "username": "WhyIronMan",
          "content": "I'll go with B, D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 383993,
          "date": "Thu 21 Oct 2021 06:38",
          "username": "Waiweng",
          "content": "it's B,D",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#696",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company is deploying a public-facing global application on AWS using Amazon CloudFront. The application communicates with an external system. A solutions architect needs to ensure the data is secured during end-to-end transit and at rest.<br>Which combination of steps will satisfy these requirements? (Choose three.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: BDE</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#696",
          "answers": [
            {
              "choice": "<p>A. Create a public certificate for the required domain in AWS Certificate Manager and deploy it to CloudFront, an Application Load Balancer, and Amazon EC2 instances.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Acquire a public certificate from a third-party vendor and deploy it to CloudFront, an Application Load Balancer, and Amazon EC2 instances.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Provision Amazon EBS encrypted volumes using AWS KMS and ensure explicit encryption of data when writing to Amazon EBS.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Provision Amazon EBS encrypted volumes using AWS KMS.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Use SSL or encrypt data while communicating with the external system using a VPN.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>F. Communicate with the external system using plaintext and use the VPN to encrypt the data in transit.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 316534,
          "date": "Mon 27 Sep 2021 09:40",
          "username": "SD13certainlytuananhngoWhyIronMan",
          "content": "Correct Options: BDE<br>C is asking for explicit encryption on top of EBS encryption with KMS, I believe it's not needed.I Agree. explicit encryption on top of EBS encryption with KMS just sounds weirdA IS BETTER THAN BA is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included<br><br>https://docs.aws.amazon.com/acm/latest/userguide/acm-services.html",
          "upvote_count": "171317",
          "selected_answers": ""
        },
        {
          "id": 317666,
          "date": "Sun 03 Oct 2021 02:54",
          "username": "certainly",
          "content": "I Agree. explicit encryption on top of EBS encryption with KMS just sounds weird",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 403032,
          "date": "Sun 17 Oct 2021 11:13",
          "username": "tuananhngoWhyIronMan",
          "content": "A IS BETTER THAN BA is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included<br><br>https://docs.aws.amazon.com/acm/latest/userguide/acm-services.html",
          "upvote_count": "317",
          "selected_answers": ""
        },
        {
          "id": 414010,
          "date": "Thu 21 Oct 2021 03:56",
          "username": "WhyIronMan",
          "content": "A is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included<br><br>https://docs.aws.amazon.com/acm/latest/userguide/acm-services.html",
          "upvote_count": "17",
          "selected_answers": ""
        },
        {
          "id": 318612,
          "date": "Mon 04 Oct 2021 10:43",
          "username": "eji",
          "content": "BDE for me, we cannot use \\\"public\\\" certificate for ec2 from amazon certificate manager, so A cannot be the answer. and for C i agree with SD13 i think explicit encryption it's not needed",
          "upvote_count": "8",
          "selected_answers": ""
        },
        {
          "id": 714201,
          "date": "Wed 09 Nov 2022 02:19",
          "username": "due",
          "content": "vote BDE",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 679926,
          "date": "Mon 26 Sep 2022 18:03",
          "username": "dcdcdc3",
          "content": "IRL we use self-signed cert between LB and the ec2 (or private from ACM). The way the answer is written A cannot be true.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496796,
          "date": "Wed 08 Dec 2021 13:08",
          "username": "cldy",
          "content": "B.  Acquire a public certificate from a third-party vendor and deploy it to CloudFront, an Application Load Balancer, and Amazon EC2 instances.<br>D.  Provision Amazon EBS encrypted volumes using AWS KMS.<br>E.  Use SSL or encrypt data while communicating with the external system using a VPN.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 484030,
          "date": "Mon 22 Nov 2021 10:19",
          "username": "acloudguru",
          "content": "A is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included<br><br>https://docs.aws.amazon.com/acm/latest/userguide/acm-services.html<br>C is asking for explicit encryption on top of EBS encryption with KMS, I believe it's not needed.",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: BDE"
        },
        {
          "id": 459431,
          "date": "Sun 07 Nov 2021 13:23",
          "username": "student22",
          "content": "B,D,E<br>---<br>Q: With which AWS services can I use ACM certificates?<br><br>You can use public and private ACM certificates with the following AWS services:<br>• Elastic Load Balancing – Refer to the Elastic Load Balancing documentation<br>• Amazon CloudFront – Refer to the CloudFront documentation<br>• Amazon API Gateway – Refer to the API Gateway documentation<br>• AWS Elastic Beanstalk – Refer to the AWS Elastic Beanstalk documentation<br>• AWS CloudFormation – Support is currently limited to public certificates that use email validation. Refer to the AWS CloudFormation documentation <br><br>In addition, you can use private certificates issued with ACM Private CA with EC2 instances, containers, IoT devices, and on your own servers.<br><br>https://aws.amazon.com/certificate-manager/faqs/?nc1=h_ls",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 446958,
          "date": "Thu 04 Nov 2021 19:14",
          "username": "andylogan",
          "content": "It's B D E",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 435312,
          "date": "Wed 03 Nov 2021 12:03",
          "username": "tgv",
          "content": "BBB DDD EEE<br>---<br>https://aws.amazon.com/certificate-manager/faqs/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 434016,
          "date": "Tue 02 Nov 2021 10:15",
          "username": "blackgamer",
          "content": "BDE is correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 414009,
          "date": "Tue 19 Oct 2021 10:57",
          "username": "WhyIronMan",
          "content": "I'll go with B,D,E<br><br>Q: Can I use certificates on Amazon EC2 instances or on my own servers?<br><br>You can use private certificates issued with ACM Private CA with EC2 instances, containers, and on your own servers. At this time, public ACM certificates can be used only with specific AWS services. See With which AWS services can I use ACM certificates?<br><br>https://aws.amazon.com/certificate-manager/faqs/?nc1=h_ls",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 398613,
          "date": "Sun 17 Oct 2021 04:37",
          "username": "DashL",
          "content": "BDE<br>For those answering ADE:<br>HTTPS between viewers and CloudFront – You can use a certificate that was issued by a trusted certificate authority (CA) such as Comodo, DigiCert, or Symantec, or you can use a certificate provided by AWS Certificate Manager (ACM).<br>HTTPS between CloudFront and a custom origin – If the origin is not an Elastic Load Balancing (ELB) load balancer, such as Amazon EC2, the certificate must be issued by a trusted CA such as Comodo, DigiCert, or Symantec. If your origin is an ELB load balancer, you can also use a certificate provided by ACM.<br>For SSL Between ELB and EC2: Amazon-issued certificates can’t be installed on an EC2 instance. To enable end-to-end encryption, you must use a third-party SSL certificate. Install the third-party certificate on an EC2 instance. Then, associate the third-party certificate with a load balancer by importing it into AWS Certificate Manager (ACM) (https://aws.amazon.com/premiumsupport/knowledge-center/acm-ssl-certificate-ec2-elb/)<br>The requirement of 3rd party cert between ELB and EC2 makes Option A is invalid.",
          "upvote_count": "4",
          "selected_answers": ""
        },
        {
          "id": 385628,
          "date": "Sat 16 Oct 2021 20:17",
          "username": "hk436",
          "content": "BDE are my answers!!",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 382900,
          "date": "Sat 16 Oct 2021 08:50",
          "username": "chkmtessogryzek",
          "content": "BDE<br>Explanation for B - \\\"You can't export an Amazon Issued ACM public certificate for use on an EC2 instance because ACM manages the private key.\\\"<br>https://aws.amazon.com/premiumsupport/knowledge-center/configure-acm-certificates-ec2/What about get-certificate . Doesn't it export cert with whole chain. For me it is still AC<br>https://docs.aws.amazon.com/cli/latest/reference/acm/get-certificate.html",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 405274,
          "date": "Mon 18 Oct 2021 07:46",
          "username": "ogryzek",
          "content": "What about get-certificate . Doesn't it export cert with whole chain. For me it is still AC<br>https://docs.aws.amazon.com/cli/latest/reference/acm/get-certificate.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 381354,
          "date": "Fri 15 Oct 2021 20:53",
          "username": "TonyGe",
          "content": "BED for sure.<br>A is incorrect, public cert cannot be used in EC2.",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 380359,
          "date": "Wed 13 Oct 2021 11:16",
          "username": "ElreySham",
          "content": "You generate the certificate for CF.  Answer is ADE. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 357778,
          "date": "Tue 12 Oct 2021 08:21",
          "username": "WaiwengWhyIronManKopa",
          "content": "it's A,D,EA is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included<br><br>https://docs.aws.amazon.com/acm/latest/userguide/acm-services.htmlCan you please argument why its A? Thanks",
          "upvote_count": "331",
          "selected_answers": ""
        },
        {
          "id": 414011,
          "date": "Thu 21 Oct 2021 21:30",
          "username": "WhyIronMan",
          "content": "A is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included<br><br>https://docs.aws.amazon.com/acm/latest/userguide/acm-services.html",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 414480,
          "date": "Mon 01 Nov 2021 05:24",
          "username": "Kopa",
          "content": "Can you please argument why its A? Thanks",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#697",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company provides a centralized Amazon EC2 application hosted in a single shared VPC.  The centralized application must be accessible from client applications running in the VPCs of other business units. The centralized application front end is configured with a Network Load Balancer (NLB) for scalability.<br>Up to 10 business unit VPCs will need to be connected to the shared VPC.  Some of the business unit VPC CIDR blocks overlap with the shared VPC, and some overlap with each other. Network connectivity to the centralized application in the shared VPC should be allowed from authorized business unit VPCs only.<br>Which network configuration should a solutions architect use to provide connectivity from the client applications in the business unit VPCs to the centralized application in the shared VPC?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: B</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#697",
          "answers": [
            {
              "choice": "<p>A. Create an AWS Transit Gateway. Attach the shared VPC and the authorized business unit VPCs to the transit gateway. Create a single transit gateway route table and associate it with all of the attached VPCs. Allow automatic propagation of routes from the attachments into the route table. Configure VPC routing tables to send traffic to the transit gateway.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create a VPC endpoint service using the centralized application NLB and enable the option to require endpoint acceptance. Create a VPC endpoint in each of the business unit VPCs using the service name of the endpoint service. Accept authorized endpoint requests from the endpoint service console.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>C. Create a VPC peering connection from each business unit VPC to the shared VPC.  Accept the VPC peering connections from the shared VPC console. Configure VPC routing tables to send traffic to the VPC peering connection.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Configure a virtual private gateway for the shared VPC and create customer gateways for each of the authorized business unit VPCs. Establish a Site-to-Site VPN connection from the business unit VPCs to the shared VPC.  Configure VPC routing tables to send traffic to the VPN connection.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 313141,
          "date": "Fri 01 Oct 2021 01:05",
          "username": "wasabidevDashL",
          "content": "B.  Transit Gateway doesn't support routing between VPCwith identical CIDRsAmazon Transit Gateway doesn’t support routing between Amazon VPCs with overlapping CIDRs. If you attach a new Amazon VPC that has a CIDR which overlaps with an already attached Amazon VPC, Amazon Transit Gateway will not propagate the new Amazon VPC route into the Amazon Transit Gateway route table.",
          "upvote_count": "193",
          "selected_answers": ""
        },
        {
          "id": 398620,
          "date": "Sat 09 Oct 2021 22:39",
          "username": "DashL",
          "content": "Amazon Transit Gateway doesn’t support routing between Amazon VPCs with overlapping CIDRs. If you attach a new Amazon VPC that has a CIDR which overlaps with an already attached Amazon VPC, Amazon Transit Gateway will not propagate the new Amazon VPC route into the Amazon Transit Gateway route table.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 430603,
          "date": "Thu 14 Oct 2021 02:57",
          "username": "tvskirrim",
          "content": "B.  Use NLB VPC endpoint service name overcome CIDR overlap issues.Agree!<br><br>NLBs always SNAT the client source IP address to their own IP within your VPC when the incoming request to the NLB via a gateway load balancer endpoint or vpc endpoint (private link):<br><br>https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-target-groups.html#client-ip-preservation<br><br>(This can be annoying if you want the NLB's client IP preservation feature!)",
          "upvote_count": "72",
          "selected_answers": ""
        },
        {
          "id": 463666,
          "date": "Sun 24 Oct 2021 12:08",
          "username": "kirrim",
          "content": "Agree!<br><br>NLBs always SNAT the client source IP address to their own IP within your VPC when the incoming request to the NLB via a gateway load balancer endpoint or vpc endpoint (private link):<br><br>https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-target-groups.html#client-ip-preservation<br><br>(This can be annoying if you want the NLB's client IP preservation feature!)",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 628807,
          "date": "Fri 08 Jul 2022 16:20",
          "username": "asfsdfsdf",
          "content": "B - classic use cased for PrivateLink (NLB +EP) all other options are out due to overlapping CIDRs not possible to route it",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 514362,
          "date": "Sat 01 Jan 2022 05:49",
          "username": "cldy",
          "content": "B correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496979,
          "date": "Wed 08 Dec 2021 18:11",
          "username": "AzureDP900",
          "content": "I'll go with B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 491033,
          "date": "Tue 30 Nov 2021 23:30",
          "username": "acloudguru",
          "content": "A is not useful for overlap CIDR. B, use NLB's vpc endpoint",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: B"
        },
        {
          "id": 436574,
          "date": "Sun 24 Oct 2021 00:37",
          "username": "tgv",
          "content": "BBB<br>---",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 434034,
          "date": "Wed 20 Oct 2021 02:53",
          "username": "blackgamer",
          "content": "It is B",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 414019,
          "date": "Wed 13 Oct 2021 22:00",
          "username": "WhyIronMan",
          "content": "I'll go with B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 357786,
          "date": "Thu 07 Oct 2021 15:01",
          "username": "Waiweng",
          "content": "it's B",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 317419,
          "date": "Tue 05 Oct 2021 00:20",
          "username": "aws_master",
          "content": "B for sure",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 316542,
          "date": "Fri 01 Oct 2021 20:20",
          "username": "SD13",
          "content": "Correct option : B",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 313130,
          "date": "Sat 25 Sep 2021 07:06",
          "username": "gm",
          "content": "Yes, B",
          "upvote_count": "5",
          "selected_answers": ""
        },
        {
          "id": 308871,
          "date": "Mon 20 Sep 2021 08:06",
          "username": "kalyan_krishna742020kalyan_krishna742020",
          "content": "Ans: C<br>https://docs.aws.amazon.com/vpc/latest/peering/peering-configurations-partial-access.htmlMy bad.. it is B.  <br>https://aws.amazon.com/blogs/networking-and-content-delivery/how-to-securely-publish-internet-applications-at-scale-using-application-load-balancer-and-aws-privatelink/",
          "upvote_count": "38",
          "selected_answers": ""
        },
        {
          "id": 308874,
          "date": "Wed 22 Sep 2021 01:25",
          "username": "kalyan_krishna742020",
          "content": "My bad.. it is B.  <br>https://aws.amazon.com/blogs/networking-and-content-delivery/how-to-securely-publish-internet-applications-at-scale-using-application-load-balancer-and-aws-privatelink/",
          "upvote_count": "8",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#698",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A company has an on-premises monitoring solution using a PostgreSQL database for persistence of events. The database is unable to scale due to heavy ingestion and it frequently runs out of storage.<br>The company wants to create a hybrid solution and has already set up a VPN connection between its network and AWS. The solution should include the following attributes:<br>✑ Managed AWS services to minimize operational complexity.<br>✑ A buffer that automatically scales to match the throughput of data and requires no ongoing administration.<br>✑ A visualization tool to create dashboards to observe events in near-real time.<br>✑ Support for semi-structured JSON data and dynamic schemas.<br>Which combination of components will enable the company to create a monitoring solution that will satisfy these requirements? (Choose two.)<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": true,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: AD</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#698",
          "answers": [
            {
              "choice": "<p>A. Use Amazon Kinesis Data Firehose to buffer events. Create an AWS Lambda function to process and transform events.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>B. Create an Amazon Kinesis data stream to buffer events. Create an AWS Lambda function to process and transform events.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Configure an Amazon Aurora PostgreSQL DB cluster to receive events. Use Amazon QuickSight to read from the database and create near-real-time visualizations and dashboards.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>D. Configure Amazon Elasticsearch Service (Amazon ES) to receive events. Use the Kibana endpoint deployed with Amazon ES to create near-real-time visualizations and dashboards.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>E. Configure an Amazon Neptune DB instance to receive events. Use Amazon QuickSight to read from the database and create near-real-time visualizations and dashboards.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 343653,
          "date": "Fri 22 Oct 2021 03:19",
          "username": "ExtHoDashL",
          "content": "A is correct instead Band Final answer AD. <br>https://aws.amazon.com/kinesis/data-firehose/faqs/<br>Q: What is Amazon Kinesis Data Firehose?<br>It is a fully managed service that automatically scales to match the throughput of your data and requires no ongoing administration.Unlike some other AWS services, Kinesis does not provide a native auto-scaling solution like DynamoDB On-Demand or EC2 Auto Scaling. Therefore, there is a need for the right number of shards to be calculated for every stream based on the expected number of records and/or the size of the records. This can lead to over/under-provisioning of shards within a stream resulting in higher costs and/or data ingestion being throttled.",
          "upvote_count": "153",
          "selected_answers": ""
        },
        {
          "id": 398622,
          "date": "Thu 28 Oct 2021 08:08",
          "username": "DashL",
          "content": "Unlike some other AWS services, Kinesis does not provide a native auto-scaling solution like DynamoDB On-Demand or EC2 Auto Scaling. Therefore, there is a need for the right number of shards to be calculated for every stream based on the expected number of records and/or the size of the records. This can lead to over/under-provisioning of shards within a stream resulting in higher costs and/or data ingestion being throttled.",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 357790,
          "date": "Sun 24 Oct 2021 14:30",
          "username": "Waiweng",
          "content": "It's A&D",
          "upvote_count": "8",
          "selected_answers": ""
        },
        {
          "id": 645645,
          "date": "Fri 12 Aug 2022 02:04",
          "username": "AndykrisAndykris",
          "content": "D because data is semi structure.A becase Kenisis data firehose can scale and handle data traffic",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 645646,
          "date": "Fri 12 Aug 2022 02:06",
          "username": "Andykris",
          "content": "A becase Kenisis data firehose can scale and handle data traffic",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 613094,
          "date": "Wed 08 Jun 2022 08:09",
          "username": "Anhdd",
          "content": "I still dont understand why choose D over C.  Amazon QuickSight do the same thing as Kibana isn't it?",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 603118,
          "date": "Wed 18 May 2022 04:14",
          "username": "Niaj",
          "content": "AD for sure is the right answer here",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: AD"
        },
        {
          "id": 542545,
          "date": "Mon 07 Feb 2022 17:44",
          "username": "jj22222",
          "content": "a and D look right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 516936,
          "date": "Tue 04 Jan 2022 20:22",
          "username": "shaiker",
          "content": "es is the only one doing the json unstructured data in the list. Aurora is relational and requires structured schema. firehose stream near realtime into es",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: AD"
        },
        {
          "id": 515457,
          "date": "Mon 03 Jan 2022 08:51",
          "username": "tkanmani76fanq10fanq10Anhddtkanmani76",
          "content": "A is fine. <br>C - Why not QuickSight ? As this specifically handles embeddable dashboards with visualizations on real time basis. Kibana can as well do this along with ES - but why not QuickSight - AWS solution for dashboards ?.Why C? Here is the answer:<br>https://www.elastic.co/guide/en/elasticsearch/reference/current/near-real-time.html<br>Therefore, Amazon ES + kibanaSorry, a typo - Correction -> Why NOT C? Here is the answer:<br>https://www.elastic.co/guide/en/elasticsearch/reference/current/near-real-time.html<br>Therefore, the Answer is D: Amazon ES + kibanaseem that Aurora is relational and requires structured schema, while the question require the json unstructured data. In my opinionSupporting Links - Confirming Quicksight support for handling JSON Semi structured data as well ..https://docs.aws.amazon.com/quicksight/latest/user/supported-data-sources.html",
          "upvote_count": "21111",
          "selected_answers": ""
        },
        {
          "id": 698803,
          "date": "Wed 19 Oct 2022 10:07",
          "username": "fanq10fanq10",
          "content": "Why C? Here is the answer:<br>https://www.elastic.co/guide/en/elasticsearch/reference/current/near-real-time.html<br>Therefore, Amazon ES + kibanaSorry, a typo - Correction -> Why NOT C? Here is the answer:<br>https://www.elastic.co/guide/en/elasticsearch/reference/current/near-real-time.html<br>Therefore, the Answer is D: Amazon ES + kibana",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 698805,
          "date": "Wed 19 Oct 2022 10:09",
          "username": "fanq10",
          "content": "Sorry, a typo - Correction -> Why NOT C? Here is the answer:<br>https://www.elastic.co/guide/en/elasticsearch/reference/current/near-real-time.html<br>Therefore, the Answer is D: Amazon ES + kibana",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 613097,
          "date": "Wed 08 Jun 2022 08:11",
          "username": "Anhdd",
          "content": "seem that Aurora is relational and requires structured schema, while the question require the json unstructured data. In my opinion",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 515465,
          "date": "Mon 03 Jan 2022 09:00",
          "username": "tkanmani76",
          "content": "Supporting Links - Confirming Quicksight support for handling JSON Semi structured data as well ..https://docs.aws.amazon.com/quicksight/latest/user/supported-data-sources.html",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 499310,
          "date": "Sat 11 Dec 2021 11:10",
          "username": "cldy",
          "content": "A.  Use Amazon Kinesis Data Firehose to buffer events. Create an AWS Lambda function to process and transform events.<br>D.  Configure Amazon Elasticsearch Service (Amazon ES) to receive events. Use the Kibana endpoint deployed with Amazon ES to create near-real-time visualizations and dashboards.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 495101,
          "date": "Mon 06 Dec 2021 13:02",
          "username": "AzureDP900",
          "content": "A & D is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 490387,
          "date": "Tue 30 Nov 2021 04:30",
          "username": "acloudguru",
          "content": "AD, this is a pattern of AWS, simple question, hope I can have it in my exam",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: AD"
        },
        {
          "id": 446968,
          "date": "Sun 07 Nov 2021 05:59",
          "username": "andylogan",
          "content": "It's A D",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 444965,
          "date": "Fri 05 Nov 2021 18:45",
          "username": "icttss",
          "content": "how about B&E ? <br>https://aws-samples.github.io/aws-dbs-refarch-graph/src/writing-from-amazon-kinesis-data-streams/",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 439713,
          "date": "Thu 04 Nov 2021 18:35",
          "username": "DerekKey",
          "content": "A&D correct<br>B wrong - Kinesis Datastream will not scale automatically. You must do it manually<br>C wrong - \\\"dynamic schemas\\\"",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 435315,
          "date": "Tue 02 Nov 2021 09:11",
          "username": "tgv",
          "content": "AAA DDD<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 434043,
          "date": "Sun 31 Oct 2021 15:58",
          "username": "blackgamer",
          "content": "Answer is AD",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 414025,
          "date": "Sat 30 Oct 2021 12:45",
          "username": "WhyIronManWhyIronMan",
          "content": "I'll go with with B,DChanging to A,D after read",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 414026,
          "date": "Sun 31 Oct 2021 04:20",
          "username": "WhyIronMan",
          "content": "Changing to A,D after read",
          "upvote_count": "1",
          "selected_answers": ""
        }
      ]
    },
    {
      "question_id": "#699",
      "topic_id": 1,
      "course_id": 1,
      "case_study_id": null,
      "lab_id": 0,
      "question_text": "<p>A life sciences company is using a combination of open source tools to manage data analysis workflows and Docker containers running on servers in its on- premises data center to process genomics data. Sequencing data is generated and stored on a local storage area network (SAN), and then the data is processed.<br>The research and development teams are running into capacity issues and have decided to re-architect their genomics analysis platform on AWS to scale based on workload demands and reduce the turnaround time from weeks to days.<br>The company has a high-speed AWS Direct Connect connection. Sequencers will generate around 200 GB of data for each genome, and individual jobs can take several hours to process the data with ideal compute capacity. The end result will be stored in Amazon S3. The company is expecting 10-15 job requests each day.<br>Which solution meets these requirements?<br><br><br></p>",
      "mark": 1,
      "is_partially_correct": false,
      "question_type": "1",
      "difficulty_level": "0",
      "general_feedback": "<p>Correct Answer: C</p>",
      "is_active": true,
      "answer_list": [
        {
          "question_answer_id": 1,
          "question_id": "#699",
          "answers": [
            {
              "choice": "<p>A. Use regularly scheduled AWS Snowball Edge devices to transfer the sequencing data into AWS. When AWS receives the Snowball Edge device and the data is loaded into Amazon S3, use S3 events to trigger an AWS Lambda function to process the data.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>B. Use AWS Data Pipeline to transfer the sequencing data to Amazon S3. Use S3 events to trigger an Amazon EC2 Auto Scaling group to launch custom-AMI EC2 instances running the Docker containers to process the data.<br></p>",
              "correct": false,
              "feedback": ""
            },
            {
              "choice": "<p>C. Use AWS DataSync to transfer the sequencing data to Amazon S3. Use S3 events to trigger an AWS Lambda function that starts an AWS Step Functions workflow. Store the Docker images in Amazon Elastic Container Registry (Amazon ECR) and trigger AWS Batch to run the container and process the sequencing data.<br></p>",
              "correct": true,
              "feedback": ""
            },
            {
              "choice": "<p>D. Use an AWS Storage Gateway file gateway to transfer the sequencing data to Amazon S3. Use S3 events to trigger an AWS Batch job that executes on Amazon EC2 instances running the Docker containers to process the data.<br></p>",
              "correct": false,
              "feedback": ""
            }
          ]
        }
      ],
      "topic_name": "",
      "discusstion": [
        {
          "id": 339643,
          "date": "Wed 13 Oct 2021 09:06",
          "username": "CarisBExtHo",
          "content": "Agree on C. <br>For instance: https://docs.aws.amazon.com/whitepapers/latest/genomics-data-transfer-analytics-and-machine-learning/transferring-genomics-data-to-the-cloud-and-establishing-data-access-patterns-using-aws-datasync-and-aws-storage-gateway-for-files.html => Use AWS DataSync to transfer data to Amazon S3Very good reference provided clears doubts :)",
          "upvote_count": "191",
          "selected_answers": ""
        },
        {
          "id": 343655,
          "date": "Wed 13 Oct 2021 15:20",
          "username": "ExtHo",
          "content": "Very good reference provided clears doubts :)",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 314924,
          "date": "Fri 24 Sep 2021 04:00",
          "username": "sek12324",
          "content": "C for me, as docker images are used - they need ECR",
          "upvote_count": "15",
          "selected_answers": ""
        },
        {
          "id": 688502,
          "date": "Fri 07 Oct 2022 12:10",
          "username": "sjpd10",
          "content": "The question has some key words that are referred in the AWS link - third-party tools, open-source tools, which is in the question. It also says, if the data is local storage (SAN), use 'Storage GW.<br><br>Is the answer still A.  I vote D. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 682614,
          "date": "Thu 29 Sep 2022 13:32",
          "username": "JohnPiJohnPi",
          "content": "the problem that I see with optionC AWS DataSync is related to the fact that input is a storage area network (SAN) and according to the docs AWS DataSync can connect to NAS as a NFS/SMB file sharethis is the statement:\\\"Sequencing data is generated and stored on a local storage area network (SAN), and then the data is processed.\\\" so SAN not NAS",
          "upvote_count": "11",
          "selected_answers": ""
        },
        {
          "id": 682618,
          "date": "Thu 29 Sep 2022 13:33",
          "username": "JohnPi",
          "content": "this is the statement:\\\"Sequencing data is generated and stored on a local storage area network (SAN), and then the data is processed.\\\" so SAN not NAS",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 628810,
          "date": "Fri 08 Jul 2022 16:40",
          "username": "asfsdfsdf",
          "content": "Answer is C - docker images with ECR / DataSync to move the data with DX / Batch to run compute process with containers - this donewith job Type: \\\"container\\\" and an image from ECR",
          "upvote_count": "1",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 553153,
          "date": "Mon 21 Feb 2022 20:18",
          "username": "johnnsmithasfsdfsdf",
          "content": "D is the correct answer. C is incorrect. S3 event can trigger Batch job.This is incorrect, S3 event can trigger only the below services:<br>Amazon Simple Notification Service (Amazon SNS) topics<br>Amazon Simple Queue Service (Amazon SQS) queues<br>AWS Lambda function<br>Answer is C - docker images - ECR / DataSync to move the data with DX",
          "upvote_count": "21",
          "selected_answers": ""
        },
        {
          "id": 628809,
          "date": "Fri 08 Jul 2022 16:37",
          "username": "asfsdfsdf",
          "content": "This is incorrect, S3 event can trigger only the below services:<br>Amazon Simple Notification Service (Amazon SNS) topics<br>Amazon Simple Queue Service (Amazon SQS) queues<br>AWS Lambda function<br>Answer is C - docker images - ECR / DataSync to move the data with DX",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 543099,
          "date": "Tue 08 Feb 2022 15:36",
          "username": "jj22222",
          "content": "CCCCCCCCCCCCCCCCCC",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 522849,
          "date": "Thu 13 Jan 2022 14:25",
          "username": "pititcu667",
          "content": "c because i belive it's better to use ecs than lambda.",
          "upvote_count": "2",
          "selected_answers": "Selected Answer: C"
        },
        {
          "id": 513901,
          "date": "Fri 31 Dec 2021 06:48",
          "username": "cldy",
          "content": "C is correct.",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 501383,
          "date": "Tue 14 Dec 2021 14:30",
          "username": "mm84",
          "content": "Agree on C. ",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 496981,
          "date": "Wed 08 Dec 2021 18:13",
          "username": "AzureDP900",
          "content": "C is right",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 446976,
          "date": "Thu 04 Nov 2021 02:27",
          "username": "andylogan",
          "content": "It's C <br>refer to compare DataSync usage to others<br>https://aws.amazon.com/datasync/faqs/#When_to_choose_AWS_DataSync",
          "upvote_count": "3",
          "selected_answers": ""
        },
        {
          "id": 436577,
          "date": "Thu 28 Oct 2021 22:53",
          "username": "tgv",
          "content": "CCC<br>---",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 434060,
          "date": "Sat 23 Oct 2021 15:59",
          "username": "blackgamer",
          "content": "C is the answer",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 414029,
          "date": "Thu 21 Oct 2021 09:02",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "2",
          "selected_answers": ""
        },
        {
          "id": 414024,
          "date": "Wed 20 Oct 2021 18:41",
          "username": "WhyIronMan",
          "content": "I'll go with C",
          "upvote_count": "1",
          "selected_answers": ""
        },
        {
          "id": 367538,
          "date": "Wed 20 Oct 2021 10:47",
          "username": "mustpassla",
          "content": "C looks good",
          "upvote_count": "2",
          "selected_answers": ""
        }
      ]
    }
  ]
}